{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T10:28:45.210262Z",
     "start_time": "2020-10-01T10:28:44.233496Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import imp\n",
    "import re\n",
    "import pickle\n",
    "import datetime\n",
    "import random\n",
    "import math\n",
    "import logging\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torch.utils import data\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "\n",
    "from utils import utils\n",
    "from utils.readers import InHospitalMortalityReader\n",
    "from utils.preprocessing import Discretizer, Normalizer\n",
    "from utils import metrics\n",
    "from utils import common_utils\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import imp\n",
    "import re\n",
    "import pickle\n",
    "import datetime\n",
    "import random\n",
    "import math\n",
    "import logging\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torch.utils import data\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "\n",
    "from utils import utils\n",
    "from utils.readers import InHospitalMortalityReader\n",
    "from utils.preprocessing import Discretizer, Normalizer\n",
    "from utils import metrics\n",
    "from utils import common_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T10:28:45.224657Z",
     "start_time": "2020-10-01T10:28:45.213220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "available device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() == True else 'cpu')\n",
    "# device = torch.device('cuda')\n",
    "print(\"available device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T10:28:45.291735Z",
     "start_time": "2020-10-01T10:28:45.228522Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_loss(y_pred, y_true):\n",
    "    loss = torch.nn.BCELoss()\n",
    "    return loss(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T10:28:45.349940Z",
     "start_time": "2020-10-01T10:28:45.295457Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_re_loss(y_pred, y_true):\n",
    "    loss = torch.nn.MSELoss()\n",
    "    return loss(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T10:28:45.408877Z",
     "start_time": "2020-10-01T10:28:45.353534Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_kl_loss(x_pred, x_target):\n",
    "    loss = torch.nn.KLDivLoss(reduce=True, size_average=True)\n",
    "    return loss(x_pred, x_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T10:28:45.479272Z",
     "start_time": "2020-10-01T10:28:45.412774Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_wass_dist(x_pred, x_target):\n",
    "    m1 = torch.mean(x_pred, dim=0)\n",
    "    m2 = torch.mean(x_target, dim=0)\n",
    "    v1 = torch.var(x_pred, dim=0)\n",
    "    v2 = torch.var(x_target, dim=0)\n",
    "    p1 = torch.sum(torch.pow((m1 - m2), 2))\n",
    "    p2 = torch.sum(torch.pow(torch.pow(v1, 1/2) - torch.pow(v2, 1/2), 2))\n",
    "    return torch.pow(p1+p2, 1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T10:28:45.541426Z",
     "start_time": "2020-10-01T10:28:45.481530Z"
    }
   },
   "outputs": [],
   "source": [
    "def pad_sents(sents, pad_token):\n",
    "\n",
    "    sents_padded = []\n",
    "\n",
    "    max_length = max([len(_) for _ in sents])\n",
    "    for i in sents:\n",
    "        padded = list(i) + [pad_token]*(max_length-len(i))\n",
    "        sents_padded.append(np.array(padded))\n",
    "\n",
    "\n",
    "    return np.array(sents_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T10:28:45.605189Z",
     "start_time": "2020-10-01T10:28:45.545009Z"
    }
   },
   "outputs": [],
   "source": [
    "def batch_iter(x, y, mask, lens, batch_size, shuffle=False):\n",
    "    \"\"\" Yield batches of source and target sentences reverse sorted by length (largest to smallest).\n",
    "    @param data (list of (src_sent, tgt_sent)): list of tuples containing source and target sentence\n",
    "    @param batch_size (int): batch size\n",
    "    @param shuffle (boolean): whether to randomly shuffle the dataset\n",
    "    \"\"\"\n",
    "    batch_num = math.ceil(len(x) / batch_size) # 向下取整\n",
    "    index_array = list(range(len(x)))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(index_array)\n",
    "\n",
    "    for i in range(batch_num):\n",
    "        indices = index_array[i * batch_size: (i + 1) * batch_size] #  fetch out all the induces\n",
    "        \n",
    "        examples = []\n",
    "        for idx in indices:\n",
    "            examples.append((x[idx], y[idx], mask[idx], lens[idx]))\n",
    "       \n",
    "        examples = sorted(examples, key=lambda e: len(e[0]), reverse=True)\n",
    "    \n",
    "        batch_x = [e[0] for e in examples]\n",
    "        batch_y = [e[1] for e in examples]\n",
    "        batch_mask_x = [e[2] for e in examples]\n",
    "#         batch_name = [e[2] for e in examples]\n",
    "        batch_lens = [e[3] for e in examples]\n",
    "\n",
    "        yield batch_x, batch_y, batch_mask_x, batch_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T10:28:45.671862Z",
     "start_time": "2020-10-01T10:28:45.608261Z"
    }
   },
   "outputs": [],
   "source": [
    "def length_to_mask(length, max_len=None, dtype=None):\n",
    "    \"\"\"length: B.\n",
    "    return B x max_len.\n",
    "    If max_len is None, then max of length will be used.\n",
    "    \"\"\"\n",
    "    assert len(length.shape) == 1, 'Length shape should be 1 dimensional.'\n",
    "    max_len = max_len or length.max().item()\n",
    "    mask = torch.arange(max_len, device=length.device,\n",
    "                        dtype=length.dtype).expand(len(length), max_len) < length.unsqueeze(1)\n",
    "    if dtype is not None:\n",
    "        mask = torch.as_tensor(mask, dtype=dtype, device=length.device)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T10:28:45.763313Z",
     "start_time": "2020-10-01T10:28:45.675341Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = ''\n",
    "all_x = pickle.load(open(data_path + 'x_all.pkl', 'rb'))\n",
    "all_y = pickle.load(open(data_path + 'y_death.pkl', 'rb'))\n",
    "# all_time = pickle.load(open(data_path + 'time_all.dat', 'rb'))\n",
    "# all_static = pickle.load(open(data_path + 'demo.dat', 'rb'))\n",
    "all_x_len = [len(i) for i in all_x]\n",
    "\n",
    "long_x = all_x\n",
    "long_y = [s[-1] for s in all_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T10:28:45.900293Z",
     "start_time": "2020-10-01T10:28:45.847212Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_n2n_data(x, y, x_len):\n",
    "    length = len(x)\n",
    "    assert length == len(y)\n",
    "    assert length == len(x_len)\n",
    "    new_x = []\n",
    "    new_y = []\n",
    "    new_x_len = []\n",
    "    for i in range(length):\n",
    "        for j in range(len(x[i])):\n",
    "            new_x.append(x[i][:j+1])\n",
    "            new_y.append(y[i])\n",
    "            new_x_len.append(j+1)\n",
    "    return new_x, new_y, new_x_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T10:28:45.997905Z",
     "start_time": "2020-10-01T10:28:45.903460Z"
    }
   },
   "outputs": [],
   "source": [
    "class SingleAttention(nn.Module):\n",
    "    def __init__(self, attention_input_dim, attention_hidden_dim, attention_type='add', demographic_dim=12, time_aware=False, use_demographic=False):\n",
    "        super(SingleAttention, self).__init__()\n",
    "        \n",
    "        self.attention_type = attention_type\n",
    "        self.attention_hidden_dim = attention_hidden_dim\n",
    "        self.attention_input_dim = attention_input_dim\n",
    "        self.use_demographic = use_demographic\n",
    "        self.demographic_dim = demographic_dim\n",
    "        self.time_aware = time_aware\n",
    "\n",
    "       \n",
    "        \n",
    "        if attention_type == 'add':\n",
    "            if self.time_aware == True:\n",
    "                \n",
    "                self.Wx = nn.Parameter(torch.randn(attention_input_dim, attention_hidden_dim))\n",
    "                self.Wtime_aware = nn.Parameter(torch.randn(1, attention_hidden_dim))\n",
    "                nn.init.kaiming_uniform_(self.Wtime_aware, a=math.sqrt(5))\n",
    "            else:\n",
    "                self.Wx = nn.Parameter(torch.randn(attention_input_dim, attention_hidden_dim))\n",
    "            self.Wt = nn.Parameter(torch.randn(attention_input_dim, attention_hidden_dim))\n",
    "            self.Wd = nn.Parameter(torch.randn(demographic_dim, attention_hidden_dim))\n",
    "            self.bh = nn.Parameter(torch.zeros(attention_hidden_dim,))\n",
    "            self.Wa = nn.Parameter(torch.randn(attention_hidden_dim, 1))\n",
    "            self.ba = nn.Parameter(torch.zeros(1,))\n",
    "            \n",
    "            nn.init.kaiming_uniform_(self.Wd, a=math.sqrt(5))\n",
    "            nn.init.kaiming_uniform_(self.Wx, a=math.sqrt(5))\n",
    "            nn.init.kaiming_uniform_(self.Wt, a=math.sqrt(5))\n",
    "            nn.init.kaiming_uniform_(self.Wa, a=math.sqrt(5))\n",
    "        elif attention_type == 'mul':\n",
    "            self.Wa = nn.Parameter(torch.randn(attention_input_dim, attention_input_dim))\n",
    "            self.ba = nn.Parameter(torch.zeros(1,))\n",
    "            \n",
    "            nn.init.kaiming_uniform_(self.Wa, a=math.sqrt(5))\n",
    "        elif attention_type == 'concat':\n",
    "            if self.time_aware == True:\n",
    "                self.Wh = nn.Parameter(torch.randn(2*attention_input_dim+1, attention_hidden_dim))\n",
    "            else:\n",
    "                self.Wh = nn.Parameter(torch.randn(2*attention_input_dim, attention_hidden_dim))\n",
    "\n",
    "            self.Wa = nn.Parameter(torch.randn(attention_hidden_dim, 1))\n",
    "            self.ba = nn.Parameter(torch.zeros(1,))\n",
    "            \n",
    "            nn.init.kaiming_uniform_(self.Wh, a=math.sqrt(5))\n",
    "            nn.init.kaiming_uniform_(self.Wa, a=math.sqrt(5))\n",
    "        else:\n",
    "            raise RuntimeError('Wrong attention type.')\n",
    "        \n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "    \n",
    "    def forward(self, input, demo=None):\n",
    " \n",
    "        batch_size, time_step, input_dim = input.size() # batch_size * time_step * hidden_dim(i)\n",
    "        \n",
    "        time_decays = torch.tensor(range(47,-1,-1), dtype=torch.float32).unsqueeze(-1).unsqueeze(0).to(device)# 1*t*1\n",
    "        b_time_decays = time_decays.repeat(batch_size,1,1)# b t 1\n",
    "        \n",
    "        if self.attention_type == 'add': #B*T*I  @ H*I\n",
    "            q = torch.matmul(input[:,-1,:], self.Wt)# b h\n",
    "            q = torch.reshape(q, (batch_size, 1, self.attention_hidden_dim)) #B*1*H\n",
    "            if self.time_aware == True:\n",
    "                # k_input = torch.cat((input, time), dim=-1)\n",
    "                k = torch.matmul(input, self.Wx)#b t h\n",
    "                # k = torch.reshape(k, (batch_size, 1, time_step, self.attention_hidden_dim)) #B*1*T*H\n",
    "                time_hidden = torch.matmul(b_time_decays, self.Wtime_aware)#  b t h\n",
    "            else:\n",
    "                k = torch.matmul(input, self.Wx)# b t h\n",
    "                # k = torch.reshape(k, (batch_size, 1, time_step, self.attention_hidden_dim)) #B*1*T*H\n",
    "            if self.use_demographic == True:\n",
    "                d = torch.matmul(demo, self.Wd) #B*H\n",
    "                d = torch.reshape(d, (batch_size, 1, self.attention_hidden_dim)) # b 1 h\n",
    "            h = q + k + self.bh # b t h\n",
    "            if self.time_aware == True:\n",
    "                h += time_hidden\n",
    "            h = self.tanh(h) #B*T*H\n",
    "            e = torch.matmul(h, self.Wa) + self.ba #B*T*1\n",
    "            e = torch.reshape(e, (batch_size, time_step))# b t\n",
    "        elif self.attention_type == 'mul':\n",
    "            e = torch.matmul(input[:,-1,:], self.Wa)#b i\n",
    "            e = torch.matmul(e.unsqueeze(1), input.permute(0,2,1)).squeeze() + self.ba #b t\n",
    "        elif self.attention_type == 'concat':\n",
    "            q = input[:,-1,:].unsqueeze(1).repeat(1,time_step,1)# b t i\n",
    "            k = input\n",
    "            c = torch.cat((q, k), dim=-1) #B*T*2I\n",
    "            if self.time_aware == True:\n",
    "                c = torch.cat((c, b_time_decays), dim=-1) #B*T*2I+1\n",
    "            h = torch.matmul(c, self.Wh)\n",
    "            h = self.tanh(h)\n",
    "            e = torch.matmul(h, self.Wa) + self.ba #B*T*1\n",
    "            e = torch.reshape(e, (batch_size, time_step)) # b t \n",
    "     \n",
    "        a = self.softmax(e) #B*T\n",
    "        v = torch.matmul(a.unsqueeze(1), input).squeeze() #B*I\n",
    "\n",
    "        return v, a\n",
    "\n",
    "class FinalAttentionQKV(nn.Module):\n",
    "    def __init__(self, attention_input_dim, attention_hidden_dim, attention_type='add', dropout=None):\n",
    "        super(FinalAttentionQKV, self).__init__()\n",
    "        \n",
    "        self.attention_type = attention_type\n",
    "        self.attention_hidden_dim = attention_hidden_dim\n",
    "        self.attention_input_dim = attention_input_dim\n",
    "\n",
    "\n",
    "        self.W_q = nn.Linear(attention_input_dim, attention_hidden_dim)\n",
    "        self.W_k = nn.Linear(attention_input_dim, attention_hidden_dim)\n",
    "        self.W_v = nn.Linear(attention_input_dim, attention_hidden_dim)\n",
    "\n",
    "        self.W_out = nn.Linear(attention_hidden_dim, 1)\n",
    "\n",
    "        self.b_in = nn.Parameter(torch.zeros(1,))\n",
    "        self.b_out = nn.Parameter(torch.zeros(1,))\n",
    "\n",
    "        nn.init.kaiming_uniform_(self.W_q.weight, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.W_k.weight, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.W_v.weight, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.W_out.weight, a=math.sqrt(5))\n",
    "\n",
    "        self.Wh = nn.Parameter(torch.randn(2*attention_input_dim, attention_hidden_dim))\n",
    "        self.Wa = nn.Parameter(torch.randn(attention_hidden_dim, 1))\n",
    "        self.ba = nn.Parameter(torch.zeros(1,))\n",
    "        \n",
    "        nn.init.kaiming_uniform_(self.Wh, a=math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.Wa, a=math.sqrt(5))\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "#         self.sparsemax = Sparsemax()\n",
    "    \n",
    "    def forward(self, input):\n",
    " \n",
    "        batch_size, time_step, input_dim = input.size() # batch_size * input_dim + 1 * hidden_dim(i)\n",
    "#         input_q = self.W_q(input[:, -1, :]) # b h\n",
    "        input_q = self.W_q(torch.mean(input, 1))\n",
    "        input_k = self.W_k(input)# b t h\n",
    "        input_v = self.W_v(input)# b t h\n",
    "\n",
    "        if self.attention_type == 'add': #B*T*I  @ H*I\n",
    "\n",
    "            q = torch.reshape(input_q, (batch_size, 1, self.attention_hidden_dim)) #B*1*H\n",
    "            h = q + input_k + self.b_in # b t h\n",
    "            h = self.tanh(h) #B*T*H\n",
    "            e = self.W_out(h) # b t 1\n",
    "            e = torch.reshape(e, (batch_size, time_step))# b t\n",
    "\n",
    "        elif self.attention_type == 'mul':\n",
    "            q = torch.reshape(input_q, (batch_size, self.attention_hidden_dim, 1)) #B*h 1\n",
    "            e = torch.matmul(input_k, q).squeeze(2)#b t\n",
    "            \n",
    "        elif self.attention_type == 'concat':\n",
    "            q = input_q.unsqueeze(1).repeat(1,time_step,1)# b t h\n",
    "            k = input_k\n",
    "            c = torch.cat((q, k), dim=-1) #B*T*2I\n",
    "            h = torch.matmul(c, self.Wh)\n",
    "            h = self.tanh(h)\n",
    "            e = torch.matmul(h, self.Wa) + self.ba #B*T*1\n",
    "            e = torch.reshape(e, (batch_size, time_step)) # b t \n",
    "        \n",
    "        a = self.softmax(e) \n",
    "        if self.dropout is not None:\n",
    "            a = self.dropout(a)\n",
    "        v = torch.matmul(a.unsqueeze(1), input_v).squeeze(1) #B*I\n",
    "\n",
    "        return v, a\n",
    "\n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "def tile(a, dim, n_tile):\n",
    "    init_dim = a.size(dim)\n",
    "    repeat_idx = [1] * a.dim()\n",
    "    repeat_idx[dim] = n_tile\n",
    "    a = a.repeat(*(repeat_idx))\n",
    "    order_index = torch.LongTensor(np.concatenate([init_dim * np.arange(n_tile) + i for i in range(init_dim)])).to(device)\n",
    "    return torch.index_select(a, dim, order_index).to(device)\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module): # new added\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x)))), None\n",
    "\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module): \n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, dropout, max_len=400):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0., max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0., d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], \n",
    "                         requires_grad=False)\n",
    "        return self.dropout(x)\n",
    "\n",
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0 \n",
    "\n",
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)# b h t d_k\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k) # b h t t\n",
    "    if mask is not None:# 1 1 t t\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)# b h t t\n",
    "    p_attn = F.softmax(scores, dim = -1)# b h t t\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn # b h t v (d_k) \n",
    "    \n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, self.d_k * self.h), 3)\n",
    "        self.final_linear = nn.Linear(d_model, d_model)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1) # 1 1 t t\n",
    "\n",
    "        nbatches = query.size(0)# b\n",
    "        input_dim = query.size(1)# i+1\n",
    "        feature_dim = query.size(-1)# i+1\n",
    "\n",
    "        #input size -> # batch_size * d_input * hidden_dim\n",
    "        \n",
    "        # d_model => h * d_k \n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))] # b num_head d_input d_k\n",
    "        \n",
    "       \n",
    "        x, self.attn = attention(query, key, value, mask=mask, \n",
    "                                 dropout=self.dropout)# b num_head d_input d_v (d_k) \n",
    "\n",
    "       \n",
    "\n",
    "      \n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)# batch_size * d_input * hidden_dim\n",
    "\n",
    "\n",
    "\n",
    "        return self.final_linear(x), 0\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, features, eps=1e-7):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
    "\n",
    "def cov(m, y=None):\n",
    "    if y is not None:\n",
    "        m = torch.cat((m, y), dim=0)\n",
    "    m_exp = torch.mean(m, dim=1)\n",
    "    x = m - m_exp[:, None]\n",
    "    cov = 1 / (x.size(1) - 1) * x.mm(x.t())\n",
    "    return cov\n",
    "\n",
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        returned_value = sublayer(self.norm(x))\n",
    "        return x + self.dropout(returned_value[0]) , returned_value[1]\n",
    "\n",
    "class vanilla_transformer_encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, d_model,  MHD_num_head, d_ff, output_dim, keep_prob=0.5):\n",
    "        super(vanilla_transformer_encoder, self).__init__()\n",
    "\n",
    "        # hyperparameters\n",
    "        self.input_dim = input_dim  \n",
    "        self.hidden_dim = hidden_dim  # d_model\n",
    "        self.d_model = d_model\n",
    "        self.MHD_num_head = MHD_num_head\n",
    "        self.d_ff = d_ff\n",
    "        self.output_dim = output_dim\n",
    "        self.keep_prob = keep_prob\n",
    "\n",
    "        # layers\n",
    "        self.PositionalEncoding = PositionalEncoding(self.d_model, dropout = 0, max_len = 400)\n",
    "\n",
    "        self.GRUs = clones(nn.GRU(1, self.hidden_dim, batch_first = True), self.input_dim)\n",
    "        self.LastStepAttentions = clones(SingleAttention(self.hidden_dim, 8, attention_type='concat', demographic_dim=12, time_aware=True, use_demographic=False),self.input_dim)\n",
    "        \n",
    "        self.FinalAttentionQKV = FinalAttentionQKV(self.hidden_dim, self.hidden_dim, attention_type='mul',dropout = 1 - self.keep_prob)\n",
    "\n",
    "        self.MultiHeadedAttention = MultiHeadedAttention(self.MHD_num_head, self.d_model,dropout = 1 - self.keep_prob)\n",
    "        self.SublayerConnection = SublayerConnection(self.d_model, dropout = 1 - self.keep_prob)\n",
    "\n",
    "        self.PositionwiseFeedForward = PositionwiseFeedForward(self.d_model, self.d_ff, dropout=0.1)\n",
    "\n",
    "        self.demo_proj_main = nn.Linear(12, self.hidden_dim)\n",
    "        self.demo_proj = nn.Linear(12, self.hidden_dim)\n",
    "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(p = 1 - self.keep_prob)\n",
    "        self.tanh=nn.Tanh()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu=nn.ReLU()\n",
    "\n",
    "    def forward(self, input, demo_input):\n",
    " \n",
    "        \n",
    "        batch_size = input.size(0)\n",
    "        time_step = input.size(1)\n",
    "        feature_dim = input.size(2)\n",
    "        assert(feature_dim == self.input_dim)# input Tensor : 256 * 48 * 76\n",
    "        assert(self.d_model % self.MHD_num_head == 0)\n",
    "\n",
    "       \n",
    "\n",
    "        GRU_embeded_input = self.GRUs[0](input[:,:,0].unsqueeze(-1), Variable(torch.zeros(batch_size, self.hidden_dim).unsqueeze(0)).to(device))[0][:,-1,:].unsqueeze(1) # b 1 h\n",
    "        for i in range(feature_dim-1):\n",
    "            embeded_input = self.GRUs[i+1](input[:,:,i+1].unsqueeze(-1), Variable(torch.zeros(batch_size, self.hidden_dim).unsqueeze(0)).to(device))[0][:,-1,:].unsqueeze(1) # b 1 h\n",
    "            GRU_embeded_input = torch.cat((GRU_embeded_input, embeded_input), 1)\n",
    "\n",
    "        GRU_embeded_input = torch.cat((GRU_embeded_input, demo_main), 1)# b i+1 h\n",
    "        posi_input = self.dropout(GRU_embeded_input) # batch_size * d_input * hidden_dim\n",
    "\n",
    "\n",
    "        contexts = self.SublayerConnection(posi_input, lambda x: self.MultiHeadedAttention(posi_input, posi_input, posi_input, None))# # batch_size * d_input * hidden_dim\n",
    "\n",
    "        DeCov_loss = contexts[1]\n",
    "        contexts = contexts[0]\n",
    "\n",
    "        contexts = self.SublayerConnection(contexts, lambda x: self.PositionwiseFeedForward(contexts))[0]# # batch_size * d_input * hidden_dim\n",
    "        \n",
    "        weighted_contexts = self.FinalAttentionQKV(contexts)[0]\n",
    "        output = self.output(weighted_contexts)# b 1\n",
    "        output = self.sigmoid(output)\n",
    "          \n",
    "        return output, DeCov_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T10:28:46.074895Z",
     "start_time": "2020-10-01T10:28:46.000280Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "class vanilla_transformer_encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, d_model,  MHD_num_head, d_ff, output_dim, keep_prob=0.5):\n",
    "        super(vanilla_transformer_encoder, self).__init__()\n",
    "\n",
    "        # hyperparameters\n",
    "        self.input_dim = input_dim  \n",
    "        self.hidden_dim = hidden_dim  # d_model\n",
    "        self.d_model = d_model\n",
    "        self.MHD_num_head = MHD_num_head\n",
    "        self.d_ff = d_ff\n",
    "        self.output_dim = output_dim\n",
    "        self.keep_prob = keep_prob\n",
    "\n",
    "        # layers\n",
    "        self.PositionalEncoding = PositionalEncoding(self.d_model, dropout = 0, max_len = 400)\n",
    "\n",
    "        self.GRUs = clones(nn.GRU(1, self.hidden_dim, batch_first = True), self.input_dim)\n",
    "        self.LastStepAttentions = clones(SingleAttention(self.hidden_dim, 8, attention_type='concat', demographic_dim=12, time_aware=True, use_demographic=False),self.input_dim)\n",
    "        \n",
    "        self.FinalAttentionQKV = FinalAttentionQKV(self.hidden_dim, self.hidden_dim, attention_type='mul',dropout = 1 - self.keep_prob)\n",
    "\n",
    "        self.MultiHeadedAttention = MultiHeadedAttention(self.MHD_num_head, self.d_model,dropout = 1 - self.keep_prob)\n",
    "        self.SublayerConnection = SublayerConnection(self.d_model, dropout = 1 - self.keep_prob)\n",
    "\n",
    "        self.PositionwiseFeedForward = PositionwiseFeedForward(self.d_model, self.d_ff, dropout=0.1)\n",
    "\n",
    "        self.demo_proj_main = nn.Linear(2, self.hidden_dim)\n",
    "        self.demo_proj = nn.Linear(2, self.hidden_dim)\n",
    "        self.output = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(p = 1 - self.keep_prob)\n",
    "        self.tanh=nn.Tanh()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.relu=nn.ReLU()\n",
    "\n",
    "    def forward(self, input, lens):\n",
    "        \n",
    "        \n",
    "        batch_size = input.size(0)\n",
    "        time_step = input.size(1)\n",
    "        feature_dim = input.size(2)\n",
    "        assert(feature_dim == self.input_dim)# input Tensor : 256 * 48 * 76\n",
    "        assert(self.d_model % self.MHD_num_head == 0)\n",
    "\n",
    "        GRU_embeded_input = self.GRUs[0](pack_padded_sequence(input[:, :, 0].unsqueeze(-1), lens, batch_first=True))[1].squeeze(0).unsqueeze(1)\n",
    "        for i in range(feature_dim-1):\n",
    "            embeded_input = self.GRUs[i + 1](pack_padded_sequence(input[:, :, i + 1].unsqueeze(-1), lens, batch_first=True))[1].squeeze(0).unsqueeze(1)\n",
    "            GRU_embeded_input = torch.cat((GRU_embeded_input, embeded_input), 1)\n",
    "\n",
    "        posi_input = self.dropout(GRU_embeded_input) # batch_size * d_input * hidden_dim\n",
    "\n",
    "        contexts = self.SublayerConnection(posi_input, lambda x: self.MultiHeadedAttention(posi_input, posi_input, posi_input, None))# # batch_size * d_input * hidden_dim\n",
    "    \n",
    "        DeCov_loss = contexts[1]\n",
    "        contexts = contexts[0]\n",
    "\n",
    "        contexts = self.SublayerConnection(contexts, lambda x: self.PositionwiseFeedForward(contexts))[0]# # batch_size * d_input * hidden_dim\n",
    "        \n",
    "        weighted_contexts, attn = self.FinalAttentionQKV(contexts)\n",
    "        output = self.output(weighted_contexts)# b 1\n",
    "          \n",
    "        return output, attn, weighted_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T10:28:46.149129Z",
     "start_time": "2020-10-01T10:28:46.077436Z"
    }
   },
   "outputs": [],
   "source": [
    "def euclidean_dist(x, y):\n",
    "    b = x.size(0)\n",
    "    xx = torch.pow(x, 2).sum(1, keepdim=True).expand(b, b)\n",
    "    yy = torch.pow(y, 2).sum(1, keepdim=True).expand(b, b).t()\n",
    "    dist = xx+yy-2*torch.mm(x, y.t())\n",
    "    return dist\n",
    "\n",
    "def guassian_kernel(source, kernel_mul=2.0, kernel_num=1, fix_sigma=None):\n",
    "    n = source.size(0)\n",
    "    L2_distance = euclidean_dist(source, source)\n",
    "    if fix_sigma:\n",
    "        bandwidth = fix_sigma\n",
    "    else:\n",
    "        bandwidth = torch.sum(L2_distance.data) / (n**2-n)\n",
    "    bandwidth /= kernel_mul ** (kernel_num//2)\n",
    "    bandwidth_list = [bandwidth*(kernel_mul**i) for i in range(kernel_num)]\n",
    "    kernel_val = [torch.exp(-L2_distance/bandwidth_temp) for bandwidth_temp in bandwidth_list]\n",
    "    return sum(kernel_val)/len(kernel_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T10:29:52.540128Z",
     "start_time": "2020-10-01T10:29:52.483243Z"
    }
   },
   "outputs": [],
   "source": [
    "# Our MAPLE framework\n",
    "\n",
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "    \n",
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.Tensor(in_features, out_features).float())\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_features).float())\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.initialize_parameters()\n",
    "\n",
    "    def initialize_parameters(self):\n",
    "        std = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(-std, std)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-std, std)\n",
    "\n",
    "    def forward(self, adj, x):\n",
    "        y = torch.mm(x.float(), self.weight.float())\n",
    "        output = torch.mm(adj.float(), y.float())\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias.float()\n",
    "        else:\n",
    "            return output\n",
    "    \n",
    "\n",
    "class PAIL(nn.Module):\n",
    "    def __init__(self, device, input_dim = 76, hidden_dim = 32, output_dim = 1, cluster_num = 12, dropout=0.0, block='LSTM'):\n",
    "        super(PAIL, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.cluster_num = cluster_num\n",
    "        self.dropout = dropout\n",
    "        self.block = block\n",
    "\n",
    "        \n",
    "        self.embed_layer = nn.Linear(self.input_dim, self.hidden_dim)\n",
    "        self.GRUs = clones(nn.GRU(1, self.hidden_dim, batch_first = True), self.input_dim)\n",
    "        self.opt_layer2 = nn.Linear( self.input_dim*self.hidden_dim, self.hidden_dim)\n",
    "        \n",
    "        self.opt_layer = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "        \n",
    "        \n",
    "        nn.init.xavier_uniform_(self.embed_layer.weight)\n",
    "        nn.init.xavier_uniform_(self.opt_layer.weight)\n",
    "        \n",
    "        self.backbone = vanilla_transformer_encoder(input_dim = self.input_dim, hidden_dim = self.hidden_dim, d_model = self.hidden_dim,  MHD_num_head = 4 , d_ff = 2*self.hidden_dim, output_dim = self.output_dim).to(device)\n",
    "\n",
    "        \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.bn1 = nn.BatchNorm1d(2 * self.hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout) \n",
    "        self.weight1 = nn.Linear(self.hidden_dim, 1)\n",
    "        self.weight2 = nn.Linear(self.hidden_dim, 1)\n",
    "        \n",
    "        self.simiProj = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
    "        \n",
    "        \n",
    "\n",
    "        self.bn = nn.BatchNorm1d(self.hidden_dim)\n",
    "    \n",
    "        self.GCN = GraphConvolution(self.hidden_dim, self.hidden_dim, bias=True)\n",
    "        self.GCN.initialize_parameters()\n",
    "        self.GCN_2 = GraphConvolution(self.hidden_dim, self.hidden_dim, bias=True)\n",
    "        self.GCN_2.initialize_parameters()\n",
    "        self.eps = nn.Parameter(torch.zeros(size=(1,)))\n",
    "\n",
    "        \n",
    "    def sample_gumbel(self, shape, eps=1e-20):\n",
    "        U = torch.rand(shape).to(device)\n",
    "\n",
    "        return -torch.log(-torch.log(U + eps) + eps)\n",
    "\n",
    "\n",
    "    def gumbel_softmax_sample(self, logits, temperature):\n",
    "        y = logits + self.sample_gumbel(logits.size())\n",
    "        return F.softmax(y / temperature, dim=-1)\n",
    "\n",
    "\n",
    "    def gumbel_softmax(self, logits, temperature, hard=False):\n",
    "        \"\"\"\n",
    "        ST-gumple-softmax\n",
    "        input: [*, n_class]\n",
    "        return: flatten --> [*, n_class] an one-hot vector\n",
    "        \"\"\"\n",
    "        y = self.gumbel_softmax_sample(logits, temperature)\n",
    "\n",
    "        if not hard:\n",
    "            return y.view(-1, self.cluster_num)\n",
    "\n",
    "        shape = y.size()\n",
    "        _, ind = y.max(dim=-1)\n",
    "        y_hard = torch.zeros_like(y).view(-1, shape[-1])\n",
    "        y_hard.scatter_(1, ind.view(-1, 1), 1)\n",
    "        y_hard = y_hard.view(*shape)\n",
    "        # Set gradients w.r.t. y_hard gradients w.r.t. y\n",
    "        y_hard = (y_hard - y).detach() + y\n",
    "        return y_hard\n",
    "    \n",
    "\n",
    "        \n",
    "    def forward(self, input, lens):\n",
    "        batch_size = input.size(0)\n",
    "        time_step = input.size(1)\n",
    "        feature_dim = input.size(2)\n",
    "        \n",
    "       \n",
    "        _,_, hidden_t = self.backbone(input,lens)\n",
    "        \n",
    "\n",
    "        adj_mat = guassian_kernel(self.tanh(self.simiProj(hidden_t)), kernel_mul=2.0, kernel_num=3)\n",
    "        adj_mat2 = guassian_kernel(hidden_t, kernel_mul=2.0, kernel_num=3)\n",
    "\n",
    "        adj_mat = ((1-self.sigmoid(self.eps))*adj_mat+self.sigmoid(self.eps))*adj_mat2\n",
    "    \n",
    "        scores = self.gumbel_softmax(adj_mat, temperature = 1, hard = True).int()# b b\n",
    "        for i in range(batch_size-1):\n",
    "            scores = scores | self.gumbel_softmax(adj_mat, temperature = 1, hard = True).int()# b b\n",
    "\n",
    "        adj_mat = adj_mat*scores.float()\n",
    "\n",
    "        h_prime = self.relu(self.GCN(adj_mat, hidden_t))\n",
    "        h_prime = self.relu(self.GCN_2(adj_mat, h_prime))\n",
    "\n",
    "\n",
    "         \n",
    "        weight1=torch.sigmoid(self.weight1(h_prime))\n",
    "        weight2 = torch.sigmoid(self.weight2(hidden_t))\n",
    "        weight1 = weight1/(weight1+weight2)\n",
    "        weight2= 1-weight1\n",
    "\n",
    "        final_h = weight1*h_prime+weight2*hidden_t\n",
    "\n",
    "\n",
    "        opt = self.sigmoid(self.opt_layer(self.bn(final_h))).squeeze(-1)\n",
    "\n",
    "                      \n",
    "        return opt, hidden_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T10:29:53.254754Z",
     "start_time": "2020-10-01T10:29:53.244814Z"
    }
   },
   "outputs": [],
   "source": [
    "input_dim = 33\n",
    "demo_dim = 2\n",
    "output_dim = 1\n",
    "hidden_dim = 64\n",
    "dropout = 0.5\n",
    "cluster_num =50\n",
    "block = 'GRU'\n",
    "use_demo = False\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED) #numpy\n",
    "random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED) # cpu\n",
    "torch.cuda.manual_seed(RANDOM_SEED) #gpu\n",
    "torch.backends.cudnn.deterministic=True # cudnn\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T10:29:54.065864Z",
     "start_time": "2020-10-01T10:29:54.051446Z"
    }
   },
   "outputs": [],
   "source": [
    "def covid_batch_iter(x, y, lens, batch_size, shuffle=False):\n",
    "    \"\"\" Yield batches of source and target sentences reverse sorted by length (largest to smallest).\n",
    "    @param data (list of (src_sent, tgt_sent)): list of tuples containing source and target sentence\n",
    "    @param batch_size (int): batch size\n",
    "    @param shuffle (boolean): whether to randomly shuffle the dataset\n",
    "    \"\"\"\n",
    "    batch_num = math.ceil(len(x) / batch_size) # 向下取整\n",
    "    index_array = list(range(len(x)))\n",
    "\n",
    "    if shuffle:\n",
    "        np.random.shuffle(index_array)\n",
    "\n",
    "    for i in range(batch_num):\n",
    "        indices = index_array[i * batch_size: (i + 1) * batch_size] #  fetch out all the induces\n",
    "        \n",
    "        examples = []\n",
    "        for idx in indices:\n",
    "            examples.append((x[idx], y[idx],  lens[idx]))\n",
    "       \n",
    "        examples = sorted(examples, key=lambda e: len(e[0]), reverse=True)\n",
    "    \n",
    "        batch_x = [e[0] for e in examples]\n",
    "        batch_y = [e[1] for e in examples]\n",
    "        batch_lens = [e[2] for e in examples]\n",
    "       \n",
    "\n",
    "        yield batch_x, batch_y, batch_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-01T11:34:11.594097Z",
     "start_time": "2020-10-01T10:29:55.495745Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: 6266, Validation data size: 1597\n",
      "Fold 1 Epoch 0 Batch 0: Train Loss = 0.7368\n",
      "Fold 1 Epoch 0 Batch 5: Train Loss = 0.6619\n",
      "Fold 1 Epoch 0 Batch 10: Train Loss = 0.6246\n",
      "Fold 1 Epoch 0 Batch 15: Train Loss = 0.6114\n",
      "Fold 1 Epoch 0 Batch 20: Train Loss = 0.5859\n",
      "Fold 1, epoch 0: Loss = 0.6157 Valid loss = 0.5795 roc = 0.8486\n",
      "confusion matrix:\n",
      "[[1225    0]\n",
      " [ 312   60]]\n",
      "accuracy = 0.8046336770057678\n",
      "precision class 0 = 0.797007143497467\n",
      "precision class 1 = 1.0\n",
      "recall class 0 = 1.0\n",
      "recall class 1 = 0.16129031777381897\n",
      "AUC of ROC = 0.8486229975861312\n",
      "AUC of PRC = 0.749629464514094\n",
      "min(+P, Se) = 0.6666666666666666\n",
      "f1_score = 0.2777777777777778\n",
      "------------ Save best model - AUROC: 0.8486 ------------\n",
      "Fold 1, roc = 0.8486, prc = 0.7496\n",
      "Fold 1 Epoch 1 Batch 0: Train Loss = 0.5024\n",
      "Fold 1 Epoch 1 Batch 5: Train Loss = 0.5310\n",
      "Fold 1 Epoch 1 Batch 10: Train Loss = 0.5342\n",
      "Fold 1 Epoch 1 Batch 15: Train Loss = 0.5093\n",
      "Fold 1 Epoch 1 Batch 20: Train Loss = 0.4368\n",
      "------------ Save best model - AUROC: 0.8543 ------------\n",
      "Fold 1, roc = 0.8543, prc = 0.7634\n",
      "Fold 1 Epoch 2 Batch 0: Train Loss = 0.4432\n",
      "Fold 1 Epoch 2 Batch 5: Train Loss = 0.3924\n",
      "Fold 1 Epoch 2 Batch 10: Train Loss = 0.4424\n",
      "Fold 1 Epoch 2 Batch 15: Train Loss = 0.4148\n",
      "Fold 1 Epoch 2 Batch 20: Train Loss = 0.3872\n",
      "------------ Save best model - AUROC: 0.8627 ------------\n",
      "Fold 1, roc = 0.8627, prc = 0.7725\n",
      "Fold 1 Epoch 3 Batch 0: Train Loss = 0.3713\n",
      "Fold 1 Epoch 3 Batch 5: Train Loss = 0.3803\n",
      "Fold 1 Epoch 3 Batch 10: Train Loss = 0.3548\n",
      "Fold 1 Epoch 3 Batch 15: Train Loss = 0.3569\n",
      "Fold 1 Epoch 3 Batch 20: Train Loss = 0.3714\n",
      "------------ Save best model - AUROC: 0.8655 ------------\n",
      "Fold 1, roc = 0.8655, prc = 0.7790\n",
      "Fold 1 Epoch 4 Batch 0: Train Loss = 0.3417\n",
      "Fold 1 Epoch 4 Batch 5: Train Loss = 0.3386\n",
      "Fold 1 Epoch 4 Batch 10: Train Loss = 0.3103\n",
      "Fold 1 Epoch 4 Batch 15: Train Loss = 0.3246\n",
      "Fold 1 Epoch 4 Batch 20: Train Loss = 0.2981\n",
      "Fold 1, roc = 0.8653, prc = 0.7745\n",
      "Fold 1 Epoch 5 Batch 0: Train Loss = 0.2609\n",
      "Fold 1 Epoch 5 Batch 5: Train Loss = 0.3231\n",
      "Fold 1 Epoch 5 Batch 10: Train Loss = 0.2574\n",
      "Fold 1 Epoch 5 Batch 15: Train Loss = 0.3119\n",
      "Fold 1 Epoch 5 Batch 20: Train Loss = 0.2693\n",
      "------------ Save best model - AUROC: 0.8818 ------------\n",
      "Fold 1, roc = 0.8818, prc = 0.7944\n",
      "Fold 1 Epoch 6 Batch 0: Train Loss = 0.2956\n",
      "Fold 1 Epoch 6 Batch 5: Train Loss = 0.2484\n",
      "Fold 1 Epoch 6 Batch 10: Train Loss = 0.2706\n",
      "Fold 1 Epoch 6 Batch 15: Train Loss = 0.3336\n",
      "Fold 1 Epoch 6 Batch 20: Train Loss = 0.2438\n",
      "Fold 1, roc = 0.8722, prc = 0.7826\n",
      "Fold 1 Epoch 7 Batch 0: Train Loss = 0.2647\n",
      "Fold 1 Epoch 7 Batch 5: Train Loss = 0.2593\n",
      "Fold 1 Epoch 7 Batch 10: Train Loss = 0.2873\n",
      "Fold 1 Epoch 7 Batch 15: Train Loss = 0.2775\n",
      "Fold 1 Epoch 7 Batch 20: Train Loss = 0.2459\n",
      "------------ Save best model - AUROC: 0.8876 ------------\n",
      "Fold 1, roc = 0.8876, prc = 0.8039\n",
      "Fold 1 Epoch 8 Batch 0: Train Loss = 0.2699\n",
      "Fold 1 Epoch 8 Batch 5: Train Loss = 0.2718\n",
      "Fold 1 Epoch 8 Batch 10: Train Loss = 0.3162\n",
      "Fold 1 Epoch 8 Batch 15: Train Loss = 0.2215\n",
      "Fold 1 Epoch 8 Batch 20: Train Loss = 0.2569\n",
      "Fold 1, roc = 0.8754, prc = 0.7942\n",
      "Fold 1 Epoch 9 Batch 0: Train Loss = 0.2476\n",
      "Fold 1 Epoch 9 Batch 5: Train Loss = 0.3167\n",
      "Fold 1 Epoch 9 Batch 10: Train Loss = 0.2867\n",
      "Fold 1 Epoch 9 Batch 15: Train Loss = 0.3091\n",
      "Fold 1 Epoch 9 Batch 20: Train Loss = 0.3159\n",
      "Fold 1, roc = 0.8860, prc = 0.8064\n",
      "Fold 1 Epoch 10 Batch 0: Train Loss = 0.2602\n",
      "Fold 1 Epoch 10 Batch 5: Train Loss = 0.2319\n",
      "Fold 1 Epoch 10 Batch 10: Train Loss = 0.2814\n",
      "Fold 1 Epoch 10 Batch 15: Train Loss = 0.2384\n",
      "Fold 1 Epoch 10 Batch 20: Train Loss = 0.2494\n",
      "Fold 1, epoch 10: Loss = 0.2534 Valid loss = 0.3203 roc = 0.8801\n",
      "confusion matrix:\n",
      "[[1186   39]\n",
      " [ 144  228]]\n",
      "accuracy = 0.8854101300239563\n",
      "precision class 0 = 0.8917292952537537\n",
      "precision class 1 = 0.8539325594902039\n",
      "recall class 0 = 0.968163251876831\n",
      "recall class 1 = 0.6129032373428345\n",
      "AUC of ROC = 0.8800603467193329\n",
      "AUC of PRC = 0.7960998148518486\n",
      "min(+P, Se) = 0.7265415549597856\n",
      "f1_score = 0.7136150516388816\n",
      "Fold 1, roc = 0.8801, prc = 0.7961\n",
      "Fold 1 Epoch 11 Batch 0: Train Loss = 0.2048\n",
      "Fold 1 Epoch 11 Batch 5: Train Loss = 0.2246\n",
      "Fold 1 Epoch 11 Batch 10: Train Loss = 0.2697\n",
      "Fold 1 Epoch 11 Batch 15: Train Loss = 0.2227\n",
      "Fold 1 Epoch 11 Batch 20: Train Loss = 0.2410\n",
      "Fold 1, roc = 0.8704, prc = 0.7842\n",
      "Fold 1 Epoch 12 Batch 0: Train Loss = 0.2206\n",
      "Fold 1 Epoch 12 Batch 5: Train Loss = 0.2183\n",
      "Fold 1 Epoch 12 Batch 10: Train Loss = 0.2164\n",
      "Fold 1 Epoch 12 Batch 15: Train Loss = 0.2490\n",
      "Fold 1 Epoch 12 Batch 20: Train Loss = 0.2467\n",
      "Fold 1, roc = 0.8828, prc = 0.8000\n",
      "Fold 1 Epoch 13 Batch 0: Train Loss = 0.2495\n",
      "Fold 1 Epoch 13 Batch 5: Train Loss = 0.2311\n",
      "Fold 1 Epoch 13 Batch 10: Train Loss = 0.2639\n",
      "Fold 1 Epoch 13 Batch 15: Train Loss = 0.2787\n",
      "Fold 1 Epoch 13 Batch 20: Train Loss = 0.2561\n",
      "Fold 1, roc = 0.8762, prc = 0.7899\n",
      "Fold 1 Epoch 14 Batch 0: Train Loss = 0.2401\n",
      "Fold 1 Epoch 14 Batch 5: Train Loss = 0.2302\n",
      "Fold 1 Epoch 14 Batch 10: Train Loss = 0.2377\n",
      "Fold 1 Epoch 14 Batch 15: Train Loss = 0.2443\n",
      "Fold 1 Epoch 14 Batch 20: Train Loss = 0.2436\n",
      "------------ Save best model - AUROC: 0.8878 ------------\n",
      "Fold 1, roc = 0.8878, prc = 0.8055\n",
      "Fold 1 Epoch 15 Batch 0: Train Loss = 0.2300\n",
      "Fold 1 Epoch 15 Batch 5: Train Loss = 0.2029\n",
      "Fold 1 Epoch 15 Batch 10: Train Loss = 0.1891\n",
      "Fold 1 Epoch 15 Batch 15: Train Loss = 0.2784\n",
      "Fold 1 Epoch 15 Batch 20: Train Loss = 0.2932\n",
      "Fold 1, roc = 0.8847, prc = 0.7996\n",
      "Fold 1 Epoch 16 Batch 0: Train Loss = 0.2044\n",
      "Fold 1 Epoch 16 Batch 5: Train Loss = 0.2271\n",
      "Fold 1 Epoch 16 Batch 10: Train Loss = 0.2241\n",
      "Fold 1 Epoch 16 Batch 15: Train Loss = 0.1984\n",
      "Fold 1 Epoch 16 Batch 20: Train Loss = 0.2208\n",
      "Fold 1, roc = 0.8702, prc = 0.7767\n",
      "Fold 1 Epoch 17 Batch 0: Train Loss = 0.2245\n",
      "Fold 1 Epoch 17 Batch 5: Train Loss = 0.2171\n",
      "Fold 1 Epoch 17 Batch 10: Train Loss = 0.2371\n",
      "Fold 1 Epoch 17 Batch 15: Train Loss = 0.2225\n",
      "Fold 1 Epoch 17 Batch 20: Train Loss = 0.2231\n",
      "Fold 1, roc = 0.8782, prc = 0.7841\n",
      "Fold 1 Epoch 18 Batch 0: Train Loss = 0.1919\n",
      "Fold 1 Epoch 18 Batch 5: Train Loss = 0.2162\n",
      "Fold 1 Epoch 18 Batch 10: Train Loss = 0.2244\n",
      "Fold 1 Epoch 18 Batch 15: Train Loss = 0.2139\n",
      "Fold 1 Epoch 18 Batch 20: Train Loss = 0.2207\n",
      "------------ Save best model - AUROC: 0.8901 ------------\n",
      "Fold 1, roc = 0.8901, prc = 0.7992\n",
      "Fold 1 Epoch 19 Batch 0: Train Loss = 0.2008\n",
      "Fold 1 Epoch 19 Batch 5: Train Loss = 0.2066\n",
      "Fold 1 Epoch 19 Batch 10: Train Loss = 0.2548\n",
      "Fold 1 Epoch 19 Batch 15: Train Loss = 0.2192\n",
      "Fold 1 Epoch 19 Batch 20: Train Loss = 0.2645\n",
      "Fold 1, roc = 0.8894, prc = 0.8092\n",
      "Fold 1 Epoch 20 Batch 0: Train Loss = 0.2284\n",
      "Fold 1 Epoch 20 Batch 5: Train Loss = 0.2178\n",
      "Fold 1 Epoch 20 Batch 10: Train Loss = 0.2205\n",
      "Fold 1 Epoch 20 Batch 15: Train Loss = 0.2560\n",
      "Fold 1 Epoch 20 Batch 20: Train Loss = 0.1801\n",
      "Fold 1, epoch 20: Loss = 0.2227 Valid loss = 0.4151 roc = 0.8639\n",
      "confusion matrix:\n",
      "[[1200   25]\n",
      " [ 182  190]]\n",
      "accuracy = 0.8703819513320923\n",
      "precision class 0 = 0.8683068156242371\n",
      "precision class 1 = 0.8837209343910217\n",
      "recall class 0 = 0.9795918464660645\n",
      "recall class 1 = 0.5107526779174805\n",
      "AUC of ROC = 0.8639400921658986\n",
      "AUC of PRC = 0.7712747958186219\n",
      "min(+P, Se) = 0.706989247311828\n",
      "f1_score = 0.6473594754045618\n",
      "Fold 1, roc = 0.8639, prc = 0.7713\n",
      "Fold 1 Epoch 21 Batch 0: Train Loss = 0.2439\n",
      "Fold 1 Epoch 21 Batch 5: Train Loss = 0.2250\n",
      "Fold 1 Epoch 21 Batch 10: Train Loss = 0.2058\n",
      "Fold 1 Epoch 21 Batch 15: Train Loss = 0.1931\n",
      "Fold 1 Epoch 21 Batch 20: Train Loss = 0.2232\n",
      "Fold 1, roc = 0.8691, prc = 0.7711\n",
      "Fold 1 Epoch 22 Batch 0: Train Loss = 0.2031\n",
      "Fold 1 Epoch 22 Batch 5: Train Loss = 0.2372\n",
      "Fold 1 Epoch 22 Batch 10: Train Loss = 0.2029\n",
      "Fold 1 Epoch 22 Batch 15: Train Loss = 0.2434\n",
      "Fold 1 Epoch 22 Batch 20: Train Loss = 0.3085\n",
      "Fold 1, roc = 0.8785, prc = 0.7872\n",
      "Fold 1 Epoch 23 Batch 0: Train Loss = 0.1504\n",
      "Fold 1 Epoch 23 Batch 5: Train Loss = 0.2501\n",
      "Fold 1 Epoch 23 Batch 10: Train Loss = 0.1990\n",
      "Fold 1 Epoch 23 Batch 15: Train Loss = 0.1728\n",
      "Fold 1 Epoch 23 Batch 20: Train Loss = 0.1947\n",
      "Fold 1, roc = 0.8889, prc = 0.8075\n",
      "Fold 1 Epoch 24 Batch 0: Train Loss = 0.1968\n",
      "Fold 1 Epoch 24 Batch 5: Train Loss = 0.2115\n",
      "Fold 1 Epoch 24 Batch 10: Train Loss = 0.1935\n",
      "Fold 1 Epoch 24 Batch 15: Train Loss = 0.2810\n",
      "Fold 1 Epoch 24 Batch 20: Train Loss = 0.1918\n",
      "Fold 1, roc = 0.8787, prc = 0.7936\n",
      "Fold 1 Epoch 25 Batch 0: Train Loss = 0.1829\n",
      "Fold 1 Epoch 25 Batch 5: Train Loss = 0.1640\n",
      "Fold 1 Epoch 25 Batch 10: Train Loss = 0.2140\n",
      "Fold 1 Epoch 25 Batch 15: Train Loss = 0.2463\n",
      "Fold 1 Epoch 25 Batch 20: Train Loss = 0.2345\n",
      "Fold 1, roc = 0.8633, prc = 0.7567\n",
      "Fold 1 Epoch 26 Batch 0: Train Loss = 0.2222\n",
      "Fold 1 Epoch 26 Batch 5: Train Loss = 0.2055\n",
      "Fold 1 Epoch 26 Batch 10: Train Loss = 0.2234\n",
      "Fold 1 Epoch 26 Batch 15: Train Loss = 0.1848\n",
      "Fold 1 Epoch 26 Batch 20: Train Loss = 0.1675\n",
      "Fold 1, roc = 0.8787, prc = 0.7920\n",
      "Fold 1 Epoch 27 Batch 0: Train Loss = 0.1375\n",
      "Fold 1 Epoch 27 Batch 5: Train Loss = 0.2212\n",
      "Fold 1 Epoch 27 Batch 10: Train Loss = 0.1926\n",
      "Fold 1 Epoch 27 Batch 15: Train Loss = 0.1878\n",
      "Fold 1 Epoch 27 Batch 20: Train Loss = 0.2619\n",
      "Fold 1, roc = 0.8839, prc = 0.8064\n",
      "Fold 1 Epoch 28 Batch 0: Train Loss = 0.1943\n",
      "Fold 1 Epoch 28 Batch 5: Train Loss = 0.1872\n",
      "Fold 1 Epoch 28 Batch 10: Train Loss = 0.1865\n",
      "Fold 1 Epoch 28 Batch 15: Train Loss = 0.2218\n",
      "Fold 1 Epoch 28 Batch 20: Train Loss = 0.1635\n",
      "Fold 1, roc = 0.8724, prc = 0.7654\n",
      "Fold 1 Epoch 29 Batch 0: Train Loss = 0.2302\n",
      "Fold 1 Epoch 29 Batch 5: Train Loss = 0.2200\n",
      "Fold 1 Epoch 29 Batch 10: Train Loss = 0.2272\n",
      "Fold 1 Epoch 29 Batch 15: Train Loss = 0.2037\n",
      "Fold 1 Epoch 29 Batch 20: Train Loss = 0.2486\n",
      "Fold 1, roc = 0.8368, prc = 0.7210\n",
      "Fold 1 Epoch 30 Batch 0: Train Loss = 0.2169\n",
      "Fold 1 Epoch 30 Batch 5: Train Loss = 0.2635\n",
      "Fold 1 Epoch 30 Batch 10: Train Loss = 0.1471\n",
      "Fold 1 Epoch 30 Batch 15: Train Loss = 0.2183\n",
      "Fold 1 Epoch 30 Batch 20: Train Loss = 0.1948\n",
      "Fold 1, epoch 30: Loss = 0.1998 Valid loss = 0.3980 roc = 0.8760\n",
      "confusion matrix:\n",
      "[[1188   37]\n",
      " [ 163  209]]\n",
      "accuracy = 0.874765157699585\n",
      "precision class 0 = 0.879348635673523\n",
      "precision class 1 = 0.8495935201644897\n",
      "recall class 0 = 0.9697959423065186\n",
      "recall class 1 = 0.5618279576301575\n",
      "AUC of ROC = 0.8760149220978714\n",
      "AUC of PRC = 0.7765565368797986\n",
      "min(+P, Se) = 0.7258064516129032\n",
      "f1_score = 0.6763753841100636\n",
      "Fold 1, roc = 0.8760, prc = 0.7766\n",
      "Fold 1 Epoch 31 Batch 0: Train Loss = 0.2218\n",
      "Fold 1 Epoch 31 Batch 5: Train Loss = 0.2129\n",
      "Fold 1 Epoch 31 Batch 10: Train Loss = 0.2044\n",
      "Fold 1 Epoch 31 Batch 15: Train Loss = 0.2014\n",
      "Fold 1 Epoch 31 Batch 20: Train Loss = 0.1893\n",
      "Fold 1, roc = 0.8736, prc = 0.7728\n",
      "Fold 1 Epoch 32 Batch 0: Train Loss = 0.1798\n",
      "Fold 1 Epoch 32 Batch 5: Train Loss = 0.2220\n",
      "Fold 1 Epoch 32 Batch 10: Train Loss = 0.1855\n",
      "Fold 1 Epoch 32 Batch 15: Train Loss = 0.1899\n",
      "Fold 1 Epoch 32 Batch 20: Train Loss = 0.1546\n",
      "Fold 1, roc = 0.8716, prc = 0.7658\n",
      "Fold 1 Epoch 33 Batch 0: Train Loss = 0.2267\n",
      "Fold 1 Epoch 33 Batch 5: Train Loss = 0.1743\n",
      "Fold 1 Epoch 33 Batch 10: Train Loss = 0.2287\n",
      "Fold 1 Epoch 33 Batch 15: Train Loss = 0.1724\n",
      "Fold 1 Epoch 33 Batch 20: Train Loss = 0.1610\n",
      "Fold 1, roc = 0.8797, prc = 0.7851\n",
      "Fold 1 Epoch 34 Batch 0: Train Loss = 0.1550\n",
      "Fold 1 Epoch 34 Batch 5: Train Loss = 0.2224\n",
      "Fold 1 Epoch 34 Batch 10: Train Loss = 0.1510\n",
      "Fold 1 Epoch 34 Batch 15: Train Loss = 0.1804\n",
      "Fold 1 Epoch 34 Batch 20: Train Loss = 0.1704\n",
      "Fold 1, roc = 0.8836, prc = 0.7967\n",
      "Fold 1 Epoch 35 Batch 0: Train Loss = 0.1817\n",
      "Fold 1 Epoch 35 Batch 5: Train Loss = 0.2231\n",
      "Fold 1 Epoch 35 Batch 10: Train Loss = 0.1832\n",
      "Fold 1 Epoch 35 Batch 15: Train Loss = 0.1684\n",
      "Fold 1 Epoch 35 Batch 20: Train Loss = 0.1961\n",
      "Fold 1, roc = 0.8521, prc = 0.7277\n",
      "Fold 1 Epoch 36 Batch 0: Train Loss = 0.1813\n",
      "Fold 1 Epoch 36 Batch 5: Train Loss = 0.1901\n",
      "Fold 1 Epoch 36 Batch 10: Train Loss = 0.1482\n",
      "Fold 1 Epoch 36 Batch 15: Train Loss = 0.1752\n",
      "Fold 1 Epoch 36 Batch 20: Train Loss = 0.1814\n",
      "Fold 1, roc = 0.8683, prc = 0.7636\n",
      "Fold 1 Epoch 37 Batch 0: Train Loss = 0.1897\n",
      "Fold 1 Epoch 37 Batch 5: Train Loss = 0.1977\n",
      "Fold 1 Epoch 37 Batch 10: Train Loss = 0.1582\n",
      "Fold 1 Epoch 37 Batch 15: Train Loss = 0.2012\n",
      "Fold 1 Epoch 37 Batch 20: Train Loss = 0.1380\n",
      "Fold 1, roc = 0.8786, prc = 0.7738\n",
      "Fold 1 Epoch 38 Batch 0: Train Loss = 0.2035\n",
      "Fold 1 Epoch 38 Batch 5: Train Loss = 0.1614\n",
      "Fold 1 Epoch 38 Batch 10: Train Loss = 0.1851\n",
      "Fold 1 Epoch 38 Batch 15: Train Loss = 0.2419\n",
      "Fold 1 Epoch 38 Batch 20: Train Loss = 0.2214\n",
      "Fold 1, roc = 0.8630, prc = 0.7518\n",
      "Fold 1 Epoch 39 Batch 0: Train Loss = 0.2139\n",
      "Fold 1 Epoch 39 Batch 5: Train Loss = 0.2367\n",
      "Fold 1 Epoch 39 Batch 10: Train Loss = 0.1798\n",
      "Fold 1 Epoch 39 Batch 15: Train Loss = 0.2133\n",
      "Fold 1 Epoch 39 Batch 20: Train Loss = 0.1400\n",
      "Fold 1, roc = 0.8793, prc = 0.7698\n",
      "Fold 1 Epoch 40 Batch 0: Train Loss = 0.1711\n",
      "Fold 1 Epoch 40 Batch 5: Train Loss = 0.2250\n",
      "Fold 1 Epoch 40 Batch 10: Train Loss = 0.2141\n",
      "Fold 1 Epoch 40 Batch 15: Train Loss = 0.2780\n",
      "Fold 1 Epoch 40 Batch 20: Train Loss = 0.1884\n",
      "Fold 1, epoch 40: Loss = 0.2024 Valid loss = 0.4293 roc = 0.8561\n",
      "confusion matrix:\n",
      "[[1179   46]\n",
      " [ 177  195]]\n",
      "accuracy = 0.8603631854057312\n",
      "precision class 0 = 0.8694690465927124\n",
      "precision class 1 = 0.8091286420822144\n",
      "recall class 0 = 0.9624489545822144\n",
      "recall class 1 = 0.524193525314331\n",
      "AUC of ROC = 0.8560884353741497\n",
      "AUC of PRC = 0.7360962482824654\n",
      "min(+P, Se) = 0.6854838709677419\n",
      "f1_score = 0.6362153209438531\n",
      "Fold 1, roc = 0.8561, prc = 0.7361\n",
      "Fold 1 Epoch 41 Batch 0: Train Loss = 0.2333\n",
      "Fold 1 Epoch 41 Batch 5: Train Loss = 0.1471\n",
      "Fold 1 Epoch 41 Batch 10: Train Loss = 0.1978\n",
      "Fold 1 Epoch 41 Batch 15: Train Loss = 0.2274\n",
      "Fold 1 Epoch 41 Batch 20: Train Loss = 0.4062\n",
      "Fold 1, roc = 0.4630, prc = 0.3360\n",
      "Fold 1 Epoch 42 Batch 0: Train Loss = 0.3331\n",
      "Fold 1 Epoch 42 Batch 5: Train Loss = 0.5036\n",
      "Fold 1 Epoch 42 Batch 10: Train Loss = 0.3559\n",
      "Fold 1 Epoch 42 Batch 15: Train Loss = 0.2847\n",
      "Fold 1 Epoch 42 Batch 20: Train Loss = 0.2802\n",
      "Fold 1, roc = 0.7942, prc = 0.6460\n",
      "Fold 1 Epoch 43 Batch 0: Train Loss = 0.2600\n",
      "Fold 1 Epoch 43 Batch 5: Train Loss = 0.2834\n",
      "Fold 1 Epoch 43 Batch 10: Train Loss = 0.2491\n",
      "Fold 1 Epoch 43 Batch 15: Train Loss = 0.2643\n",
      "Fold 1 Epoch 43 Batch 20: Train Loss = 0.2711\n",
      "Fold 1, roc = 0.8270, prc = 0.6508\n",
      "Fold 1 Epoch 44 Batch 0: Train Loss = 0.2052\n",
      "Fold 1 Epoch 44 Batch 5: Train Loss = 0.2448\n",
      "Fold 1 Epoch 44 Batch 10: Train Loss = 0.3185\n",
      "Fold 1 Epoch 44 Batch 15: Train Loss = 0.2225\n",
      "Fold 1 Epoch 44 Batch 20: Train Loss = 0.2292\n",
      "Fold 1, roc = 0.8360, prc = 0.6426\n",
      "Fold 1 Epoch 45 Batch 0: Train Loss = 0.2480\n",
      "Fold 1 Epoch 45 Batch 5: Train Loss = 0.2032\n",
      "Fold 1 Epoch 45 Batch 10: Train Loss = 0.2317\n",
      "Fold 1 Epoch 45 Batch 15: Train Loss = 0.1974\n",
      "Fold 1 Epoch 45 Batch 20: Train Loss = 0.2855\n",
      "Fold 1, roc = 0.8492, prc = 0.7068\n",
      "Fold 1 Epoch 46 Batch 0: Train Loss = 0.1850\n",
      "Fold 1 Epoch 46 Batch 5: Train Loss = 0.2650\n",
      "Fold 1 Epoch 46 Batch 10: Train Loss = 0.1610\n",
      "Fold 1 Epoch 46 Batch 15: Train Loss = 0.2011\n",
      "Fold 1 Epoch 46 Batch 20: Train Loss = 0.1550\n",
      "Fold 1, roc = 0.8597, prc = 0.7140\n",
      "Fold 1 Epoch 47 Batch 0: Train Loss = 0.2426\n",
      "Fold 1 Epoch 47 Batch 5: Train Loss = 0.2106\n",
      "Fold 1 Epoch 47 Batch 10: Train Loss = 0.2017\n",
      "Fold 1 Epoch 47 Batch 15: Train Loss = 0.1938\n",
      "Fold 1 Epoch 47 Batch 20: Train Loss = 0.2556\n",
      "Fold 1, roc = 0.8707, prc = 0.7530\n",
      "Fold 1 Epoch 48 Batch 0: Train Loss = 0.2338\n",
      "Fold 1 Epoch 48 Batch 5: Train Loss = 0.1850\n",
      "Fold 1 Epoch 48 Batch 10: Train Loss = 0.1918\n",
      "Fold 1 Epoch 48 Batch 15: Train Loss = 0.1979\n",
      "Fold 1 Epoch 48 Batch 20: Train Loss = 0.1908\n",
      "Fold 1, roc = 0.8303, prc = 0.6417\n",
      "Fold 1 Epoch 49 Batch 0: Train Loss = 0.1984\n",
      "Fold 1 Epoch 49 Batch 5: Train Loss = 0.1939\n",
      "Fold 1 Epoch 49 Batch 10: Train Loss = 0.2922\n",
      "Fold 1 Epoch 49 Batch 15: Train Loss = 0.1637\n",
      "Fold 1 Epoch 49 Batch 20: Train Loss = 0.2115\n",
      "Fold 1, roc = 0.8351, prc = 0.6772\n",
      "Fold 1 Epoch 50 Batch 0: Train Loss = 0.1666\n",
      "Fold 1 Epoch 50 Batch 5: Train Loss = 0.2073\n",
      "Fold 1 Epoch 50 Batch 10: Train Loss = 0.2181\n",
      "Fold 1 Epoch 50 Batch 15: Train Loss = 0.1694\n",
      "Fold 1 Epoch 50 Batch 20: Train Loss = 0.1919\n",
      "Fold 1, epoch 50: Loss = 0.1997 Valid loss = 0.4409 roc = 0.8575\n",
      "confusion matrix:\n",
      "[[1127   98]\n",
      " [ 134  238]]\n",
      "accuracy = 0.8547276258468628\n",
      "precision class 0 = 0.8937351107597351\n",
      "precision class 1 = 0.7083333134651184\n",
      "recall class 0 = 0.9200000166893005\n",
      "recall class 1 = 0.6397849321365356\n",
      "AUC of ROC = 0.8574720210664911\n",
      "AUC of PRC = 0.7051094389413473\n",
      "min(+P, Se) = 0.6514745308310992\n",
      "f1_score = 0.6723163377207896\n",
      "Fold 1, roc = 0.8575, prc = 0.7051\n",
      "Fold 1 Epoch 51 Batch 0: Train Loss = 0.1608\n",
      "Fold 1 Epoch 51 Batch 5: Train Loss = 0.2052\n",
      "Fold 1 Epoch 51 Batch 10: Train Loss = 0.1951\n",
      "Fold 1 Epoch 51 Batch 15: Train Loss = 0.2162\n",
      "Fold 1 Epoch 51 Batch 20: Train Loss = 0.1517\n",
      "Fold 1, roc = 0.8580, prc = 0.7038\n",
      "Fold 1 Epoch 52 Batch 0: Train Loss = 0.2127\n",
      "Fold 1 Epoch 52 Batch 5: Train Loss = 0.1752\n",
      "Fold 1 Epoch 52 Batch 10: Train Loss = 0.1725\n",
      "Fold 1 Epoch 52 Batch 15: Train Loss = 0.1898\n",
      "Fold 1 Epoch 52 Batch 20: Train Loss = 0.1446\n",
      "Fold 1, roc = 0.8639, prc = 0.7177\n",
      "Fold 1 Epoch 53 Batch 0: Train Loss = 0.2745\n",
      "Fold 1 Epoch 53 Batch 5: Train Loss = 0.1977\n",
      "Fold 1 Epoch 53 Batch 10: Train Loss = 0.1456\n",
      "Fold 1 Epoch 53 Batch 15: Train Loss = 0.2322\n",
      "Fold 1 Epoch 53 Batch 20: Train Loss = 0.1807\n",
      "Fold 1, roc = 0.8640, prc = 0.7126\n",
      "Fold 1 Epoch 54 Batch 0: Train Loss = 0.2240\n",
      "Fold 1 Epoch 54 Batch 5: Train Loss = 0.1700\n",
      "Fold 1 Epoch 54 Batch 10: Train Loss = 0.1999\n",
      "Fold 1 Epoch 54 Batch 15: Train Loss = 0.2113\n",
      "Fold 1 Epoch 54 Batch 20: Train Loss = 0.1747\n",
      "Fold 1, roc = 0.8580, prc = 0.7191\n",
      "Fold 1 Epoch 55 Batch 0: Train Loss = 0.1746\n",
      "Fold 1 Epoch 55 Batch 5: Train Loss = 0.1506\n",
      "Fold 1 Epoch 55 Batch 10: Train Loss = 0.1796\n",
      "Fold 1 Epoch 55 Batch 15: Train Loss = 0.1798\n",
      "Fold 1 Epoch 55 Batch 20: Train Loss = 0.1846\n",
      "Fold 1, roc = 0.8627, prc = 0.7245\n",
      "Fold 1 Epoch 56 Batch 0: Train Loss = 0.1913\n",
      "Fold 1 Epoch 56 Batch 5: Train Loss = 0.1419\n",
      "Fold 1 Epoch 56 Batch 10: Train Loss = 0.1286\n",
      "Fold 1 Epoch 56 Batch 15: Train Loss = 0.1475\n",
      "Fold 1 Epoch 56 Batch 20: Train Loss = 0.2934\n",
      "Fold 1, roc = 0.8476, prc = 0.7073\n",
      "Fold 1 Epoch 57 Batch 0: Train Loss = 0.1753\n",
      "Fold 1 Epoch 57 Batch 5: Train Loss = 0.2034\n",
      "Fold 1 Epoch 57 Batch 10: Train Loss = 0.2491\n",
      "Fold 1 Epoch 57 Batch 15: Train Loss = 0.1463\n",
      "Fold 1 Epoch 57 Batch 20: Train Loss = 0.1625\n",
      "Fold 1, roc = 0.8346, prc = 0.6962\n",
      "Fold 1 Epoch 58 Batch 0: Train Loss = 0.1310\n",
      "Fold 1 Epoch 58 Batch 5: Train Loss = 0.1773\n",
      "Fold 1 Epoch 58 Batch 10: Train Loss = 0.1817\n",
      "Fold 1 Epoch 58 Batch 15: Train Loss = 0.2107\n",
      "Fold 1 Epoch 58 Batch 20: Train Loss = 0.1188\n",
      "Fold 1, roc = 0.8633, prc = 0.7370\n",
      "Fold 1 Epoch 59 Batch 0: Train Loss = 0.1691\n",
      "Fold 1 Epoch 59 Batch 5: Train Loss = 0.2402\n",
      "Fold 1 Epoch 59 Batch 10: Train Loss = 0.1735\n",
      "Fold 1 Epoch 59 Batch 15: Train Loss = 0.1908\n",
      "Fold 1 Epoch 59 Batch 20: Train Loss = 0.1788\n",
      "Fold 1, roc = 0.8703, prc = 0.7549\n",
      "Fold 1 Epoch 60 Batch 0: Train Loss = 0.2088\n",
      "Fold 1 Epoch 60 Batch 5: Train Loss = 0.1670\n",
      "Fold 1 Epoch 60 Batch 10: Train Loss = 0.1878\n",
      "Fold 1 Epoch 60 Batch 15: Train Loss = 0.1567\n",
      "Fold 1 Epoch 60 Batch 20: Train Loss = 0.1416\n",
      "Fold 1, epoch 60: Loss = 0.1833 Valid loss = 0.4286 roc = 0.8598\n",
      "confusion matrix:\n",
      "[[1149   76]\n",
      " [ 142  230]]\n",
      "accuracy = 0.8634940385818481\n",
      "precision class 0 = 0.890007734298706\n",
      "precision class 1 = 0.7516340017318726\n",
      "recall class 0 = 0.9379591941833496\n",
      "recall class 1 = 0.6182795763015747\n",
      "AUC of ROC = 0.8598025016458196\n",
      "AUC of PRC = 0.7401481295667911\n",
      "min(+P, Se) = 0.6693548387096774\n",
      "f1_score = 0.6784660865859274\n",
      "Fold 1, roc = 0.8598, prc = 0.7401\n",
      "Fold 1 Epoch 61 Batch 0: Train Loss = 0.1414\n",
      "Fold 1 Epoch 61 Batch 5: Train Loss = 0.1603\n",
      "Fold 1 Epoch 61 Batch 10: Train Loss = 0.1230\n",
      "Fold 1 Epoch 61 Batch 15: Train Loss = 0.1403\n",
      "Fold 1 Epoch 61 Batch 20: Train Loss = 0.1694\n",
      "Fold 1, roc = 0.8549, prc = 0.7327\n",
      "Fold 1 Epoch 62 Batch 0: Train Loss = 0.1905\n",
      "Fold 1 Epoch 62 Batch 5: Train Loss = 0.1826\n",
      "Fold 1 Epoch 62 Batch 10: Train Loss = 0.1981\n",
      "Fold 1 Epoch 62 Batch 15: Train Loss = 0.1610\n",
      "Fold 1 Epoch 62 Batch 20: Train Loss = 0.1725\n",
      "Fold 1, roc = 0.8550, prc = 0.7384\n",
      "Fold 1 Epoch 63 Batch 0: Train Loss = 0.1585\n",
      "Fold 1 Epoch 63 Batch 5: Train Loss = 0.1457\n",
      "Fold 1 Epoch 63 Batch 10: Train Loss = 0.1619\n",
      "Fold 1 Epoch 63 Batch 15: Train Loss = 0.2131\n",
      "Fold 1 Epoch 63 Batch 20: Train Loss = 0.1850\n",
      "Fold 1, roc = 0.8507, prc = 0.7302\n",
      "Fold 1 Epoch 64 Batch 0: Train Loss = 0.1651\n",
      "Fold 1 Epoch 64 Batch 5: Train Loss = 0.1770\n",
      "Fold 1 Epoch 64 Batch 10: Train Loss = 0.1648\n",
      "Fold 1 Epoch 64 Batch 15: Train Loss = 0.2059\n",
      "Fold 1 Epoch 64 Batch 20: Train Loss = 0.1413\n",
      "Fold 1, roc = 0.8630, prc = 0.7531\n",
      "Fold 1 Epoch 65 Batch 0: Train Loss = 0.1752\n",
      "Fold 1 Epoch 65 Batch 5: Train Loss = 0.1855\n",
      "Fold 1 Epoch 65 Batch 10: Train Loss = 0.1488\n",
      "Fold 1 Epoch 65 Batch 15: Train Loss = 0.1385\n",
      "Fold 1 Epoch 65 Batch 20: Train Loss = 0.2101\n",
      "Fold 1, roc = 0.8499, prc = 0.7269\n",
      "Fold 1 Epoch 66 Batch 0: Train Loss = 0.1520\n",
      "Fold 1 Epoch 66 Batch 5: Train Loss = 0.1893\n",
      "Fold 1 Epoch 66 Batch 10: Train Loss = 0.1986\n",
      "Fold 1 Epoch 66 Batch 15: Train Loss = 0.1917\n",
      "Fold 1 Epoch 66 Batch 20: Train Loss = 0.1807\n",
      "Fold 1, roc = 0.8580, prc = 0.7395\n",
      "Fold 1 Epoch 67 Batch 0: Train Loss = 0.2070\n",
      "Fold 1 Epoch 67 Batch 5: Train Loss = 0.1739\n",
      "Fold 1 Epoch 67 Batch 10: Train Loss = 0.2350\n",
      "Fold 1 Epoch 67 Batch 15: Train Loss = 0.1781\n",
      "Fold 1 Epoch 67 Batch 20: Train Loss = 0.1178\n",
      "Fold 1, roc = 0.8643, prc = 0.7479\n",
      "Fold 1 Epoch 68 Batch 0: Train Loss = 0.1768\n",
      "Fold 1 Epoch 68 Batch 5: Train Loss = 0.2145\n",
      "Fold 1 Epoch 68 Batch 10: Train Loss = 0.1707\n",
      "Fold 1 Epoch 68 Batch 15: Train Loss = 0.1456\n",
      "Fold 1 Epoch 68 Batch 20: Train Loss = 0.1384\n",
      "Fold 1, roc = 0.8407, prc = 0.7163\n",
      "Fold 1 Epoch 69 Batch 0: Train Loss = 0.2297\n",
      "Fold 1 Epoch 69 Batch 5: Train Loss = 0.1767\n",
      "Fold 1 Epoch 69 Batch 10: Train Loss = 0.1749\n",
      "Fold 1 Epoch 69 Batch 15: Train Loss = 0.1453\n",
      "Fold 1 Epoch 69 Batch 20: Train Loss = 0.1987\n",
      "Fold 1, roc = 0.8560, prc = 0.7376\n",
      "Fold 1 Epoch 70 Batch 0: Train Loss = 0.1922\n",
      "Fold 1 Epoch 70 Batch 5: Train Loss = 0.1834\n",
      "Fold 1 Epoch 70 Batch 10: Train Loss = 0.1493\n",
      "Fold 1 Epoch 70 Batch 15: Train Loss = 0.1938\n",
      "Fold 1 Epoch 70 Batch 20: Train Loss = 0.1552\n",
      "Fold 1, epoch 70: Loss = 0.1747 Valid loss = 0.4373 roc = 0.8605\n",
      "confusion matrix:\n",
      "[[1165   60]\n",
      " [ 160  212]]\n",
      "accuracy = 0.8622416853904724\n",
      "precision class 0 = 0.8792452812194824\n",
      "precision class 1 = 0.779411792755127\n",
      "recall class 0 = 0.9510204195976257\n",
      "recall class 1 = 0.5698924660682678\n",
      "AUC of ROC = 0.8604761904761905\n",
      "AUC of PRC = 0.7417875256441439\n",
      "min(+P, Se) = 0.6827956989247311\n",
      "f1_score = 0.6583851275540248\n",
      "Fold 1, roc = 0.8605, prc = 0.7418\n",
      "Fold 1 Epoch 71 Batch 0: Train Loss = 0.1633\n",
      "Fold 1 Epoch 71 Batch 5: Train Loss = 0.1453\n",
      "Fold 1 Epoch 71 Batch 10: Train Loss = 0.1596\n",
      "Fold 1 Epoch 71 Batch 15: Train Loss = 0.2083\n",
      "Fold 1 Epoch 71 Batch 20: Train Loss = 0.1781\n",
      "Fold 1, roc = 0.8633, prc = 0.7490\n",
      "Fold 1 Epoch 72 Batch 0: Train Loss = 0.1326\n",
      "Fold 1 Epoch 72 Batch 5: Train Loss = 0.1833\n",
      "Fold 1 Epoch 72 Batch 10: Train Loss = 0.2325\n",
      "Fold 1 Epoch 72 Batch 15: Train Loss = 0.2099\n",
      "Fold 1 Epoch 72 Batch 20: Train Loss = 0.1974\n",
      "Fold 1, roc = 0.8611, prc = 0.7495\n",
      "Fold 1 Epoch 73 Batch 0: Train Loss = 0.1649\n",
      "Fold 1 Epoch 73 Batch 5: Train Loss = 0.1694\n",
      "Fold 1 Epoch 73 Batch 10: Train Loss = 0.1543\n",
      "Fold 1 Epoch 73 Batch 15: Train Loss = 0.1812\n",
      "Fold 1 Epoch 73 Batch 20: Train Loss = 0.1806\n",
      "Fold 1, roc = 0.8671, prc = 0.7541\n",
      "Fold 1 Epoch 74 Batch 0: Train Loss = 0.1788\n",
      "Fold 1 Epoch 74 Batch 5: Train Loss = 0.1515\n",
      "Fold 1 Epoch 74 Batch 10: Train Loss = 0.1839\n",
      "Fold 1 Epoch 74 Batch 15: Train Loss = 0.0994\n",
      "Fold 1 Epoch 74 Batch 20: Train Loss = 0.1866\n",
      "Fold 1, roc = 0.8631, prc = 0.7496\n",
      "Fold 1 Epoch 75 Batch 0: Train Loss = 0.1612\n",
      "Fold 1 Epoch 75 Batch 5: Train Loss = 0.1563\n",
      "Fold 1 Epoch 75 Batch 10: Train Loss = 0.1325\n",
      "Fold 1 Epoch 75 Batch 15: Train Loss = 0.1574\n",
      "Fold 1 Epoch 75 Batch 20: Train Loss = 0.1831\n",
      "Fold 1, roc = 0.8641, prc = 0.7417\n",
      "Fold 1 Epoch 76 Batch 0: Train Loss = 0.1701\n",
      "Fold 1 Epoch 76 Batch 5: Train Loss = 0.1667\n",
      "Fold 1 Epoch 76 Batch 10: Train Loss = 0.1498\n",
      "Fold 1 Epoch 76 Batch 15: Train Loss = 0.1795\n",
      "Fold 1 Epoch 76 Batch 20: Train Loss = 0.2059\n",
      "Fold 1, roc = 0.8486, prc = 0.7113\n",
      "Fold 1 Epoch 77 Batch 0: Train Loss = 0.1916\n",
      "Fold 1 Epoch 77 Batch 5: Train Loss = 0.1596\n",
      "Fold 1 Epoch 77 Batch 10: Train Loss = 0.2214\n",
      "Fold 1 Epoch 77 Batch 15: Train Loss = 0.1463\n",
      "Fold 1 Epoch 77 Batch 20: Train Loss = 0.1512\n",
      "Fold 1, roc = 0.8792, prc = 0.7685\n",
      "Fold 1 Epoch 78 Batch 0: Train Loss = 0.1601\n",
      "Fold 1 Epoch 78 Batch 5: Train Loss = 0.1743\n",
      "Fold 1 Epoch 78 Batch 10: Train Loss = 0.1383\n",
      "Fold 1 Epoch 78 Batch 15: Train Loss = 0.2213\n",
      "Fold 1 Epoch 78 Batch 20: Train Loss = 0.1480\n",
      "Fold 1, roc = 0.8653, prc = 0.7511\n",
      "Fold 1 Epoch 79 Batch 0: Train Loss = 0.2127\n",
      "Fold 1 Epoch 79 Batch 5: Train Loss = 0.1317\n",
      "Fold 1 Epoch 79 Batch 10: Train Loss = 0.1674\n",
      "Fold 1 Epoch 79 Batch 15: Train Loss = 0.1657\n",
      "Fold 1 Epoch 79 Batch 20: Train Loss = 0.1574\n",
      "Fold 1, roc = 0.8655, prc = 0.7448\n",
      "Fold 1 Epoch 80 Batch 0: Train Loss = 0.1685\n",
      "Fold 1 Epoch 80 Batch 5: Train Loss = 0.1801\n",
      "Fold 1 Epoch 80 Batch 10: Train Loss = 0.1729\n",
      "Fold 1 Epoch 80 Batch 15: Train Loss = 0.1595\n",
      "Fold 1 Epoch 80 Batch 20: Train Loss = 0.1539\n",
      "Fold 1, epoch 80: Loss = 0.1701 Valid loss = 0.4049 roc = 0.8773\n",
      "confusion matrix:\n",
      "[[1169   56]\n",
      " [ 153  219]]\n",
      "accuracy = 0.8691295981407166\n",
      "precision class 0 = 0.8842662572860718\n",
      "precision class 1 = 0.7963636517524719\n",
      "recall class 0 = 0.954285740852356\n",
      "recall class 1 = 0.5887096524238586\n",
      "AUC of ROC = 0.8772525784507352\n",
      "AUC of PRC = 0.7661126203938182\n",
      "min(+P, Se) = 0.7108753315649867\n",
      "f1_score = 0.6769706227281488\n",
      "Fold 1, roc = 0.8773, prc = 0.7661\n",
      "Fold 1 Epoch 81 Batch 0: Train Loss = 0.1968\n",
      "Fold 1 Epoch 81 Batch 5: Train Loss = 0.1665\n",
      "Fold 1 Epoch 81 Batch 10: Train Loss = 0.1461\n",
      "Fold 1 Epoch 81 Batch 15: Train Loss = 0.1405\n",
      "Fold 1 Epoch 81 Batch 20: Train Loss = 0.2001\n",
      "Fold 1, roc = 0.8808, prc = 0.7715\n",
      "Fold 1 Epoch 82 Batch 0: Train Loss = 0.2099\n",
      "Fold 1 Epoch 82 Batch 5: Train Loss = 0.1476\n",
      "Fold 1 Epoch 82 Batch 10: Train Loss = 0.2016\n",
      "Fold 1 Epoch 82 Batch 15: Train Loss = 0.2427\n",
      "Fold 1 Epoch 82 Batch 20: Train Loss = 0.2087\n",
      "Fold 1, roc = 0.8695, prc = 0.7560\n",
      "Fold 1 Epoch 83 Batch 0: Train Loss = 0.1897\n",
      "Fold 1 Epoch 83 Batch 5: Train Loss = 0.1566\n",
      "Fold 1 Epoch 83 Batch 10: Train Loss = 0.1688\n",
      "Fold 1 Epoch 83 Batch 15: Train Loss = 0.1785\n",
      "Fold 1 Epoch 83 Batch 20: Train Loss = 0.2129\n",
      "Fold 1, roc = 0.8708, prc = 0.7623\n",
      "Fold 1 Epoch 84 Batch 0: Train Loss = 0.1635\n",
      "Fold 1 Epoch 84 Batch 5: Train Loss = 0.1745\n",
      "Fold 1 Epoch 84 Batch 10: Train Loss = 0.2098\n",
      "Fold 1 Epoch 84 Batch 15: Train Loss = 0.1317\n",
      "Fold 1 Epoch 84 Batch 20: Train Loss = 0.1693\n",
      "Fold 1, roc = 0.8740, prc = 0.7619\n",
      "Fold 1 Epoch 85 Batch 0: Train Loss = 0.1455\n",
      "Fold 1 Epoch 85 Batch 5: Train Loss = 0.1531\n",
      "Fold 1 Epoch 85 Batch 10: Train Loss = 0.1545\n",
      "Fold 1 Epoch 85 Batch 15: Train Loss = 0.1899\n",
      "Fold 1 Epoch 85 Batch 20: Train Loss = 0.2087\n",
      "Fold 1, roc = 0.8570, prc = 0.7461\n",
      "Fold 1 Epoch 86 Batch 0: Train Loss = 0.1379\n",
      "Fold 1 Epoch 86 Batch 5: Train Loss = 0.1584\n",
      "Fold 1 Epoch 86 Batch 10: Train Loss = 0.1428\n",
      "Fold 1 Epoch 86 Batch 15: Train Loss = 0.1352\n",
      "Fold 1 Epoch 86 Batch 20: Train Loss = 0.1315\n",
      "Fold 1, roc = 0.8716, prc = 0.7621\n",
      "Fold 1 Epoch 87 Batch 0: Train Loss = 0.1551\n",
      "Fold 1 Epoch 87 Batch 5: Train Loss = 0.1833\n",
      "Fold 1 Epoch 87 Batch 10: Train Loss = 0.1743\n",
      "Fold 1 Epoch 87 Batch 15: Train Loss = 0.1867\n",
      "Fold 1 Epoch 87 Batch 20: Train Loss = 0.2047\n",
      "Fold 1, roc = 0.8565, prc = 0.7411\n",
      "Fold 1 Epoch 88 Batch 0: Train Loss = 0.1463\n",
      "Fold 1 Epoch 88 Batch 5: Train Loss = 0.2495\n",
      "Fold 1 Epoch 88 Batch 10: Train Loss = 0.1581\n",
      "Fold 1 Epoch 88 Batch 15: Train Loss = 0.1746\n",
      "Fold 1 Epoch 88 Batch 20: Train Loss = 0.1637\n",
      "Fold 1, roc = 0.8725, prc = 0.7570\n",
      "Fold 1 Epoch 89 Batch 0: Train Loss = 0.1430\n",
      "Fold 1 Epoch 89 Batch 5: Train Loss = 0.1310\n",
      "Fold 1 Epoch 89 Batch 10: Train Loss = 0.1859\n",
      "Fold 1 Epoch 89 Batch 15: Train Loss = 0.1510\n",
      "Fold 1 Epoch 89 Batch 20: Train Loss = 0.1345\n",
      "Fold 1, roc = 0.8577, prc = 0.7287\n",
      "Fold 1 Epoch 90 Batch 0: Train Loss = 0.1945\n",
      "Fold 1 Epoch 90 Batch 5: Train Loss = 0.1974\n",
      "Fold 1 Epoch 90 Batch 10: Train Loss = 0.1543\n",
      "Fold 1 Epoch 90 Batch 15: Train Loss = 0.1849\n",
      "Fold 1 Epoch 90 Batch 20: Train Loss = 0.2207\n",
      "Fold 1, epoch 90: Loss = 0.1694 Valid loss = 0.4500 roc = 0.8606\n",
      "confusion matrix:\n",
      "[[1176   49]\n",
      " [ 179  193]]\n",
      "accuracy = 0.8572323322296143\n",
      "precision class 0 = 0.8678966760635376\n",
      "precision class 1 = 0.797520637512207\n",
      "recall class 0 = 0.9599999785423279\n",
      "recall class 1 = 0.5188171863555908\n",
      "AUC of ROC = 0.8605508009655474\n",
      "AUC of PRC = 0.7295642320677337\n",
      "min(+P, Se) = 0.675603217158177\n",
      "f1_score = 0.6286644745933483\n",
      "Fold 1, roc = 0.8606, prc = 0.7296\n",
      "Fold 1 Epoch 91 Batch 0: Train Loss = 0.1413\n",
      "Fold 1 Epoch 91 Batch 5: Train Loss = 0.1482\n",
      "Fold 1 Epoch 91 Batch 10: Train Loss = 0.1470\n",
      "Fold 1 Epoch 91 Batch 15: Train Loss = 0.1864\n",
      "Fold 1 Epoch 91 Batch 20: Train Loss = 0.1793\n",
      "Fold 1, roc = 0.8337, prc = 0.6954\n",
      "Fold 1 Epoch 92 Batch 0: Train Loss = 0.1490\n",
      "Fold 1 Epoch 92 Batch 5: Train Loss = 0.2155\n",
      "Fold 1 Epoch 92 Batch 10: Train Loss = 0.1962\n",
      "Fold 1 Epoch 92 Batch 15: Train Loss = 0.1828\n",
      "Fold 1 Epoch 92 Batch 20: Train Loss = 0.1389\n",
      "Fold 1, roc = 0.8514, prc = 0.7135\n",
      "Fold 1 Epoch 93 Batch 0: Train Loss = 0.1541\n",
      "Fold 1 Epoch 93 Batch 5: Train Loss = 0.1862\n",
      "Fold 1 Epoch 93 Batch 10: Train Loss = 0.1237\n",
      "Fold 1 Epoch 93 Batch 15: Train Loss = 0.0982\n",
      "Fold 1 Epoch 93 Batch 20: Train Loss = 0.1577\n",
      "Fold 1, roc = 0.8401, prc = 0.7008\n",
      "Fold 1 Epoch 94 Batch 0: Train Loss = 0.1700\n",
      "Fold 1 Epoch 94 Batch 5: Train Loss = 0.1525\n",
      "Fold 1 Epoch 94 Batch 10: Train Loss = 0.1504\n",
      "Fold 1 Epoch 94 Batch 15: Train Loss = 0.1463\n",
      "Fold 1 Epoch 94 Batch 20: Train Loss = 0.1440\n",
      "Fold 1, roc = 0.8254, prc = 0.6743\n",
      "Fold 1 Epoch 95 Batch 0: Train Loss = 0.1661\n",
      "Fold 1 Epoch 95 Batch 5: Train Loss = 0.1378\n",
      "Fold 1 Epoch 95 Batch 10: Train Loss = 0.1736\n",
      "Fold 1 Epoch 95 Batch 15: Train Loss = 0.1652\n",
      "Fold 1 Epoch 95 Batch 20: Train Loss = 0.1987\n",
      "Fold 1, roc = 0.8662, prc = 0.7419\n",
      "Fold 1 Epoch 96 Batch 0: Train Loss = 0.1648\n",
      "Fold 1 Epoch 96 Batch 5: Train Loss = 0.1777\n",
      "Fold 1 Epoch 96 Batch 10: Train Loss = 0.1892\n",
      "Fold 1 Epoch 96 Batch 15: Train Loss = 0.1560\n",
      "Fold 1 Epoch 96 Batch 20: Train Loss = 0.1694\n",
      "Fold 1, roc = 0.8601, prc = 0.7182\n",
      "Fold 1 Epoch 97 Batch 0: Train Loss = 0.1703\n",
      "Fold 1 Epoch 97 Batch 5: Train Loss = 0.1730\n",
      "Fold 1 Epoch 97 Batch 10: Train Loss = 0.1328\n",
      "Fold 1 Epoch 97 Batch 15: Train Loss = 0.1301\n",
      "Fold 1 Epoch 97 Batch 20: Train Loss = 0.1823\n",
      "Fold 1, roc = 0.8537, prc = 0.7172\n",
      "Fold 1 Epoch 98 Batch 0: Train Loss = 0.1396\n",
      "Fold 1 Epoch 98 Batch 5: Train Loss = 0.1773\n",
      "Fold 1 Epoch 98 Batch 10: Train Loss = 0.2085\n",
      "Fold 1 Epoch 98 Batch 15: Train Loss = 0.1625\n",
      "Fold 1 Epoch 98 Batch 20: Train Loss = 0.1450\n",
      "Fold 1, roc = 0.8633, prc = 0.7355\n",
      "Fold 1 Epoch 99 Batch 0: Train Loss = 0.1877\n",
      "Fold 1 Epoch 99 Batch 5: Train Loss = 0.1762\n",
      "Fold 1 Epoch 99 Batch 10: Train Loss = 0.1572\n",
      "Fold 1 Epoch 99 Batch 15: Train Loss = 0.1153\n",
      "Fold 1 Epoch 99 Batch 20: Train Loss = 0.1655\n",
      "Fold 1, roc = 0.8578, prc = 0.7266\n",
      "Fold 1 Epoch 100 Batch 0: Train Loss = 0.1747\n",
      "Fold 1 Epoch 100 Batch 5: Train Loss = 0.1314\n",
      "Fold 1 Epoch 100 Batch 10: Train Loss = 0.2075\n",
      "Fold 1 Epoch 100 Batch 15: Train Loss = 0.1214\n",
      "Fold 1 Epoch 100 Batch 20: Train Loss = 0.1326\n",
      "Fold 1, epoch 100: Loss = 0.1640 Valid loss = 0.4501 roc = 0.8657\n",
      "confusion matrix:\n",
      "[[1172   53]\n",
      " [ 166  206]]\n",
      "accuracy = 0.8628678917884827\n",
      "precision class 0 = 0.8759342432022095\n",
      "precision class 1 = 0.7953668236732483\n",
      "recall class 0 = 0.9567347168922424\n",
      "recall class 1 = 0.5537634491920471\n",
      "AUC of ROC = 0.8656703971911345\n",
      "AUC of PRC = 0.7416211417853734\n",
      "min(+P, Se) = 0.6935483870967742\n",
      "f1_score = 0.6529318695292478\n",
      "Fold 1, roc = 0.8657, prc = 0.7416\n",
      "Fold 1 Epoch 101 Batch 0: Train Loss = 0.1583\n",
      "Fold 1 Epoch 101 Batch 5: Train Loss = 0.1441\n",
      "Fold 1 Epoch 101 Batch 10: Train Loss = 0.1014\n",
      "Fold 1 Epoch 101 Batch 15: Train Loss = 0.2303\n",
      "Fold 1 Epoch 101 Batch 20: Train Loss = 0.1763\n",
      "Fold 1, roc = 0.8435, prc = 0.7046\n",
      "Fold 1 Epoch 102 Batch 0: Train Loss = 0.1351\n",
      "Fold 1 Epoch 102 Batch 5: Train Loss = 0.1596\n",
      "Fold 1 Epoch 102 Batch 10: Train Loss = 0.1553\n",
      "Fold 1 Epoch 102 Batch 15: Train Loss = 0.1083\n",
      "Fold 1 Epoch 102 Batch 20: Train Loss = 0.1509\n",
      "Fold 1, roc = 0.8443, prc = 0.7160\n",
      "Fold 1 Epoch 103 Batch 0: Train Loss = 0.1678\n",
      "Fold 1 Epoch 103 Batch 5: Train Loss = 0.1862\n",
      "Fold 1 Epoch 103 Batch 10: Train Loss = 0.1310\n",
      "Fold 1 Epoch 103 Batch 15: Train Loss = 0.1626\n",
      "Fold 1 Epoch 103 Batch 20: Train Loss = 0.1491\n",
      "Fold 1, roc = 0.8230, prc = 0.6797\n",
      "Fold 1 Epoch 104 Batch 0: Train Loss = 0.1682\n",
      "Fold 1 Epoch 104 Batch 5: Train Loss = 0.1680\n",
      "Fold 1 Epoch 104 Batch 10: Train Loss = 0.1713\n",
      "Fold 1 Epoch 104 Batch 15: Train Loss = 0.1641\n",
      "Fold 1 Epoch 104 Batch 20: Train Loss = 0.1512\n",
      "Fold 1, roc = 0.8454, prc = 0.6992\n",
      "Fold 1 Epoch 105 Batch 0: Train Loss = 0.1179\n",
      "Fold 1 Epoch 105 Batch 5: Train Loss = 0.2133\n",
      "Fold 1 Epoch 105 Batch 10: Train Loss = 0.1460\n",
      "Fold 1 Epoch 105 Batch 15: Train Loss = 0.1705\n",
      "Fold 1 Epoch 105 Batch 20: Train Loss = 0.1885\n",
      "Fold 1, roc = 0.8375, prc = 0.6868\n",
      "Fold 1 Epoch 106 Batch 0: Train Loss = 0.1324\n",
      "Fold 1 Epoch 106 Batch 5: Train Loss = 0.2115\n",
      "Fold 1 Epoch 106 Batch 10: Train Loss = 0.1408\n",
      "Fold 1 Epoch 106 Batch 15: Train Loss = 0.1538\n",
      "Fold 1 Epoch 106 Batch 20: Train Loss = 0.1839\n",
      "Fold 1, roc = 0.8611, prc = 0.7328\n",
      "Fold 1 Epoch 107 Batch 0: Train Loss = 0.1546\n",
      "Fold 1 Epoch 107 Batch 5: Train Loss = 0.1988\n",
      "Fold 1 Epoch 107 Batch 10: Train Loss = 0.1838\n",
      "Fold 1 Epoch 107 Batch 15: Train Loss = 0.1511\n",
      "Fold 1 Epoch 107 Batch 20: Train Loss = 0.1454\n",
      "Fold 1, roc = 0.8411, prc = 0.7042\n",
      "Fold 1 Epoch 108 Batch 0: Train Loss = 0.1569\n",
      "Fold 1 Epoch 108 Batch 5: Train Loss = 0.1589\n",
      "Fold 1 Epoch 108 Batch 10: Train Loss = 0.1405\n",
      "Fold 1 Epoch 108 Batch 15: Train Loss = 0.2142\n",
      "Fold 1 Epoch 108 Batch 20: Train Loss = 0.1279\n",
      "Fold 1, roc = 0.8574, prc = 0.7307\n",
      "Fold 1 Epoch 109 Batch 0: Train Loss = 0.1940\n",
      "Fold 1 Epoch 109 Batch 5: Train Loss = 0.1740\n",
      "Fold 1 Epoch 109 Batch 10: Train Loss = 0.1489\n",
      "Fold 1 Epoch 109 Batch 15: Train Loss = 0.1154\n",
      "Fold 1 Epoch 109 Batch 20: Train Loss = 0.1911\n",
      "Fold 1, roc = 0.8394, prc = 0.6952\n",
      "Fold 1 Epoch 110 Batch 0: Train Loss = 0.1267\n",
      "Fold 1 Epoch 110 Batch 5: Train Loss = 0.1521\n",
      "Fold 1 Epoch 110 Batch 10: Train Loss = 0.1674\n",
      "Fold 1 Epoch 110 Batch 15: Train Loss = 0.1668\n",
      "Fold 1 Epoch 110 Batch 20: Train Loss = 0.1635\n",
      "Fold 1, epoch 110: Loss = 0.1569 Valid loss = 0.5171 roc = 0.8469\n",
      "confusion matrix:\n",
      "[[1173   52]\n",
      " [ 182  190]]\n",
      "accuracy = 0.8534752726554871\n",
      "precision class 0 = 0.8656826615333557\n",
      "precision class 1 = 0.7851239442825317\n",
      "recall class 0 = 0.9575510025024414\n",
      "recall class 1 = 0.5107526779174805\n",
      "AUC of ROC = 0.84687952600395\n",
      "AUC of PRC = 0.7048461357568195\n",
      "min(+P, Se) = 0.6631016042780749\n",
      "f1_score = 0.6188924935749706\n",
      "Fold 1, roc = 0.8469, prc = 0.7048\n",
      "Fold 1 Epoch 111 Batch 0: Train Loss = 0.1227\n",
      "Fold 1 Epoch 111 Batch 5: Train Loss = 0.1676\n",
      "Fold 1 Epoch 111 Batch 10: Train Loss = 0.1562\n",
      "Fold 1 Epoch 111 Batch 15: Train Loss = 0.1643\n",
      "Fold 1 Epoch 111 Batch 20: Train Loss = 0.2013\n",
      "Fold 1, roc = 0.8022, prc = 0.6571\n",
      "Fold 1 Epoch 112 Batch 0: Train Loss = 0.1681\n",
      "Fold 1 Epoch 112 Batch 5: Train Loss = 0.1305\n",
      "Fold 1 Epoch 112 Batch 10: Train Loss = 0.1463\n",
      "Fold 1 Epoch 112 Batch 15: Train Loss = 0.1389\n",
      "Fold 1 Epoch 112 Batch 20: Train Loss = 0.1658\n",
      "Fold 1, roc = 0.8312, prc = 0.6464\n",
      "Fold 1 Epoch 113 Batch 0: Train Loss = 0.1521\n",
      "Fold 1 Epoch 113 Batch 5: Train Loss = 0.1792\n",
      "Fold 1 Epoch 113 Batch 10: Train Loss = 0.1632\n",
      "Fold 1 Epoch 113 Batch 15: Train Loss = 0.1280\n",
      "Fold 1 Epoch 113 Batch 20: Train Loss = 0.2087\n",
      "Fold 1, roc = 0.8479, prc = 0.7091\n",
      "Fold 1 Epoch 114 Batch 0: Train Loss = 0.1501\n",
      "Fold 1 Epoch 114 Batch 5: Train Loss = 0.1715\n",
      "Fold 1 Epoch 114 Batch 10: Train Loss = 0.1307\n",
      "Fold 1 Epoch 114 Batch 15: Train Loss = 0.2214\n",
      "Fold 1 Epoch 114 Batch 20: Train Loss = 0.1030\n",
      "Fold 1, roc = 0.8057, prc = 0.6679\n",
      "Fold 1 Epoch 115 Batch 0: Train Loss = 0.1875\n",
      "Fold 1 Epoch 115 Batch 5: Train Loss = 0.1862\n",
      "Fold 1 Epoch 115 Batch 10: Train Loss = 0.1407\n",
      "Fold 1 Epoch 115 Batch 15: Train Loss = 0.1511\n",
      "Fold 1 Epoch 115 Batch 20: Train Loss = 0.1277\n",
      "Fold 1, roc = 0.8515, prc = 0.7164\n",
      "Fold 1 Epoch 116 Batch 0: Train Loss = 0.1302\n",
      "Fold 1 Epoch 116 Batch 5: Train Loss = 0.1967\n",
      "Fold 1 Epoch 116 Batch 10: Train Loss = 0.1216\n",
      "Fold 1 Epoch 116 Batch 15: Train Loss = 0.1647\n",
      "Fold 1 Epoch 116 Batch 20: Train Loss = 0.1384\n",
      "Fold 1, roc = 0.8511, prc = 0.7111\n",
      "Fold 1 Epoch 117 Batch 0: Train Loss = 0.1233\n",
      "Fold 1 Epoch 117 Batch 5: Train Loss = 0.1290\n",
      "Fold 1 Epoch 117 Batch 10: Train Loss = 0.1836\n",
      "Fold 1 Epoch 117 Batch 15: Train Loss = 0.1195\n",
      "Fold 1 Epoch 117 Batch 20: Train Loss = 0.1846\n",
      "Fold 1, roc = 0.8428, prc = 0.6955\n",
      "Fold 1 Epoch 118 Batch 0: Train Loss = 0.1473\n",
      "Fold 1 Epoch 118 Batch 5: Train Loss = 0.1330\n",
      "Fold 1 Epoch 118 Batch 10: Train Loss = 0.1576\n",
      "Fold 1 Epoch 118 Batch 15: Train Loss = 0.1751\n",
      "Fold 1 Epoch 118 Batch 20: Train Loss = 0.1643\n",
      "Fold 1, roc = 0.8436, prc = 0.6897\n",
      "Fold 1 Epoch 119 Batch 0: Train Loss = 0.1737\n",
      "Fold 1 Epoch 119 Batch 5: Train Loss = 0.1844\n",
      "Fold 1 Epoch 119 Batch 10: Train Loss = 0.1421\n",
      "Fold 1 Epoch 119 Batch 15: Train Loss = 0.1353\n",
      "Fold 1 Epoch 119 Batch 20: Train Loss = 0.1213\n",
      "Fold 1, roc = 0.8421, prc = 0.6926\n",
      "Fold 1 Epoch 120 Batch 0: Train Loss = 0.1785\n",
      "Fold 1 Epoch 120 Batch 5: Train Loss = 0.1568\n",
      "Fold 1 Epoch 120 Batch 10: Train Loss = 0.1357\n",
      "Fold 1 Epoch 120 Batch 15: Train Loss = 0.1828\n",
      "Fold 1 Epoch 120 Batch 20: Train Loss = 0.1567\n",
      "Fold 1, epoch 120: Loss = 0.1535 Valid loss = 0.5034 roc = 0.8603\n",
      "confusion matrix:\n",
      "[[1171   54]\n",
      " [ 176  196]]\n",
      "accuracy = 0.8559799790382385\n",
      "precision class 0 = 0.8693392872810364\n",
      "precision class 1 = 0.7839999794960022\n",
      "recall class 0 = 0.9559183716773987\n",
      "recall class 1 = 0.5268816947937012\n",
      "AUC of ROC = 0.860344524906737\n",
      "AUC of PRC = 0.7046952466939032\n",
      "min(+P, Se) = 0.6747311827956989\n",
      "f1_score = 0.630225084077211\n",
      "Fold 1, roc = 0.8603, prc = 0.7047\n",
      "Fold 1 Epoch 121 Batch 0: Train Loss = 0.1495\n",
      "Fold 1 Epoch 121 Batch 5: Train Loss = 0.1585\n",
      "Fold 1 Epoch 121 Batch 10: Train Loss = 0.1681\n",
      "Fold 1 Epoch 121 Batch 15: Train Loss = 0.1280\n",
      "Fold 1 Epoch 121 Batch 20: Train Loss = 0.1618\n",
      "Fold 1, roc = 0.8310, prc = 0.6811\n",
      "Fold 1 Epoch 122 Batch 0: Train Loss = 0.1260\n",
      "Fold 1 Epoch 122 Batch 5: Train Loss = 0.1399\n",
      "Fold 1 Epoch 122 Batch 10: Train Loss = 0.1446\n",
      "Fold 1 Epoch 122 Batch 15: Train Loss = 0.1581\n",
      "Fold 1 Epoch 122 Batch 20: Train Loss = 0.1730\n",
      "Fold 1, roc = 0.8283, prc = 0.6681\n",
      "Fold 1 Epoch 123 Batch 0: Train Loss = 0.1415\n",
      "Fold 1 Epoch 123 Batch 5: Train Loss = 0.1441\n",
      "Fold 1 Epoch 123 Batch 10: Train Loss = 0.1314\n",
      "Fold 1 Epoch 123 Batch 15: Train Loss = 0.1235\n",
      "Fold 1 Epoch 123 Batch 20: Train Loss = 0.1578\n",
      "Fold 1, roc = 0.8140, prc = 0.6493\n",
      "Fold 1 Epoch 124 Batch 0: Train Loss = 0.1619\n",
      "Fold 1 Epoch 124 Batch 5: Train Loss = 0.1731\n",
      "Fold 1 Epoch 124 Batch 10: Train Loss = 0.1538\n",
      "Fold 1 Epoch 124 Batch 15: Train Loss = 0.1442\n",
      "Fold 1 Epoch 124 Batch 20: Train Loss = 0.1756\n",
      "Fold 1, roc = 0.8403, prc = 0.6759\n",
      "Fold 1 Epoch 125 Batch 0: Train Loss = 0.1728\n",
      "Fold 1 Epoch 125 Batch 5: Train Loss = 0.1154\n",
      "Fold 1 Epoch 125 Batch 10: Train Loss = 0.1443\n",
      "Fold 1 Epoch 125 Batch 15: Train Loss = 0.1857\n",
      "Fold 1 Epoch 125 Batch 20: Train Loss = 0.2130\n",
      "Fold 1, roc = 0.8260, prc = 0.6560\n",
      "Fold 1 Epoch 126 Batch 0: Train Loss = 0.1383\n",
      "Fold 1 Epoch 126 Batch 5: Train Loss = 0.1510\n",
      "Fold 1 Epoch 126 Batch 10: Train Loss = 0.2066\n",
      "Fold 1 Epoch 126 Batch 15: Train Loss = 0.1522\n",
      "Fold 1 Epoch 126 Batch 20: Train Loss = 0.1980\n",
      "Fold 1, roc = 0.8300, prc = 0.6910\n",
      "Fold 1 Epoch 127 Batch 0: Train Loss = 0.1242\n",
      "Fold 1 Epoch 127 Batch 5: Train Loss = 0.1583\n",
      "Fold 1 Epoch 127 Batch 10: Train Loss = 0.1686\n",
      "Fold 1 Epoch 127 Batch 15: Train Loss = 0.1382\n",
      "Fold 1 Epoch 127 Batch 20: Train Loss = 0.1337\n",
      "Fold 1, roc = 0.8042, prc = 0.6459\n",
      "Fold 1 Epoch 128 Batch 0: Train Loss = 0.1318\n",
      "Fold 1 Epoch 128 Batch 5: Train Loss = 0.1446\n",
      "Fold 1 Epoch 128 Batch 10: Train Loss = 0.1687\n",
      "Fold 1 Epoch 128 Batch 15: Train Loss = 0.1498\n",
      "Fold 1 Epoch 128 Batch 20: Train Loss = 0.1544\n",
      "Fold 1, roc = 0.8161, prc = 0.6469\n",
      "Fold 1 Epoch 129 Batch 0: Train Loss = 0.1461\n",
      "Fold 1 Epoch 129 Batch 5: Train Loss = 0.1684\n",
      "Fold 1 Epoch 129 Batch 10: Train Loss = 0.1612\n",
      "Fold 1 Epoch 129 Batch 15: Train Loss = 0.1556\n",
      "Fold 1 Epoch 129 Batch 20: Train Loss = 0.1375\n",
      "Fold 1, roc = 0.7999, prc = 0.6285\n",
      "Fold 1 Epoch 130 Batch 0: Train Loss = 0.1699\n",
      "Fold 1 Epoch 130 Batch 5: Train Loss = 0.1925\n",
      "Fold 1 Epoch 130 Batch 10: Train Loss = 0.0950\n",
      "Fold 1 Epoch 130 Batch 15: Train Loss = 0.1641\n",
      "Fold 1 Epoch 130 Batch 20: Train Loss = 0.1752\n",
      "Fold 1, epoch 130: Loss = 0.1558 Valid loss = 0.6406 roc = 0.7938\n",
      "confusion matrix:\n",
      "[[1161   64]\n",
      " [ 206  166]]\n",
      "accuracy = 0.8309329748153687\n",
      "precision class 0 = 0.8493050336837769\n",
      "precision class 1 = 0.7217391133308411\n",
      "recall class 0 = 0.9477550983428955\n",
      "recall class 1 = 0.4462365508079529\n",
      "AUC of ROC = 0.7937546631555847\n",
      "AUC of PRC = 0.6124469697149548\n",
      "min(+P, Se) = 0.5833333333333334\n",
      "f1_score = 0.5514950052549599\n",
      "Fold 1, roc = 0.7938, prc = 0.6124\n",
      "Fold 1 Epoch 131 Batch 0: Train Loss = 0.1367\n",
      "Fold 1 Epoch 131 Batch 5: Train Loss = 0.1986\n",
      "Fold 1 Epoch 131 Batch 10: Train Loss = 0.1230\n",
      "Fold 1 Epoch 131 Batch 15: Train Loss = 0.1628\n",
      "Fold 1 Epoch 131 Batch 20: Train Loss = 0.1304\n",
      "Fold 1, roc = 0.7809, prc = 0.6148\n",
      "Fold 1 Epoch 132 Batch 0: Train Loss = 0.1387\n",
      "Fold 1 Epoch 132 Batch 5: Train Loss = 0.2005\n",
      "Fold 1 Epoch 132 Batch 10: Train Loss = 0.1309\n",
      "Fold 1 Epoch 132 Batch 15: Train Loss = 0.1678\n",
      "Fold 1 Epoch 132 Batch 20: Train Loss = 0.1655\n",
      "Fold 1, roc = 0.8172, prc = 0.6359\n",
      "Fold 1 Epoch 133 Batch 0: Train Loss = 0.1293\n",
      "Fold 1 Epoch 133 Batch 5: Train Loss = 0.1873\n",
      "Fold 1 Epoch 133 Batch 10: Train Loss = 0.1116\n",
      "Fold 1 Epoch 133 Batch 15: Train Loss = 0.1552\n",
      "Fold 1 Epoch 133 Batch 20: Train Loss = 0.1699\n",
      "Fold 1, roc = 0.8221, prc = 0.6541\n",
      "Fold 1 Epoch 134 Batch 0: Train Loss = 0.1811\n",
      "Fold 1 Epoch 134 Batch 5: Train Loss = 0.1764\n",
      "Fold 1 Epoch 134 Batch 10: Train Loss = 0.1388\n",
      "Fold 1 Epoch 134 Batch 15: Train Loss = 0.1341\n",
      "Fold 1 Epoch 134 Batch 20: Train Loss = 0.1546\n",
      "Fold 1, roc = 0.8396, prc = 0.6978\n",
      "Fold 1 Epoch 135 Batch 0: Train Loss = 0.1084\n",
      "Fold 1 Epoch 135 Batch 5: Train Loss = 0.1709\n",
      "Fold 1 Epoch 135 Batch 10: Train Loss = 0.1634\n",
      "Fold 1 Epoch 135 Batch 15: Train Loss = 0.1548\n",
      "Fold 1 Epoch 135 Batch 20: Train Loss = 0.1607\n",
      "Fold 1, roc = 0.8320, prc = 0.6711\n",
      "Fold 1 Epoch 136 Batch 0: Train Loss = 0.1248\n",
      "Fold 1 Epoch 136 Batch 5: Train Loss = 0.1786\n",
      "Fold 1 Epoch 136 Batch 10: Train Loss = 0.1691\n",
      "Fold 1 Epoch 136 Batch 15: Train Loss = 0.1774\n",
      "Fold 1 Epoch 136 Batch 20: Train Loss = 0.1281\n",
      "Fold 1, roc = 0.8302, prc = 0.6858\n",
      "Fold 1 Epoch 137 Batch 0: Train Loss = 0.2274\n",
      "Fold 1 Epoch 137 Batch 5: Train Loss = 0.1198\n",
      "Fold 1 Epoch 137 Batch 10: Train Loss = 0.1878\n",
      "Fold 1 Epoch 137 Batch 15: Train Loss = 0.1441\n",
      "Fold 1 Epoch 137 Batch 20: Train Loss = 0.1846\n",
      "Fold 1, roc = 0.8266, prc = 0.6598\n",
      "Fold 1 Epoch 138 Batch 0: Train Loss = 0.1419\n",
      "Fold 1 Epoch 138 Batch 5: Train Loss = 0.1627\n",
      "Fold 1 Epoch 138 Batch 10: Train Loss = 0.1654\n",
      "Fold 1 Epoch 138 Batch 15: Train Loss = 0.1720\n",
      "Fold 1 Epoch 138 Batch 20: Train Loss = 0.1517\n",
      "Fold 1, roc = 0.8104, prc = 0.6249\n",
      "Fold 1 Epoch 139 Batch 0: Train Loss = 0.1756\n",
      "Fold 1 Epoch 139 Batch 5: Train Loss = 0.1867\n",
      "Fold 1 Epoch 139 Batch 10: Train Loss = 0.1190\n",
      "Fold 1 Epoch 139 Batch 15: Train Loss = 0.1740\n",
      "Fold 1 Epoch 139 Batch 20: Train Loss = 0.1944\n",
      "Fold 1, roc = 0.8345, prc = 0.6788\n",
      "Fold 1 Epoch 140 Batch 0: Train Loss = 0.1152\n",
      "Fold 1 Epoch 140 Batch 5: Train Loss = 0.1279\n",
      "Fold 1 Epoch 140 Batch 10: Train Loss = 0.1707\n",
      "Fold 1 Epoch 140 Batch 15: Train Loss = 0.1347\n",
      "Fold 1 Epoch 140 Batch 20: Train Loss = 0.2012\n",
      "Fold 1, epoch 140: Loss = 0.1494 Valid loss = 0.6335 roc = 0.7951\n",
      "confusion matrix:\n",
      "[[1144   81]\n",
      " [ 194  178]]\n",
      "accuracy = 0.8278021216392517\n",
      "precision class 0 = 0.8550074696540833\n",
      "precision class 1 = 0.6872586607933044\n",
      "recall class 0 = 0.9338775277137756\n",
      "recall class 1 = 0.4784946143627167\n",
      "AUC of ROC = 0.7951437349133201\n",
      "AUC of PRC = 0.6180710046319456\n",
      "min(+P, Se) = 0.5802139037433155\n",
      "f1_score = 0.5641838342280638\n",
      "Fold 1, roc = 0.7951, prc = 0.6181\n",
      "Fold 1 Epoch 141 Batch 0: Train Loss = 0.1715\n",
      "Fold 1 Epoch 141 Batch 5: Train Loss = 0.1241\n",
      "Fold 1 Epoch 141 Batch 10: Train Loss = 0.1380\n",
      "Fold 1 Epoch 141 Batch 15: Train Loss = 0.1433\n",
      "Fold 1 Epoch 141 Batch 20: Train Loss = 0.1306\n",
      "Fold 1, roc = 0.8120, prc = 0.6334\n",
      "Fold 1 Epoch 142 Batch 0: Train Loss = 0.1411\n",
      "Fold 1 Epoch 142 Batch 5: Train Loss = 0.1148\n",
      "Fold 1 Epoch 142 Batch 10: Train Loss = 0.1014\n",
      "Fold 1 Epoch 142 Batch 15: Train Loss = 0.1466\n",
      "Fold 1 Epoch 142 Batch 20: Train Loss = 0.1296\n",
      "Fold 1, roc = 0.7944, prc = 0.6277\n",
      "Fold 1 Epoch 143 Batch 0: Train Loss = 0.1164\n",
      "Fold 1 Epoch 143 Batch 5: Train Loss = 0.1711\n",
      "Fold 1 Epoch 143 Batch 10: Train Loss = 0.1637\n",
      "Fold 1 Epoch 143 Batch 15: Train Loss = 0.1263\n",
      "Fold 1 Epoch 143 Batch 20: Train Loss = 0.1607\n",
      "Fold 1, roc = 0.8120, prc = 0.6446\n",
      "Fold 1 Epoch 144 Batch 0: Train Loss = 0.1741\n",
      "Fold 1 Epoch 144 Batch 5: Train Loss = 0.1601\n",
      "Fold 1 Epoch 144 Batch 10: Train Loss = 0.1327\n",
      "Fold 1 Epoch 144 Batch 15: Train Loss = 0.1605\n",
      "Fold 1 Epoch 144 Batch 20: Train Loss = 0.1795\n",
      "Fold 1, roc = 0.8223, prc = 0.6650\n",
      "Fold 1 Epoch 145 Batch 0: Train Loss = 0.1498\n",
      "Fold 1 Epoch 145 Batch 5: Train Loss = 0.1391\n",
      "Fold 1 Epoch 145 Batch 10: Train Loss = 0.1862\n",
      "Fold 1 Epoch 145 Batch 15: Train Loss = 0.1858\n",
      "Fold 1 Epoch 145 Batch 20: Train Loss = 0.2028\n",
      "Fold 1, roc = 0.8268, prc = 0.6799\n",
      "Fold 1 Epoch 146 Batch 0: Train Loss = 0.1217\n",
      "Fold 1 Epoch 146 Batch 5: Train Loss = 0.1754\n",
      "Fold 1 Epoch 146 Batch 10: Train Loss = 0.1539\n",
      "Fold 1 Epoch 146 Batch 15: Train Loss = 0.1127\n",
      "Fold 1 Epoch 146 Batch 20: Train Loss = 0.1472\n",
      "Fold 1, roc = 0.8364, prc = 0.6888\n",
      "Fold 1 Epoch 147 Batch 0: Train Loss = 0.1374\n",
      "Fold 1 Epoch 147 Batch 5: Train Loss = 0.1292\n",
      "Fold 1 Epoch 147 Batch 10: Train Loss = 0.1096\n",
      "Fold 1 Epoch 147 Batch 15: Train Loss = 0.1563\n",
      "Fold 1 Epoch 147 Batch 20: Train Loss = 0.1263\n",
      "Fold 1, roc = 0.8112, prc = 0.6689\n",
      "Fold 1 Epoch 148 Batch 0: Train Loss = 0.1650\n",
      "Fold 1 Epoch 148 Batch 5: Train Loss = 0.1480\n",
      "Fold 1 Epoch 148 Batch 10: Train Loss = 0.1646\n",
      "Fold 1 Epoch 148 Batch 15: Train Loss = 0.1162\n",
      "Fold 1 Epoch 148 Batch 20: Train Loss = 0.1188\n",
      "Fold 1, roc = 0.8115, prc = 0.6673\n",
      "Fold 1 Epoch 149 Batch 0: Train Loss = 0.2387\n",
      "Fold 1 Epoch 149 Batch 5: Train Loss = 0.1665\n",
      "Fold 1 Epoch 149 Batch 10: Train Loss = 0.1601\n",
      "Fold 1 Epoch 149 Batch 15: Train Loss = 0.1871\n",
      "Fold 1 Epoch 149 Batch 20: Train Loss = 0.1256\n",
      "Fold 1, roc = 0.8247, prc = 0.6859\n",
      "Training data size: 6190, Validation data size: 1673\n",
      "Fold 2 Epoch 0 Batch 0: Train Loss = 0.6916\n",
      "Fold 2 Epoch 0 Batch 5: Train Loss = 0.6389\n",
      "Fold 2 Epoch 0 Batch 10: Train Loss = 0.6294\n",
      "Fold 2 Epoch 0 Batch 15: Train Loss = 0.6608\n",
      "Fold 2 Epoch 0 Batch 20: Train Loss = 0.5601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/other/choczhang/EMR/HM-COVID/utils/metrics.py:22: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  prec0 = cf[0][0] / (cf[0][0] + cf[1][0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, epoch 0: Loss = 0.6185 Valid loss = 0.8672 roc = 0.7900\n",
      "confusion matrix:\n",
      "[[   0 1426]\n",
      " [   0  247]]\n",
      "accuracy = 0.1476389765739441\n",
      "precision class 0 = nan\n",
      "precision class 1 = 0.1476389765739441\n",
      "recall class 0 = 0.0\n",
      "recall class 1 = 1.0\n",
      "AUC of ROC = 0.7900088580497527\n",
      "AUC of PRC = 0.46010819729442504\n",
      "min(+P, Se) = 0.4817813765182186\n",
      "f1_score = 0.25729166039097573\n",
      "Fold 2, roc = 0.7900, prc = 0.4601\n",
      "Fold 2 Epoch 1 Batch 0: Train Loss = 0.5437\n",
      "Fold 2 Epoch 1 Batch 5: Train Loss = 0.5215\n",
      "Fold 2 Epoch 1 Batch 10: Train Loss = 0.5152\n",
      "Fold 2 Epoch 1 Batch 15: Train Loss = 0.4725\n",
      "Fold 2 Epoch 1 Batch 20: Train Loss = 0.4644\n",
      "Fold 2, roc = 0.8420, prc = 0.5530\n",
      "Fold 2 Epoch 2 Batch 0: Train Loss = 0.4606\n",
      "Fold 2 Epoch 2 Batch 5: Train Loss = 0.4428\n",
      "Fold 2 Epoch 2 Batch 10: Train Loss = 0.3989\n",
      "Fold 2 Epoch 2 Batch 15: Train Loss = 0.4435\n",
      "Fold 2 Epoch 2 Batch 20: Train Loss = 0.4157\n",
      "Fold 2, roc = 0.8890, prc = 0.6136\n",
      "Fold 2 Epoch 3 Batch 0: Train Loss = 0.3674\n",
      "Fold 2 Epoch 3 Batch 5: Train Loss = 0.3662\n",
      "Fold 2 Epoch 3 Batch 10: Train Loss = 0.3870\n",
      "Fold 2 Epoch 3 Batch 15: Train Loss = 0.3417\n",
      "Fold 2 Epoch 3 Batch 20: Train Loss = 0.3380\n",
      "------------ Save best model - AUROC: 0.8956 ------------\n",
      "Fold 2, roc = 0.8956, prc = 0.6316\n",
      "Fold 2 Epoch 4 Batch 0: Train Loss = 0.3626\n",
      "Fold 2 Epoch 4 Batch 5: Train Loss = 0.3988\n",
      "Fold 2 Epoch 4 Batch 10: Train Loss = 0.3357\n",
      "Fold 2 Epoch 4 Batch 15: Train Loss = 0.3322\n",
      "Fold 2 Epoch 4 Batch 20: Train Loss = 0.3243\n",
      "------------ Save best model - AUROC: 0.9035 ------------\n",
      "Fold 2, roc = 0.9035, prc = 0.6473\n",
      "Fold 2 Epoch 5 Batch 0: Train Loss = 0.3179\n",
      "Fold 2 Epoch 5 Batch 5: Train Loss = 0.2929\n",
      "Fold 2 Epoch 5 Batch 10: Train Loss = 0.2865\n",
      "Fold 2 Epoch 5 Batch 15: Train Loss = 0.3369\n",
      "Fold 2 Epoch 5 Batch 20: Train Loss = 0.3369\n",
      "Fold 2, roc = 0.8888, prc = 0.5856\n",
      "Fold 2 Epoch 6 Batch 0: Train Loss = 0.3251\n",
      "Fold 2 Epoch 6 Batch 5: Train Loss = 0.2998\n",
      "Fold 2 Epoch 6 Batch 10: Train Loss = 0.2920\n",
      "Fold 2 Epoch 6 Batch 15: Train Loss = 0.3043\n",
      "Fold 2 Epoch 6 Batch 20: Train Loss = 0.3165\n",
      "Fold 2, roc = 0.8847, prc = 0.5646\n",
      "Fold 2 Epoch 7 Batch 0: Train Loss = 0.3265\n",
      "Fold 2 Epoch 7 Batch 5: Train Loss = 0.2513\n",
      "Fold 2 Epoch 7 Batch 10: Train Loss = 0.2790\n",
      "Fold 2 Epoch 7 Batch 15: Train Loss = 0.2450\n",
      "Fold 2 Epoch 7 Batch 20: Train Loss = 0.2437\n",
      "Fold 2, roc = 0.8764, prc = 0.4955\n",
      "Fold 2 Epoch 8 Batch 0: Train Loss = 0.2843\n",
      "Fold 2 Epoch 8 Batch 5: Train Loss = 0.3339\n",
      "Fold 2 Epoch 8 Batch 10: Train Loss = 0.3224\n",
      "Fold 2 Epoch 8 Batch 15: Train Loss = 0.2811\n",
      "Fold 2 Epoch 8 Batch 20: Train Loss = 0.3018\n",
      "Fold 2, roc = 0.8912, prc = 0.5622\n",
      "Fold 2 Epoch 9 Batch 0: Train Loss = 0.3003\n",
      "Fold 2 Epoch 9 Batch 5: Train Loss = 0.3029\n",
      "Fold 2 Epoch 9 Batch 10: Train Loss = 0.2553\n",
      "Fold 2 Epoch 9 Batch 15: Train Loss = 0.2817\n",
      "Fold 2 Epoch 9 Batch 20: Train Loss = 0.3259\n",
      "Fold 2, roc = 0.8790, prc = 0.4983\n",
      "Fold 2 Epoch 10 Batch 0: Train Loss = 0.2953\n",
      "Fold 2 Epoch 10 Batch 5: Train Loss = 0.2977\n",
      "Fold 2 Epoch 10 Batch 10: Train Loss = 0.2300\n",
      "Fold 2 Epoch 10 Batch 15: Train Loss = 0.3276\n",
      "Fold 2 Epoch 10 Batch 20: Train Loss = 0.2375\n",
      "Fold 2, epoch 10: Loss = 0.2929 Valid loss = 0.3662 roc = 0.8837\n",
      "confusion matrix:\n",
      "[[1344   82]\n",
      " [ 128  119]]\n",
      "accuracy = 0.874476969242096\n",
      "precision class 0 = 0.9130434989929199\n",
      "precision class 1 = 0.5920398235321045\n",
      "recall class 0 = 0.9424964785575867\n",
      "recall class 1 = 0.48178136348724365\n",
      "AUC of ROC = 0.8837139644883056\n",
      "AUC of PRC = 0.5251180671829011\n",
      "min(+P, Se) = 0.5604838709677419\n",
      "f1_score = 0.5312500011510857\n",
      "Fold 2, roc = 0.8837, prc = 0.5251\n",
      "Fold 2 Epoch 11 Batch 0: Train Loss = 0.3159\n",
      "Fold 2 Epoch 11 Batch 5: Train Loss = 0.2062\n",
      "Fold 2 Epoch 11 Batch 10: Train Loss = 0.3035\n",
      "Fold 2 Epoch 11 Batch 15: Train Loss = 0.3121\n",
      "Fold 2 Epoch 11 Batch 20: Train Loss = 0.2940\n",
      "Fold 2, roc = 0.8738, prc = 0.4598\n",
      "Fold 2 Epoch 12 Batch 0: Train Loss = 0.3103\n",
      "Fold 2 Epoch 12 Batch 5: Train Loss = 0.2836\n",
      "Fold 2 Epoch 12 Batch 10: Train Loss = 0.2158\n",
      "Fold 2 Epoch 12 Batch 15: Train Loss = 0.2940\n",
      "Fold 2 Epoch 12 Batch 20: Train Loss = 0.2720\n",
      "Fold 2, roc = 0.8848, prc = 0.4736\n",
      "Fold 2 Epoch 13 Batch 0: Train Loss = 0.2779\n",
      "Fold 2 Epoch 13 Batch 5: Train Loss = 0.2725\n",
      "Fold 2 Epoch 13 Batch 10: Train Loss = 0.2772\n",
      "Fold 2 Epoch 13 Batch 15: Train Loss = 0.2509\n",
      "Fold 2 Epoch 13 Batch 20: Train Loss = 0.2576\n",
      "Fold 2, roc = 0.8811, prc = 0.4757\n",
      "Fold 2 Epoch 14 Batch 0: Train Loss = 0.2301\n",
      "Fold 2 Epoch 14 Batch 5: Train Loss = 0.2661\n",
      "Fold 2 Epoch 14 Batch 10: Train Loss = 0.2463\n",
      "Fold 2 Epoch 14 Batch 15: Train Loss = 0.2381\n",
      "Fold 2 Epoch 14 Batch 20: Train Loss = 0.3135\n",
      "Fold 2, roc = 0.8790, prc = 0.4610\n",
      "Fold 2 Epoch 15 Batch 0: Train Loss = 0.2933\n",
      "Fold 2 Epoch 15 Batch 5: Train Loss = 0.2313\n",
      "Fold 2 Epoch 15 Batch 10: Train Loss = 0.2599\n",
      "Fold 2 Epoch 15 Batch 15: Train Loss = 0.2779\n",
      "Fold 2 Epoch 15 Batch 20: Train Loss = 0.2436\n",
      "Fold 2, roc = 0.8863, prc = 0.4840\n",
      "Fold 2 Epoch 16 Batch 0: Train Loss = 0.2450\n",
      "Fold 2 Epoch 16 Batch 5: Train Loss = 0.2549\n",
      "Fold 2 Epoch 16 Batch 10: Train Loss = 0.2282\n",
      "Fold 2 Epoch 16 Batch 15: Train Loss = 0.2465\n",
      "Fold 2 Epoch 16 Batch 20: Train Loss = 0.2636\n",
      "Fold 2, roc = 0.8730, prc = 0.4884\n",
      "Fold 2 Epoch 17 Batch 0: Train Loss = 0.2428\n",
      "Fold 2 Epoch 17 Batch 5: Train Loss = 0.2771\n",
      "Fold 2 Epoch 17 Batch 10: Train Loss = 0.2940\n",
      "Fold 2 Epoch 17 Batch 15: Train Loss = 0.3631\n",
      "Fold 2 Epoch 17 Batch 20: Train Loss = 0.2669\n",
      "Fold 2, roc = 0.8737, prc = 0.4819\n",
      "Fold 2 Epoch 18 Batch 0: Train Loss = 0.2969\n",
      "Fold 2 Epoch 18 Batch 5: Train Loss = 0.2454\n",
      "Fold 2 Epoch 18 Batch 10: Train Loss = 0.2926\n",
      "Fold 2 Epoch 18 Batch 15: Train Loss = 0.2534\n",
      "Fold 2 Epoch 18 Batch 20: Train Loss = 0.2968\n",
      "Fold 2, roc = 0.8772, prc = 0.4652\n",
      "Fold 2 Epoch 19 Batch 0: Train Loss = 0.2828\n",
      "Fold 2 Epoch 19 Batch 5: Train Loss = 0.3139\n",
      "Fold 2 Epoch 19 Batch 10: Train Loss = 0.2615\n",
      "Fold 2 Epoch 19 Batch 15: Train Loss = 0.2409\n",
      "Fold 2 Epoch 19 Batch 20: Train Loss = 0.2349\n",
      "Fold 2, roc = 0.8712, prc = 0.4668\n",
      "Fold 2 Epoch 20 Batch 0: Train Loss = 0.2569\n",
      "Fold 2 Epoch 20 Batch 5: Train Loss = 0.2021\n",
      "Fold 2 Epoch 20 Batch 10: Train Loss = 0.2622\n",
      "Fold 2 Epoch 20 Batch 15: Train Loss = 0.2462\n",
      "Fold 2 Epoch 20 Batch 20: Train Loss = 0.2722\n",
      "Fold 2, epoch 20: Loss = 0.2463 Valid loss = 0.6775 roc = 0.8651\n",
      "confusion matrix:\n",
      "[[1320  106]\n",
      " [ 121  126]]\n",
      "accuracy = 0.8643156290054321\n",
      "precision class 0 = 0.9160305261611938\n",
      "precision class 1 = 0.5431034564971924\n",
      "recall class 0 = 0.9256662130355835\n",
      "recall class 1 = 0.5101214647293091\n",
      "AUC of ROC = 0.8650609558744201\n",
      "AUC of PRC = 0.4658594693575105\n",
      "min(+P, Se) = 0.5390625\n",
      "f1_score = 0.5260960411101355\n",
      "Fold 2, roc = 0.8651, prc = 0.4659\n",
      "Fold 2 Epoch 21 Batch 0: Train Loss = 0.2730\n",
      "Fold 2 Epoch 21 Batch 5: Train Loss = 0.2134\n",
      "Fold 2 Epoch 21 Batch 10: Train Loss = 0.2583\n",
      "Fold 2 Epoch 21 Batch 15: Train Loss = 0.2527\n",
      "Fold 2 Epoch 21 Batch 20: Train Loss = 0.2179\n",
      "Fold 2, roc = 0.8854, prc = 0.5129\n",
      "Fold 2 Epoch 22 Batch 0: Train Loss = 0.2277\n",
      "Fold 2 Epoch 22 Batch 5: Train Loss = 0.2959\n",
      "Fold 2 Epoch 22 Batch 10: Train Loss = 0.2474\n",
      "Fold 2 Epoch 22 Batch 15: Train Loss = 0.2850\n",
      "Fold 2 Epoch 22 Batch 20: Train Loss = 0.2438\n",
      "Fold 2, roc = 0.8765, prc = 0.4735\n",
      "Fold 2 Epoch 23 Batch 0: Train Loss = 0.2351\n",
      "Fold 2 Epoch 23 Batch 5: Train Loss = 0.2829\n",
      "Fold 2 Epoch 23 Batch 10: Train Loss = 0.2102\n",
      "Fold 2 Epoch 23 Batch 15: Train Loss = 0.2571\n",
      "Fold 2 Epoch 23 Batch 20: Train Loss = 0.1780\n",
      "Fold 2, roc = 0.8709, prc = 0.4576\n",
      "Fold 2 Epoch 24 Batch 0: Train Loss = 0.2450\n",
      "Fold 2 Epoch 24 Batch 5: Train Loss = 0.2400\n",
      "Fold 2 Epoch 24 Batch 10: Train Loss = 0.2203\n",
      "Fold 2 Epoch 24 Batch 15: Train Loss = 0.2885\n",
      "Fold 2 Epoch 24 Batch 20: Train Loss = 0.1870\n",
      "Fold 2, roc = 0.8672, prc = 0.4525\n",
      "Fold 2 Epoch 25 Batch 0: Train Loss = 0.3024\n",
      "Fold 2 Epoch 25 Batch 5: Train Loss = 0.2064\n",
      "Fold 2 Epoch 25 Batch 10: Train Loss = 0.1824\n",
      "Fold 2 Epoch 25 Batch 15: Train Loss = 0.2466\n",
      "Fold 2 Epoch 25 Batch 20: Train Loss = 0.2810\n",
      "Fold 2, roc = 0.8725, prc = 0.4623\n",
      "Fold 2 Epoch 26 Batch 0: Train Loss = 0.1932\n",
      "Fold 2 Epoch 26 Batch 5: Train Loss = 0.2143\n",
      "Fold 2 Epoch 26 Batch 10: Train Loss = 0.2115\n",
      "Fold 2 Epoch 26 Batch 15: Train Loss = 0.2740\n",
      "Fold 2 Epoch 26 Batch 20: Train Loss = 0.1778\n",
      "Fold 2, roc = 0.8634, prc = 0.4469\n",
      "Fold 2 Epoch 27 Batch 0: Train Loss = 0.2099\n",
      "Fold 2 Epoch 27 Batch 5: Train Loss = 0.1908\n",
      "Fold 2 Epoch 27 Batch 10: Train Loss = 0.2488\n",
      "Fold 2 Epoch 27 Batch 15: Train Loss = 0.2755\n",
      "Fold 2 Epoch 27 Batch 20: Train Loss = 0.2657\n",
      "Fold 2, roc = 0.8753, prc = 0.5765\n",
      "Fold 2 Epoch 28 Batch 0: Train Loss = 0.2055\n",
      "Fold 2 Epoch 28 Batch 5: Train Loss = 0.2423\n",
      "Fold 2 Epoch 28 Batch 10: Train Loss = 0.2962\n",
      "Fold 2 Epoch 28 Batch 15: Train Loss = 0.2666\n",
      "Fold 2 Epoch 28 Batch 20: Train Loss = 0.1726\n",
      "Fold 2, roc = 0.8710, prc = 0.4578\n",
      "Fold 2 Epoch 29 Batch 0: Train Loss = 0.2297\n",
      "Fold 2 Epoch 29 Batch 5: Train Loss = 0.1950\n",
      "Fold 2 Epoch 29 Batch 10: Train Loss = 0.2388\n",
      "Fold 2 Epoch 29 Batch 15: Train Loss = 0.1953\n",
      "Fold 2 Epoch 29 Batch 20: Train Loss = 0.2672\n",
      "Fold 2, roc = 0.8656, prc = 0.4469\n",
      "Fold 2 Epoch 30 Batch 0: Train Loss = 0.2906\n",
      "Fold 2 Epoch 30 Batch 5: Train Loss = 0.2435\n",
      "Fold 2 Epoch 30 Batch 10: Train Loss = 0.2501\n",
      "Fold 2 Epoch 30 Batch 15: Train Loss = 0.3095\n",
      "Fold 2 Epoch 30 Batch 20: Train Loss = 0.2423\n",
      "Fold 2, epoch 30: Loss = 0.2360 Valid loss = 1.1080 roc = 0.8362\n",
      "confusion matrix:\n",
      "[[1302  124]\n",
      " [ 143  104]]\n",
      "accuracy = 0.8404064774513245\n",
      "precision class 0 = 0.9010380506515503\n",
      "precision class 1 = 0.45614033937454224\n",
      "recall class 0 = 0.9130434989929199\n",
      "recall class 1 = 0.42105263471603394\n",
      "AUC of ROC = 0.8361644076747051\n",
      "AUC of PRC = 0.3656717703869041\n",
      "min(+P, Se) = 0.4578313253012048\n",
      "f1_score = 0.4378947332382201\n",
      "Fold 2, roc = 0.8362, prc = 0.3657\n",
      "Fold 2 Epoch 31 Batch 0: Train Loss = 0.2101\n",
      "Fold 2 Epoch 31 Batch 5: Train Loss = 0.2206\n",
      "Fold 2 Epoch 31 Batch 10: Train Loss = 0.2046\n",
      "Fold 2 Epoch 31 Batch 15: Train Loss = 0.2659\n",
      "Fold 2 Epoch 31 Batch 20: Train Loss = 0.1957\n",
      "Fold 2, roc = 0.8679, prc = 0.4487\n",
      "Fold 2 Epoch 32 Batch 0: Train Loss = 0.2368\n",
      "Fold 2 Epoch 32 Batch 5: Train Loss = 0.2757\n",
      "Fold 2 Epoch 32 Batch 10: Train Loss = 0.2469\n",
      "Fold 2 Epoch 32 Batch 15: Train Loss = 0.1951\n",
      "Fold 2 Epoch 32 Batch 20: Train Loss = 0.1889\n",
      "Fold 2, roc = 0.8602, prc = 0.4414\n",
      "Fold 2 Epoch 33 Batch 0: Train Loss = 0.1982\n",
      "Fold 2 Epoch 33 Batch 5: Train Loss = 0.2412\n",
      "Fold 2 Epoch 33 Batch 10: Train Loss = 0.2192\n",
      "Fold 2 Epoch 33 Batch 15: Train Loss = 0.2497\n",
      "Fold 2 Epoch 33 Batch 20: Train Loss = 0.2522\n",
      "Fold 2, roc = 0.8697, prc = 0.4559\n",
      "Fold 2 Epoch 34 Batch 0: Train Loss = 0.2332\n",
      "Fold 2 Epoch 34 Batch 5: Train Loss = 0.2035\n",
      "Fold 2 Epoch 34 Batch 10: Train Loss = 0.2658\n",
      "Fold 2 Epoch 34 Batch 15: Train Loss = 0.2232\n",
      "Fold 2 Epoch 34 Batch 20: Train Loss = 0.1772\n",
      "Fold 2, roc = 0.8643, prc = 0.4468\n",
      "Fold 2 Epoch 35 Batch 0: Train Loss = 0.2258\n",
      "Fold 2 Epoch 35 Batch 5: Train Loss = 0.2538\n",
      "Fold 2 Epoch 35 Batch 10: Train Loss = 0.1948\n",
      "Fold 2 Epoch 35 Batch 15: Train Loss = 0.2096\n",
      "Fold 2 Epoch 35 Batch 20: Train Loss = 0.2443\n",
      "Fold 2, roc = 0.8519, prc = 0.4257\n",
      "Fold 2 Epoch 36 Batch 0: Train Loss = 0.1753\n",
      "Fold 2 Epoch 36 Batch 5: Train Loss = 0.2195\n",
      "Fold 2 Epoch 36 Batch 10: Train Loss = 0.2236\n",
      "Fold 2 Epoch 36 Batch 15: Train Loss = 0.1977\n",
      "Fold 2 Epoch 36 Batch 20: Train Loss = 0.1579\n",
      "Fold 2, roc = 0.8762, prc = 0.4703\n",
      "Fold 2 Epoch 37 Batch 0: Train Loss = 0.1635\n",
      "Fold 2 Epoch 37 Batch 5: Train Loss = 0.1924\n",
      "Fold 2 Epoch 37 Batch 10: Train Loss = 0.2262\n",
      "Fold 2 Epoch 37 Batch 15: Train Loss = 0.2155\n",
      "Fold 2 Epoch 37 Batch 20: Train Loss = 0.2305\n",
      "Fold 2, roc = 0.8669, prc = 0.4527\n",
      "Fold 2 Epoch 38 Batch 0: Train Loss = 0.1911\n",
      "Fold 2 Epoch 38 Batch 5: Train Loss = 0.1755\n",
      "Fold 2 Epoch 38 Batch 10: Train Loss = 0.2094\n",
      "Fold 2 Epoch 38 Batch 15: Train Loss = 0.2074\n",
      "Fold 2 Epoch 38 Batch 20: Train Loss = 0.2339\n",
      "Fold 2, roc = 0.8685, prc = 0.4555\n",
      "Fold 2 Epoch 39 Batch 0: Train Loss = 0.1983\n",
      "Fold 2 Epoch 39 Batch 5: Train Loss = 0.2256\n",
      "Fold 2 Epoch 39 Batch 10: Train Loss = 0.1710\n",
      "Fold 2 Epoch 39 Batch 15: Train Loss = 0.1841\n",
      "Fold 2 Epoch 39 Batch 20: Train Loss = 0.2069\n",
      "Fold 2, roc = 0.8830, prc = 0.4991\n",
      "Fold 2 Epoch 40 Batch 0: Train Loss = 0.2067\n",
      "Fold 2 Epoch 40 Batch 5: Train Loss = 0.2587\n",
      "Fold 2 Epoch 40 Batch 10: Train Loss = 0.1953\n",
      "Fold 2 Epoch 40 Batch 15: Train Loss = 0.2046\n",
      "Fold 2 Epoch 40 Batch 20: Train Loss = 0.2193\n",
      "Fold 2, epoch 40: Loss = 0.2132 Valid loss = 0.3454 roc = 0.8802\n",
      "confusion matrix:\n",
      "[[1328   98]\n",
      " [ 126  121]]\n",
      "accuracy = 0.866108775138855\n",
      "precision class 0 = 0.9133424758911133\n",
      "precision class 1 = 0.5525113940238953\n",
      "recall class 0 = 0.9312763214111328\n",
      "recall class 1 = 0.4898785352706909\n",
      "AUC of ROC = 0.8801508707576472\n",
      "AUC of PRC = 0.5754953038962789\n",
      "min(+P, Se) = 0.5515873015873016\n",
      "f1_score = 0.519313320850484\n",
      "Fold 2, roc = 0.8802, prc = 0.5755\n",
      "Fold 2 Epoch 41 Batch 0: Train Loss = 0.1325\n",
      "Fold 2 Epoch 41 Batch 5: Train Loss = 0.1556\n",
      "Fold 2 Epoch 41 Batch 10: Train Loss = 0.2005\n",
      "Fold 2 Epoch 41 Batch 15: Train Loss = 0.2522\n",
      "Fold 2 Epoch 41 Batch 20: Train Loss = 0.1784\n",
      "Fold 2, roc = 0.8697, prc = 0.4477\n",
      "Fold 2 Epoch 42 Batch 0: Train Loss = 0.2042\n",
      "Fold 2 Epoch 42 Batch 5: Train Loss = 0.1880\n",
      "Fold 2 Epoch 42 Batch 10: Train Loss = 0.2512\n",
      "Fold 2 Epoch 42 Batch 15: Train Loss = 0.2221\n",
      "Fold 2 Epoch 42 Batch 20: Train Loss = 0.1983\n",
      "Fold 2, roc = 0.8732, prc = 0.4624\n",
      "Fold 2 Epoch 43 Batch 0: Train Loss = 0.2091\n",
      "Fold 2 Epoch 43 Batch 5: Train Loss = 0.2131\n",
      "Fold 2 Epoch 43 Batch 10: Train Loss = 0.2576\n",
      "Fold 2 Epoch 43 Batch 15: Train Loss = 0.2115\n",
      "Fold 2 Epoch 43 Batch 20: Train Loss = 0.1962\n",
      "Fold 2, roc = 0.8730, prc = 0.4568\n",
      "Fold 2 Epoch 44 Batch 0: Train Loss = 0.1993\n",
      "Fold 2 Epoch 44 Batch 5: Train Loss = 0.1704\n",
      "Fold 2 Epoch 44 Batch 10: Train Loss = 0.2117\n",
      "Fold 2 Epoch 44 Batch 15: Train Loss = 0.2304\n",
      "Fold 2 Epoch 44 Batch 20: Train Loss = 0.2245\n",
      "Fold 2, roc = 0.8687, prc = 0.4708\n",
      "Fold 2 Epoch 45 Batch 0: Train Loss = 0.2271\n",
      "Fold 2 Epoch 45 Batch 5: Train Loss = 0.2490\n",
      "Fold 2 Epoch 45 Batch 10: Train Loss = 0.2390\n",
      "Fold 2 Epoch 45 Batch 15: Train Loss = 0.2374\n",
      "Fold 2 Epoch 45 Batch 20: Train Loss = 0.2405\n",
      "Fold 2, roc = 0.8624, prc = 0.4597\n",
      "Fold 2 Epoch 46 Batch 0: Train Loss = 0.2534\n",
      "Fold 2 Epoch 46 Batch 5: Train Loss = 0.2030\n",
      "Fold 2 Epoch 46 Batch 10: Train Loss = 0.1900\n",
      "Fold 2 Epoch 46 Batch 15: Train Loss = 0.1625\n",
      "Fold 2 Epoch 46 Batch 20: Train Loss = 0.1915\n",
      "Fold 2, roc = 0.8590, prc = 0.4432\n",
      "Fold 2 Epoch 47 Batch 0: Train Loss = 0.2474\n",
      "Fold 2 Epoch 47 Batch 5: Train Loss = 0.1974\n",
      "Fold 2 Epoch 47 Batch 10: Train Loss = 0.1918\n",
      "Fold 2 Epoch 47 Batch 15: Train Loss = 0.1379\n",
      "Fold 2 Epoch 47 Batch 20: Train Loss = 0.2027\n",
      "Fold 2, roc = 0.8704, prc = 0.4556\n",
      "Fold 2 Epoch 48 Batch 0: Train Loss = 0.1795\n",
      "Fold 2 Epoch 48 Batch 5: Train Loss = 0.2177\n",
      "Fold 2 Epoch 48 Batch 10: Train Loss = 0.2343\n",
      "Fold 2 Epoch 48 Batch 15: Train Loss = 0.1918\n",
      "Fold 2 Epoch 48 Batch 20: Train Loss = 0.2059\n",
      "Fold 2, roc = 0.8698, prc = 0.4754\n",
      "Fold 2 Epoch 49 Batch 0: Train Loss = 0.2413\n",
      "Fold 2 Epoch 49 Batch 5: Train Loss = 0.2443\n",
      "Fold 2 Epoch 49 Batch 10: Train Loss = 0.2103\n",
      "Fold 2 Epoch 49 Batch 15: Train Loss = 0.1963\n",
      "Fold 2 Epoch 49 Batch 20: Train Loss = 0.1330\n",
      "Fold 2, roc = 0.8788, prc = 0.4796\n",
      "Fold 2 Epoch 50 Batch 0: Train Loss = 0.2203\n",
      "Fold 2 Epoch 50 Batch 5: Train Loss = 0.1991\n",
      "Fold 2 Epoch 50 Batch 10: Train Loss = 0.2190\n",
      "Fold 2 Epoch 50 Batch 15: Train Loss = 0.2344\n",
      "Fold 2 Epoch 50 Batch 20: Train Loss = 0.1669\n",
      "Fold 2, epoch 50: Loss = 0.2047 Valid loss = 0.3618 roc = 0.8677\n",
      "confusion matrix:\n",
      "[[1369   57]\n",
      " [ 158   89]]\n",
      "accuracy = 0.8714883327484131\n",
      "precision class 0 = 0.8965291380882263\n",
      "precision class 1 = 0.6095890402793884\n",
      "recall class 0 = 0.9600280523300171\n",
      "recall class 1 = 0.36032387614250183\n",
      "AUC of ROC = 0.8677439228668282\n",
      "AUC of PRC = 0.49168604777111735\n",
      "min(+P, Se) = 0.5341365461847389\n",
      "f1_score = 0.4529262140500062\n",
      "Fold 2, roc = 0.8677, prc = 0.4917\n",
      "Fold 2 Epoch 51 Batch 0: Train Loss = 0.1803\n",
      "Fold 2 Epoch 51 Batch 5: Train Loss = 0.2264\n",
      "Fold 2 Epoch 51 Batch 10: Train Loss = 0.2347\n",
      "Fold 2 Epoch 51 Batch 15: Train Loss = 0.2715\n",
      "Fold 2 Epoch 51 Batch 20: Train Loss = 0.2406\n",
      "Fold 2, roc = 0.8866, prc = 0.5616\n",
      "Fold 2 Epoch 52 Batch 0: Train Loss = 0.2318\n",
      "Fold 2 Epoch 52 Batch 5: Train Loss = 0.2345\n",
      "Fold 2 Epoch 52 Batch 10: Train Loss = 0.2671\n",
      "Fold 2 Epoch 52 Batch 15: Train Loss = 0.1986\n",
      "Fold 2 Epoch 52 Batch 20: Train Loss = 0.2200\n",
      "Fold 2, roc = 0.8865, prc = 0.5527\n",
      "Fold 2 Epoch 53 Batch 0: Train Loss = 0.1420\n",
      "Fold 2 Epoch 53 Batch 5: Train Loss = 0.1888\n",
      "Fold 2 Epoch 53 Batch 10: Train Loss = 0.1834\n",
      "Fold 2 Epoch 53 Batch 15: Train Loss = 0.2264\n",
      "Fold 2 Epoch 53 Batch 20: Train Loss = 0.1980\n",
      "Fold 2, roc = 0.8866, prc = 0.5905\n",
      "Fold 2 Epoch 54 Batch 0: Train Loss = 0.2458\n",
      "Fold 2 Epoch 54 Batch 5: Train Loss = 0.1708\n",
      "Fold 2 Epoch 54 Batch 10: Train Loss = 0.1511\n",
      "Fold 2 Epoch 54 Batch 15: Train Loss = 0.1980\n",
      "Fold 2 Epoch 54 Batch 20: Train Loss = 0.1683\n",
      "Fold 2, roc = 0.8795, prc = 0.5630\n",
      "Fold 2 Epoch 55 Batch 0: Train Loss = 0.2236\n",
      "Fold 2 Epoch 55 Batch 5: Train Loss = 0.2163\n",
      "Fold 2 Epoch 55 Batch 10: Train Loss = 0.1948\n",
      "Fold 2 Epoch 55 Batch 15: Train Loss = 0.1845\n",
      "Fold 2 Epoch 55 Batch 20: Train Loss = 0.2199\n",
      "Fold 2, roc = 0.8787, prc = 0.5356\n",
      "Fold 2 Epoch 56 Batch 0: Train Loss = 0.2446\n",
      "Fold 2 Epoch 56 Batch 5: Train Loss = 0.1507\n",
      "Fold 2 Epoch 56 Batch 10: Train Loss = 0.2048\n",
      "Fold 2 Epoch 56 Batch 15: Train Loss = 0.1826\n",
      "Fold 2 Epoch 56 Batch 20: Train Loss = 0.2363\n",
      "Fold 2, roc = 0.8808, prc = 0.5538\n",
      "Fold 2 Epoch 57 Batch 0: Train Loss = 0.1486\n",
      "Fold 2 Epoch 57 Batch 5: Train Loss = 0.1785\n",
      "Fold 2 Epoch 57 Batch 10: Train Loss = 0.1674\n",
      "Fold 2 Epoch 57 Batch 15: Train Loss = 0.1814\n",
      "Fold 2 Epoch 57 Batch 20: Train Loss = 0.2577\n",
      "Fold 2, roc = 0.8779, prc = 0.5327\n",
      "Fold 2 Epoch 58 Batch 0: Train Loss = 0.2324\n",
      "Fold 2 Epoch 58 Batch 5: Train Loss = 0.2221\n",
      "Fold 2 Epoch 58 Batch 10: Train Loss = 0.2174\n",
      "Fold 2 Epoch 58 Batch 15: Train Loss = 0.1463\n",
      "Fold 2 Epoch 58 Batch 20: Train Loss = 0.1851\n",
      "Fold 2, roc = 0.8865, prc = 0.5909\n",
      "Fold 2 Epoch 59 Batch 0: Train Loss = 0.1904\n",
      "Fold 2 Epoch 59 Batch 5: Train Loss = 0.2097\n",
      "Fold 2 Epoch 59 Batch 10: Train Loss = 0.1997\n",
      "Fold 2 Epoch 59 Batch 15: Train Loss = 0.2596\n",
      "Fold 2 Epoch 59 Batch 20: Train Loss = 0.2071\n",
      "Fold 2, roc = 0.8689, prc = 0.5272\n",
      "Fold 2 Epoch 60 Batch 0: Train Loss = 0.2479\n",
      "Fold 2 Epoch 60 Batch 5: Train Loss = 0.1594\n",
      "Fold 2 Epoch 60 Batch 10: Train Loss = 0.1948\n",
      "Fold 2 Epoch 60 Batch 15: Train Loss = 0.1817\n",
      "Fold 2 Epoch 60 Batch 20: Train Loss = 0.1807\n",
      "Fold 2, epoch 60: Loss = 0.1965 Valid loss = 0.4481 roc = 0.8692\n",
      "confusion matrix:\n",
      "[[1304  122]\n",
      " [ 110  137]]\n",
      "accuracy = 0.8613269329071045\n",
      "precision class 0 = 0.9222065210342407\n",
      "precision class 1 = 0.5289575457572937\n",
      "recall class 0 = 0.9144459962844849\n",
      "recall class 1 = 0.5546558499336243\n",
      "AUC of ROC = 0.8692202644922803\n",
      "AUC of PRC = 0.4831896488480193\n",
      "min(+P, Se) = 0.532\n",
      "f1_score = 0.5415019753124203\n",
      "Fold 2, roc = 0.8692, prc = 0.4832\n",
      "Fold 2 Epoch 61 Batch 0: Train Loss = 0.1898\n",
      "Fold 2 Epoch 61 Batch 5: Train Loss = 0.1945\n",
      "Fold 2 Epoch 61 Batch 10: Train Loss = 0.1721\n",
      "Fold 2 Epoch 61 Batch 15: Train Loss = 0.2338\n",
      "Fold 2 Epoch 61 Batch 20: Train Loss = 0.1823\n",
      "Fold 2, roc = 0.8696, prc = 0.5338\n",
      "Fold 2 Epoch 62 Batch 0: Train Loss = 0.2207\n",
      "Fold 2 Epoch 62 Batch 5: Train Loss = 0.2078\n",
      "Fold 2 Epoch 62 Batch 10: Train Loss = 0.1894\n",
      "Fold 2 Epoch 62 Batch 15: Train Loss = 0.1493\n",
      "Fold 2 Epoch 62 Batch 20: Train Loss = 0.2094\n",
      "Fold 2, roc = 0.8670, prc = 0.5431\n",
      "Fold 2 Epoch 63 Batch 0: Train Loss = 0.1919\n",
      "Fold 2 Epoch 63 Batch 5: Train Loss = 0.2076\n",
      "Fold 2 Epoch 63 Batch 10: Train Loss = 0.1600\n",
      "Fold 2 Epoch 63 Batch 15: Train Loss = 0.2216\n",
      "Fold 2 Epoch 63 Batch 20: Train Loss = 0.1832\n",
      "Fold 2, roc = 0.8757, prc = 0.4998\n",
      "Fold 2 Epoch 64 Batch 0: Train Loss = 0.1727\n",
      "Fold 2 Epoch 64 Batch 5: Train Loss = 0.1735\n",
      "Fold 2 Epoch 64 Batch 10: Train Loss = 0.2333\n",
      "Fold 2 Epoch 64 Batch 15: Train Loss = 0.1996\n",
      "Fold 2 Epoch 64 Batch 20: Train Loss = 0.1807\n",
      "Fold 2, roc = 0.8734, prc = 0.4786\n",
      "Fold 2 Epoch 65 Batch 0: Train Loss = 0.2301\n",
      "Fold 2 Epoch 65 Batch 5: Train Loss = 0.2199\n",
      "Fold 2 Epoch 65 Batch 10: Train Loss = 0.1601\n",
      "Fold 2 Epoch 65 Batch 15: Train Loss = 0.1815\n",
      "Fold 2 Epoch 65 Batch 20: Train Loss = 0.2000\n",
      "Fold 2, roc = 0.8689, prc = 0.4928\n",
      "Fold 2 Epoch 66 Batch 0: Train Loss = 0.1589\n",
      "Fold 2 Epoch 66 Batch 5: Train Loss = 0.1481\n",
      "Fold 2 Epoch 66 Batch 10: Train Loss = 0.2270\n",
      "Fold 2 Epoch 66 Batch 15: Train Loss = 0.2371\n",
      "Fold 2 Epoch 66 Batch 20: Train Loss = 0.1887\n",
      "Fold 2, roc = 0.8860, prc = 0.5728\n",
      "Fold 2 Epoch 67 Batch 0: Train Loss = 0.1747\n",
      "Fold 2 Epoch 67 Batch 5: Train Loss = 0.2264\n",
      "Fold 2 Epoch 67 Batch 10: Train Loss = 0.1569\n",
      "Fold 2 Epoch 67 Batch 15: Train Loss = 0.1805\n",
      "Fold 2 Epoch 67 Batch 20: Train Loss = 0.1512\n",
      "Fold 2, roc = 0.8807, prc = 0.5397\n",
      "Fold 2 Epoch 68 Batch 0: Train Loss = 0.2523\n",
      "Fold 2 Epoch 68 Batch 5: Train Loss = 0.2130\n",
      "Fold 2 Epoch 68 Batch 10: Train Loss = 0.2172\n",
      "Fold 2 Epoch 68 Batch 15: Train Loss = 0.1924\n",
      "Fold 2 Epoch 68 Batch 20: Train Loss = 0.1666\n",
      "Fold 2, roc = 0.8836, prc = 0.5867\n",
      "Fold 2 Epoch 69 Batch 0: Train Loss = 0.1812\n",
      "Fold 2 Epoch 69 Batch 5: Train Loss = 0.2389\n",
      "Fold 2 Epoch 69 Batch 10: Train Loss = 0.2290\n",
      "Fold 2 Epoch 69 Batch 15: Train Loss = 0.2093\n",
      "Fold 2 Epoch 69 Batch 20: Train Loss = 0.2043\n",
      "Fold 2, roc = 0.8786, prc = 0.5823\n",
      "Fold 2 Epoch 70 Batch 0: Train Loss = 0.1916\n",
      "Fold 2 Epoch 70 Batch 5: Train Loss = 0.1868\n",
      "Fold 2 Epoch 70 Batch 10: Train Loss = 0.2421\n",
      "Fold 2 Epoch 70 Batch 15: Train Loss = 0.2004\n",
      "Fold 2 Epoch 70 Batch 20: Train Loss = 0.1503\n",
      "Fold 2, epoch 70: Loss = 0.1956 Valid loss = 0.3631 roc = 0.8795\n",
      "confusion matrix:\n",
      "[[1301  125]\n",
      " [ 107  140]]\n",
      "accuracy = 0.8613269329071045\n",
      "precision class 0 = 0.9240056872367859\n",
      "precision class 1 = 0.5283018946647644\n",
      "recall class 0 = 0.9123421907424927\n",
      "recall class 1 = 0.5668016076087952\n",
      "AUC of ROC = 0.8794751605521517\n",
      "AUC of PRC = 0.58424431636627\n",
      "min(+P, Se) = 0.5465587044534413\n",
      "f1_score = 0.5468749987139743\n",
      "Fold 2, roc = 0.8795, prc = 0.5842\n",
      "Fold 2 Epoch 71 Batch 0: Train Loss = 0.1959\n",
      "Fold 2 Epoch 71 Batch 5: Train Loss = 0.1889\n",
      "Fold 2 Epoch 71 Batch 10: Train Loss = 0.1644\n",
      "Fold 2 Epoch 71 Batch 15: Train Loss = 0.1411\n",
      "Fold 2 Epoch 71 Batch 20: Train Loss = 0.2054\n",
      "Fold 2, roc = 0.8815, prc = 0.5869\n",
      "Fold 2 Epoch 72 Batch 0: Train Loss = 0.1949\n",
      "Fold 2 Epoch 72 Batch 5: Train Loss = 0.1858\n",
      "Fold 2 Epoch 72 Batch 10: Train Loss = 0.1714\n",
      "Fold 2 Epoch 72 Batch 15: Train Loss = 0.1978\n",
      "Fold 2 Epoch 72 Batch 20: Train Loss = 0.1910\n",
      "Fold 2, roc = 0.8736, prc = 0.5709\n",
      "Fold 2 Epoch 73 Batch 0: Train Loss = 0.1493\n",
      "Fold 2 Epoch 73 Batch 5: Train Loss = 0.2038\n",
      "Fold 2 Epoch 73 Batch 10: Train Loss = 0.1512\n",
      "Fold 2 Epoch 73 Batch 15: Train Loss = 0.1970\n",
      "Fold 2 Epoch 73 Batch 20: Train Loss = 0.2432\n",
      "Fold 2, roc = 0.8773, prc = 0.5848\n",
      "Fold 2 Epoch 74 Batch 0: Train Loss = 0.2415\n",
      "Fold 2 Epoch 74 Batch 5: Train Loss = 0.1859\n",
      "Fold 2 Epoch 74 Batch 10: Train Loss = 0.1925\n",
      "Fold 2 Epoch 74 Batch 15: Train Loss = 0.2055\n",
      "Fold 2 Epoch 74 Batch 20: Train Loss = 0.1622\n",
      "Fold 2, roc = 0.8771, prc = 0.6133\n",
      "Fold 2 Epoch 75 Batch 0: Train Loss = 0.2140\n",
      "Fold 2 Epoch 75 Batch 5: Train Loss = 0.1515\n",
      "Fold 2 Epoch 75 Batch 10: Train Loss = 0.2241\n",
      "Fold 2 Epoch 75 Batch 15: Train Loss = 0.1480\n",
      "Fold 2 Epoch 75 Batch 20: Train Loss = 0.2176\n",
      "Fold 2, roc = 0.8751, prc = 0.5780\n",
      "Fold 2 Epoch 76 Batch 0: Train Loss = 0.1924\n",
      "Fold 2 Epoch 76 Batch 5: Train Loss = 0.1348\n",
      "Fold 2 Epoch 76 Batch 10: Train Loss = 0.1917\n",
      "Fold 2 Epoch 76 Batch 15: Train Loss = 0.1594\n",
      "Fold 2 Epoch 76 Batch 20: Train Loss = 0.1628\n",
      "Fold 2, roc = 0.8603, prc = 0.5601\n",
      "Fold 2 Epoch 77 Batch 0: Train Loss = 0.1557\n",
      "Fold 2 Epoch 77 Batch 5: Train Loss = 0.1948\n",
      "Fold 2 Epoch 77 Batch 10: Train Loss = 0.2124\n",
      "Fold 2 Epoch 77 Batch 15: Train Loss = 0.1731\n",
      "Fold 2 Epoch 77 Batch 20: Train Loss = 0.2371\n",
      "Fold 2, roc = 0.8648, prc = 0.5241\n",
      "Fold 2 Epoch 78 Batch 0: Train Loss = 0.1402\n",
      "Fold 2 Epoch 78 Batch 5: Train Loss = 0.1818\n",
      "Fold 2 Epoch 78 Batch 10: Train Loss = 0.2670\n",
      "Fold 2 Epoch 78 Batch 15: Train Loss = 0.2322\n",
      "Fold 2 Epoch 78 Batch 20: Train Loss = 0.2061\n",
      "Fold 2, roc = 0.8337, prc = 0.5622\n",
      "Fold 2 Epoch 79 Batch 0: Train Loss = 0.2029\n",
      "Fold 2 Epoch 79 Batch 5: Train Loss = 0.2847\n",
      "Fold 2 Epoch 79 Batch 10: Train Loss = 0.2094\n",
      "Fold 2 Epoch 79 Batch 15: Train Loss = 0.2057\n",
      "Fold 2 Epoch 79 Batch 20: Train Loss = 0.2320\n",
      "Fold 2, roc = 0.8594, prc = 0.5972\n",
      "Fold 2 Epoch 80 Batch 0: Train Loss = 0.2094\n",
      "Fold 2 Epoch 80 Batch 5: Train Loss = 0.1575\n",
      "Fold 2 Epoch 80 Batch 10: Train Loss = 0.1481\n",
      "Fold 2 Epoch 80 Batch 15: Train Loss = 0.1779\n",
      "Fold 2 Epoch 80 Batch 20: Train Loss = 0.1804\n",
      "Fold 2, epoch 80: Loss = 0.1889 Valid loss = 0.3767 roc = 0.8626\n",
      "confusion matrix:\n",
      "[[1318  108]\n",
      " [ 127  120]]\n",
      "accuracy = 0.8595337867736816\n",
      "precision class 0 = 0.9121107459068298\n",
      "precision class 1 = 0.5263158082962036\n",
      "recall class 0 = 0.9242636561393738\n",
      "recall class 1 = 0.4858299493789673\n",
      "AUC of ROC = 0.8625880836517877\n",
      "AUC of PRC = 0.5566930674771117\n",
      "min(+P, Se) = 0.5080645161290323\n",
      "f1_score = 0.5052631610870357\n",
      "Fold 2, roc = 0.8626, prc = 0.5567\n",
      "Fold 2 Epoch 81 Batch 0: Train Loss = 0.1964\n",
      "Fold 2 Epoch 81 Batch 5: Train Loss = 0.1664\n",
      "Fold 2 Epoch 81 Batch 10: Train Loss = 0.1778\n",
      "Fold 2 Epoch 81 Batch 15: Train Loss = 0.1918\n",
      "Fold 2 Epoch 81 Batch 20: Train Loss = 0.2267\n",
      "Fold 2, roc = 0.8701, prc = 0.4700\n",
      "Fold 2 Epoch 82 Batch 0: Train Loss = 0.1817\n",
      "Fold 2 Epoch 82 Batch 5: Train Loss = 0.2234\n",
      "Fold 2 Epoch 82 Batch 10: Train Loss = 0.2101\n",
      "Fold 2 Epoch 82 Batch 15: Train Loss = 0.2083\n",
      "Fold 2 Epoch 82 Batch 20: Train Loss = 0.2100\n",
      "Fold 2, roc = 0.8652, prc = 0.5735\n",
      "Fold 2 Epoch 83 Batch 0: Train Loss = 0.1858\n",
      "Fold 2 Epoch 83 Batch 5: Train Loss = 0.2005\n",
      "Fold 2 Epoch 83 Batch 10: Train Loss = 0.2016\n",
      "Fold 2 Epoch 83 Batch 15: Train Loss = 0.1916\n",
      "Fold 2 Epoch 83 Batch 20: Train Loss = 0.2441\n",
      "Fold 2, roc = 0.8623, prc = 0.5553\n",
      "Fold 2 Epoch 84 Batch 0: Train Loss = 0.1703\n",
      "Fold 2 Epoch 84 Batch 5: Train Loss = 0.1935\n",
      "Fold 2 Epoch 84 Batch 10: Train Loss = 0.1853\n",
      "Fold 2 Epoch 84 Batch 15: Train Loss = 0.1947\n",
      "Fold 2 Epoch 84 Batch 20: Train Loss = 0.1732\n",
      "Fold 2, roc = 0.8747, prc = 0.5878\n",
      "Fold 2 Epoch 85 Batch 0: Train Loss = 0.1636\n",
      "Fold 2 Epoch 85 Batch 5: Train Loss = 0.1735\n",
      "Fold 2 Epoch 85 Batch 10: Train Loss = 0.1778\n",
      "Fold 2 Epoch 85 Batch 15: Train Loss = 0.1622\n",
      "Fold 2 Epoch 85 Batch 20: Train Loss = 0.1373\n",
      "Fold 2, roc = 0.8694, prc = 0.5899\n",
      "Fold 2 Epoch 86 Batch 0: Train Loss = 0.2067\n",
      "Fold 2 Epoch 86 Batch 5: Train Loss = 0.1540\n",
      "Fold 2 Epoch 86 Batch 10: Train Loss = 0.1324\n",
      "Fold 2 Epoch 86 Batch 15: Train Loss = 0.1568\n",
      "Fold 2 Epoch 86 Batch 20: Train Loss = 0.1695\n",
      "Fold 2, roc = 0.8609, prc = 0.5613\n",
      "Fold 2 Epoch 87 Batch 0: Train Loss = 0.1641\n",
      "Fold 2 Epoch 87 Batch 5: Train Loss = 0.2090\n",
      "Fold 2 Epoch 87 Batch 10: Train Loss = 0.1948\n",
      "Fold 2 Epoch 87 Batch 15: Train Loss = 0.1733\n",
      "Fold 2 Epoch 87 Batch 20: Train Loss = 0.1699\n",
      "Fold 2, roc = 0.8576, prc = 0.5093\n",
      "Fold 2 Epoch 88 Batch 0: Train Loss = 0.2304\n",
      "Fold 2 Epoch 88 Batch 5: Train Loss = 0.1987\n",
      "Fold 2 Epoch 88 Batch 10: Train Loss = 0.1756\n",
      "Fold 2 Epoch 88 Batch 15: Train Loss = 0.2213\n",
      "Fold 2 Epoch 88 Batch 20: Train Loss = 0.1676\n",
      "Fold 2, roc = 0.8546, prc = 0.5817\n",
      "Fold 2 Epoch 89 Batch 0: Train Loss = 0.2724\n",
      "Fold 2 Epoch 89 Batch 5: Train Loss = 0.2169\n",
      "Fold 2 Epoch 89 Batch 10: Train Loss = 0.1385\n",
      "Fold 2 Epoch 89 Batch 15: Train Loss = 0.1650\n",
      "Fold 2 Epoch 89 Batch 20: Train Loss = 0.1885\n",
      "Fold 2, roc = 0.8558, prc = 0.4896\n",
      "Fold 2 Epoch 90 Batch 0: Train Loss = 0.1881\n",
      "Fold 2 Epoch 90 Batch 5: Train Loss = 0.1909\n",
      "Fold 2 Epoch 90 Batch 10: Train Loss = 0.2682\n",
      "Fold 2 Epoch 90 Batch 15: Train Loss = 0.1762\n",
      "Fold 2 Epoch 90 Batch 20: Train Loss = 0.1963\n",
      "Fold 2, epoch 90: Loss = 0.1991 Valid loss = 0.4145 roc = 0.8622\n",
      "confusion matrix:\n",
      "[[1280  146]\n",
      " [ 110  137]]\n",
      "accuracy = 0.8469814658164978\n",
      "precision class 0 = 0.9208633303642273\n",
      "precision class 1 = 0.4840989410877228\n",
      "recall class 0 = 0.8976157307624817\n",
      "recall class 1 = 0.5546558499336243\n",
      "AUC of ROC = 0.8621650549937256\n",
      "AUC of PRC = 0.5683170941768725\n",
      "min(+P, Se) = 0.4959677419354839\n",
      "f1_score = 0.5169811089936845\n",
      "Fold 2, roc = 0.8622, prc = 0.5683\n",
      "Fold 2 Epoch 91 Batch 0: Train Loss = 0.2796\n",
      "Fold 2 Epoch 91 Batch 5: Train Loss = 0.1792\n",
      "Fold 2 Epoch 91 Batch 10: Train Loss = 0.2271\n",
      "Fold 2 Epoch 91 Batch 15: Train Loss = 1.3308\n",
      "Fold 2 Epoch 91 Batch 20: Train Loss = 0.4789\n",
      "Fold 2, roc = 0.6921, prc = 0.2355\n",
      "Fold 2 Epoch 92 Batch 0: Train Loss = 0.5941\n",
      "Fold 2 Epoch 92 Batch 5: Train Loss = 0.3826\n",
      "Fold 2 Epoch 92 Batch 10: Train Loss = 0.4586\n",
      "Fold 2 Epoch 92 Batch 15: Train Loss = 0.4384\n",
      "Fold 2 Epoch 92 Batch 20: Train Loss = 0.4341\n",
      "Fold 2, roc = 0.8036, prc = 0.3501\n",
      "Fold 2 Epoch 93 Batch 0: Train Loss = 0.4736\n",
      "Fold 2 Epoch 93 Batch 5: Train Loss = 0.4156\n",
      "Fold 2 Epoch 93 Batch 10: Train Loss = 0.4097\n",
      "Fold 2 Epoch 93 Batch 15: Train Loss = 0.3995\n",
      "Fold 2 Epoch 93 Batch 20: Train Loss = 0.4227\n",
      "Fold 2, roc = 0.7851, prc = 0.3518\n",
      "Fold 2 Epoch 94 Batch 0: Train Loss = 0.4396\n",
      "Fold 2 Epoch 94 Batch 5: Train Loss = 0.4180\n",
      "Fold 2 Epoch 94 Batch 10: Train Loss = 0.5564\n",
      "Fold 2 Epoch 94 Batch 15: Train Loss = 0.4432\n",
      "Fold 2 Epoch 94 Batch 20: Train Loss = 0.4721\n",
      "Fold 2, roc = 0.6895, prc = 0.2460\n",
      "Fold 2 Epoch 95 Batch 0: Train Loss = 0.4275\n",
      "Fold 2 Epoch 95 Batch 5: Train Loss = 0.4486\n",
      "Fold 2 Epoch 95 Batch 10: Train Loss = 0.4369\n",
      "Fold 2 Epoch 95 Batch 15: Train Loss = 0.4365\n",
      "Fold 2 Epoch 95 Batch 20: Train Loss = 0.4154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/other/choczhang/EMR/HM-COVID/utils/metrics.py:23: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  prec1 = cf[1][1] / (cf[1][1] + cf[0][1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, roc = 0.6930, prc = 0.2194\n",
      "Fold 2 Epoch 96 Batch 0: Train Loss = 0.4178\n",
      "Fold 2 Epoch 96 Batch 5: Train Loss = 0.3705\n",
      "Fold 2 Epoch 96 Batch 10: Train Loss = 0.4289\n",
      "Fold 2 Epoch 96 Batch 15: Train Loss = 0.3908\n",
      "Fold 2 Epoch 96 Batch 20: Train Loss = 0.4293\n",
      "Fold 2, roc = 0.6973, prc = 0.2609\n",
      "Fold 2 Epoch 97 Batch 0: Train Loss = 0.3726\n",
      "Fold 2 Epoch 97 Batch 5: Train Loss = 0.3948\n",
      "Fold 2 Epoch 97 Batch 10: Train Loss = 0.3644\n",
      "Fold 2 Epoch 97 Batch 15: Train Loss = 0.3809\n",
      "Fold 2 Epoch 97 Batch 20: Train Loss = 0.3891\n",
      "Fold 2, roc = 0.7349, prc = 0.2873\n",
      "Fold 2 Epoch 98 Batch 0: Train Loss = 0.3760\n",
      "Fold 2 Epoch 98 Batch 5: Train Loss = 0.3511\n",
      "Fold 2 Epoch 98 Batch 10: Train Loss = 0.4138\n",
      "Fold 2 Epoch 98 Batch 15: Train Loss = 0.4168\n",
      "Fold 2 Epoch 98 Batch 20: Train Loss = 0.3897\n",
      "Fold 2, roc = 0.7470, prc = 0.2872\n",
      "Fold 2 Epoch 99 Batch 0: Train Loss = 0.3385\n",
      "Fold 2 Epoch 99 Batch 5: Train Loss = 0.4576\n",
      "Fold 2 Epoch 99 Batch 10: Train Loss = 0.3345\n",
      "Fold 2 Epoch 99 Batch 15: Train Loss = 0.3537\n",
      "Fold 2 Epoch 99 Batch 20: Train Loss = 0.4260\n",
      "Fold 2, roc = 0.7586, prc = 0.2952\n",
      "Fold 2 Epoch 100 Batch 0: Train Loss = 0.3516\n",
      "Fold 2 Epoch 100 Batch 5: Train Loss = 0.3984\n",
      "Fold 2 Epoch 100 Batch 10: Train Loss = 0.4190\n",
      "Fold 2 Epoch 100 Batch 15: Train Loss = 0.3542\n",
      "Fold 2 Epoch 100 Batch 20: Train Loss = 0.3369\n",
      "Fold 2, epoch 100: Loss = 0.3610 Valid loss = 0.5950 roc = 0.7282\n",
      "confusion matrix:\n",
      "[[1120  306]\n",
      " [ 174   73]]\n",
      "accuracy = 0.7130902409553528\n",
      "precision class 0 = 0.8655332326889038\n",
      "precision class 1 = 0.19261214137077332\n",
      "recall class 0 = 0.7854137420654297\n",
      "recall class 1 = 0.2955465614795685\n",
      "AUC of ROC = 0.7281771155691581\n",
      "AUC of PRC = 0.22814647590063797\n",
      "min(+P, Se) = 0.2767732962447844\n",
      "f1_score = 0.23322684098003574\n",
      "Fold 2, roc = 0.7282, prc = 0.2281\n",
      "Fold 2 Epoch 101 Batch 0: Train Loss = 0.3796\n",
      "Fold 2 Epoch 101 Batch 5: Train Loss = 0.3835\n",
      "Fold 2 Epoch 101 Batch 10: Train Loss = 0.3157\n",
      "Fold 2 Epoch 101 Batch 15: Train Loss = 0.3273\n",
      "Fold 2 Epoch 101 Batch 20: Train Loss = 0.3310\n",
      "Fold 2, roc = 0.7924, prc = 0.2957\n",
      "Fold 2 Epoch 102 Batch 0: Train Loss = 0.3182\n",
      "Fold 2 Epoch 102 Batch 5: Train Loss = 0.3875\n",
      "Fold 2 Epoch 102 Batch 10: Train Loss = 0.3488\n",
      "Fold 2 Epoch 102 Batch 15: Train Loss = 0.2889\n",
      "Fold 2 Epoch 102 Batch 20: Train Loss = 0.3339\n",
      "Fold 2, roc = 0.8331, prc = 0.3539\n",
      "Fold 2 Epoch 103 Batch 0: Train Loss = 0.3192\n",
      "Fold 2 Epoch 103 Batch 5: Train Loss = 0.3127\n",
      "Fold 2 Epoch 103 Batch 10: Train Loss = 0.3142\n",
      "Fold 2 Epoch 103 Batch 15: Train Loss = 0.3416\n",
      "Fold 2 Epoch 103 Batch 20: Train Loss = 0.2880\n",
      "Fold 2, roc = 0.8338, prc = 0.3515\n",
      "Fold 2 Epoch 104 Batch 0: Train Loss = 0.3850\n",
      "Fold 2 Epoch 104 Batch 5: Train Loss = 0.3417\n",
      "Fold 2 Epoch 104 Batch 10: Train Loss = 0.2925\n",
      "Fold 2 Epoch 104 Batch 15: Train Loss = 0.2722\n",
      "Fold 2 Epoch 104 Batch 20: Train Loss = 0.3069\n",
      "Fold 2, roc = 0.8360, prc = 0.3907\n",
      "Fold 2 Epoch 105 Batch 0: Train Loss = 0.2876\n",
      "Fold 2 Epoch 105 Batch 5: Train Loss = 0.2848\n",
      "Fold 2 Epoch 105 Batch 10: Train Loss = 0.3452\n",
      "Fold 2 Epoch 105 Batch 15: Train Loss = 0.3058\n",
      "Fold 2 Epoch 105 Batch 20: Train Loss = 0.3405\n",
      "Fold 2, roc = 0.8609, prc = 0.4246\n",
      "Fold 2 Epoch 106 Batch 0: Train Loss = 0.3048\n",
      "Fold 2 Epoch 106 Batch 5: Train Loss = 0.2863\n",
      "Fold 2 Epoch 106 Batch 10: Train Loss = 0.2506\n",
      "Fold 2 Epoch 106 Batch 15: Train Loss = 0.2790\n",
      "Fold 2 Epoch 106 Batch 20: Train Loss = 0.2277\n",
      "Fold 2, roc = 0.8768, prc = 0.5447\n",
      "Fold 2 Epoch 107 Batch 0: Train Loss = 0.2595\n",
      "Fold 2 Epoch 107 Batch 5: Train Loss = 0.2092\n",
      "Fold 2 Epoch 107 Batch 10: Train Loss = 0.2617\n",
      "Fold 2 Epoch 107 Batch 15: Train Loss = 0.2209\n",
      "Fold 2 Epoch 107 Batch 20: Train Loss = 0.2039\n",
      "Fold 2, roc = 0.8940, prc = 0.5936\n",
      "Fold 2 Epoch 108 Batch 0: Train Loss = 0.2018\n",
      "Fold 2 Epoch 108 Batch 5: Train Loss = 0.1994\n",
      "Fold 2 Epoch 108 Batch 10: Train Loss = 0.2335\n",
      "Fold 2 Epoch 108 Batch 15: Train Loss = 0.2111\n",
      "Fold 2 Epoch 108 Batch 20: Train Loss = 0.2064\n",
      "Fold 2, roc = 0.8268, prc = 0.5593\n",
      "Fold 2 Epoch 109 Batch 0: Train Loss = 0.2209\n",
      "Fold 2 Epoch 109 Batch 5: Train Loss = 0.2124\n",
      "Fold 2 Epoch 109 Batch 10: Train Loss = 0.2103\n",
      "Fold 2 Epoch 109 Batch 15: Train Loss = 0.2921\n",
      "Fold 2 Epoch 109 Batch 20: Train Loss = 0.2254\n",
      "Fold 2, roc = 0.7131, prc = 0.4440\n",
      "Fold 2 Epoch 110 Batch 0: Train Loss = 0.2214\n",
      "Fold 2 Epoch 110 Batch 5: Train Loss = 0.2190\n",
      "Fold 2 Epoch 110 Batch 10: Train Loss = 0.1901\n",
      "Fold 2 Epoch 110 Batch 15: Train Loss = 0.2309\n",
      "Fold 2 Epoch 110 Batch 20: Train Loss = 0.2401\n",
      "Fold 2, epoch 110: Loss = 0.2084 Valid loss = 21.1120 roc = 0.4281\n",
      "confusion matrix:\n",
      "[[  66 1360]\n",
      " [   0  247]]\n",
      "accuracy = 0.18708905577659607\n",
      "precision class 0 = 1.0\n",
      "precision class 1 = 0.15370255708694458\n",
      "recall class 0 = 0.046283308416604996\n",
      "recall class 1 = 1.0\n",
      "AUC of ROC = 0.4280751912146317\n",
      "AUC of PRC = 0.4477629702797862\n",
      "min(+P, Se) = 0.15413533834586465\n",
      "f1_score = 0.2664509393407163\n",
      "Fold 2, roc = 0.4281, prc = 0.4478\n",
      "Fold 2 Epoch 111 Batch 0: Train Loss = 0.2321\n",
      "Fold 2 Epoch 111 Batch 5: Train Loss = 0.2213\n",
      "Fold 2 Epoch 111 Batch 10: Train Loss = 0.2552\n",
      "Fold 2 Epoch 111 Batch 15: Train Loss = 0.1830\n",
      "Fold 2 Epoch 111 Batch 20: Train Loss = 0.1732\n",
      "Fold 2, roc = 0.4520, prc = 0.2025\n",
      "Fold 2 Epoch 112 Batch 0: Train Loss = 0.2165\n",
      "Fold 2 Epoch 112 Batch 5: Train Loss = 0.1770\n",
      "Fold 2 Epoch 112 Batch 10: Train Loss = 0.1972\n",
      "Fold 2 Epoch 112 Batch 15: Train Loss = 0.2810\n",
      "Fold 2 Epoch 112 Batch 20: Train Loss = 0.1946\n",
      "Fold 2, roc = 0.8825, prc = 0.5900\n",
      "Fold 2 Epoch 113 Batch 0: Train Loss = 0.1839\n",
      "Fold 2 Epoch 113 Batch 5: Train Loss = 0.2137\n",
      "Fold 2 Epoch 113 Batch 10: Train Loss = 0.1927\n",
      "Fold 2 Epoch 113 Batch 15: Train Loss = 0.1655\n",
      "Fold 2 Epoch 113 Batch 20: Train Loss = 0.1926\n",
      "Fold 2, roc = 0.8822, prc = 0.5655\n",
      "Fold 2 Epoch 114 Batch 0: Train Loss = 0.2398\n",
      "Fold 2 Epoch 114 Batch 5: Train Loss = 0.1620\n",
      "Fold 2 Epoch 114 Batch 10: Train Loss = 0.1790\n",
      "Fold 2 Epoch 114 Batch 15: Train Loss = 0.1669\n",
      "Fold 2 Epoch 114 Batch 20: Train Loss = 0.2382\n",
      "Fold 2, roc = 0.8758, prc = 0.5942\n",
      "Fold 2 Epoch 115 Batch 0: Train Loss = 0.1905\n",
      "Fold 2 Epoch 115 Batch 5: Train Loss = 0.1875\n",
      "Fold 2 Epoch 115 Batch 10: Train Loss = 0.1741\n",
      "Fold 2 Epoch 115 Batch 15: Train Loss = 0.2254\n",
      "Fold 2 Epoch 115 Batch 20: Train Loss = 0.1672\n",
      "Fold 2, roc = 0.8852, prc = 0.5958\n",
      "Fold 2 Epoch 116 Batch 0: Train Loss = 0.2131\n",
      "Fold 2 Epoch 116 Batch 5: Train Loss = 0.1817\n",
      "Fold 2 Epoch 116 Batch 10: Train Loss = 0.1859\n",
      "Fold 2 Epoch 116 Batch 15: Train Loss = 0.2023\n",
      "Fold 2 Epoch 116 Batch 20: Train Loss = 0.1852\n",
      "Fold 2, roc = 0.8835, prc = 0.6064\n",
      "Fold 2 Epoch 117 Batch 0: Train Loss = 0.2337\n",
      "Fold 2 Epoch 117 Batch 5: Train Loss = 0.1561\n",
      "Fold 2 Epoch 117 Batch 10: Train Loss = 0.1728\n",
      "Fold 2 Epoch 117 Batch 15: Train Loss = 0.2104\n",
      "Fold 2 Epoch 117 Batch 20: Train Loss = 0.1908\n",
      "Fold 2, roc = 0.8836, prc = 0.6154\n",
      "Fold 2 Epoch 118 Batch 0: Train Loss = 0.1526\n",
      "Fold 2 Epoch 118 Batch 5: Train Loss = 0.1597\n",
      "Fold 2 Epoch 118 Batch 10: Train Loss = 0.1569\n",
      "Fold 2 Epoch 118 Batch 15: Train Loss = 0.2012\n",
      "Fold 2 Epoch 118 Batch 20: Train Loss = 0.2066\n",
      "Fold 2, roc = 0.8833, prc = 0.6026\n",
      "Fold 2 Epoch 119 Batch 0: Train Loss = 0.2203\n",
      "Fold 2 Epoch 119 Batch 5: Train Loss = 0.1384\n",
      "Fold 2 Epoch 119 Batch 10: Train Loss = 0.1847\n",
      "Fold 2 Epoch 119 Batch 15: Train Loss = 0.2251\n",
      "Fold 2 Epoch 119 Batch 20: Train Loss = 0.2016\n",
      "Fold 2, roc = 0.8822, prc = 0.5925\n",
      "Fold 2 Epoch 120 Batch 0: Train Loss = 0.2351\n",
      "Fold 2 Epoch 120 Batch 5: Train Loss = 0.1608\n",
      "Fold 2 Epoch 120 Batch 10: Train Loss = 0.1411\n",
      "Fold 2 Epoch 120 Batch 15: Train Loss = 0.1690\n",
      "Fold 2 Epoch 120 Batch 20: Train Loss = 0.1596\n",
      "Fold 2, epoch 120: Loss = 0.1842 Valid loss = 0.3704 roc = 0.8792\n",
      "confusion matrix:\n",
      "[[1286  140]\n",
      " [ 104  143]]\n",
      "accuracy = 0.8541542291641235\n",
      "precision class 0 = 0.9251798391342163\n",
      "precision class 1 = 0.5053003430366516\n",
      "recall class 0 = 0.9018232822418213\n",
      "recall class 1 = 0.5789473652839661\n",
      "AUC of ROC = 0.8791557597197222\n",
      "AUC of PRC = 0.5885256898791335\n",
      "min(+P, Se) = 0.532258064516129\n",
      "f1_score = 0.5396226342618147\n",
      "Fold 2, roc = 0.8792, prc = 0.5885\n",
      "Fold 2 Epoch 121 Batch 0: Train Loss = 0.1684\n",
      "Fold 2 Epoch 121 Batch 5: Train Loss = 0.2117\n",
      "Fold 2 Epoch 121 Batch 10: Train Loss = 0.1868\n",
      "Fold 2 Epoch 121 Batch 15: Train Loss = 0.1215\n",
      "Fold 2 Epoch 121 Batch 20: Train Loss = 0.1540\n",
      "Fold 2, roc = 0.8809, prc = 0.5955\n",
      "Fold 2 Epoch 122 Batch 0: Train Loss = 0.1874\n",
      "Fold 2 Epoch 122 Batch 5: Train Loss = 0.2498\n",
      "Fold 2 Epoch 122 Batch 10: Train Loss = 0.1599\n",
      "Fold 2 Epoch 122 Batch 15: Train Loss = 0.1646\n",
      "Fold 2 Epoch 122 Batch 20: Train Loss = 0.1791\n",
      "Fold 2, roc = 0.8837, prc = 0.5918\n",
      "Fold 2 Epoch 123 Batch 0: Train Loss = 0.1878\n",
      "Fold 2 Epoch 123 Batch 5: Train Loss = 0.1515\n",
      "Fold 2 Epoch 123 Batch 10: Train Loss = 0.1372\n",
      "Fold 2 Epoch 123 Batch 15: Train Loss = 0.1419\n",
      "Fold 2 Epoch 123 Batch 20: Train Loss = 0.1673\n",
      "Fold 2, roc = 0.8808, prc = 0.5813\n",
      "Fold 2 Epoch 124 Batch 0: Train Loss = 0.1820\n",
      "Fold 2 Epoch 124 Batch 5: Train Loss = 0.1590\n",
      "Fold 2 Epoch 124 Batch 10: Train Loss = 0.1856\n",
      "Fold 2 Epoch 124 Batch 15: Train Loss = 0.1360\n",
      "Fold 2 Epoch 124 Batch 20: Train Loss = 0.2168\n",
      "Fold 2, roc = 0.8756, prc = 0.5875\n",
      "Fold 2 Epoch 125 Batch 0: Train Loss = 0.1607\n",
      "Fold 2 Epoch 125 Batch 5: Train Loss = 0.2244\n",
      "Fold 2 Epoch 125 Batch 10: Train Loss = 0.1868\n",
      "Fold 2 Epoch 125 Batch 15: Train Loss = 0.2001\n",
      "Fold 2 Epoch 125 Batch 20: Train Loss = 0.1457\n",
      "Fold 2, roc = 0.8823, prc = 0.5936\n",
      "Fold 2 Epoch 126 Batch 0: Train Loss = 0.1652\n",
      "Fold 2 Epoch 126 Batch 5: Train Loss = 0.1364\n",
      "Fold 2 Epoch 126 Batch 10: Train Loss = 0.1882\n",
      "Fold 2 Epoch 126 Batch 15: Train Loss = 0.1929\n",
      "Fold 2 Epoch 126 Batch 20: Train Loss = 0.1728\n",
      "Fold 2, roc = 0.8731, prc = 0.5762\n",
      "Fold 2 Epoch 127 Batch 0: Train Loss = 0.1513\n",
      "Fold 2 Epoch 127 Batch 5: Train Loss = 0.1990\n",
      "Fold 2 Epoch 127 Batch 10: Train Loss = 0.1162\n",
      "Fold 2 Epoch 127 Batch 15: Train Loss = 0.1615\n",
      "Fold 2 Epoch 127 Batch 20: Train Loss = 0.1448\n",
      "Fold 2, roc = 0.8751, prc = 0.5806\n",
      "Fold 2 Epoch 128 Batch 0: Train Loss = 0.2017\n",
      "Fold 2 Epoch 128 Batch 5: Train Loss = 0.1679\n",
      "Fold 2 Epoch 128 Batch 10: Train Loss = 0.2727\n",
      "Fold 2 Epoch 128 Batch 15: Train Loss = 0.1916\n",
      "Fold 2 Epoch 128 Batch 20: Train Loss = 0.1590\n",
      "Fold 2, roc = 0.8756, prc = 0.5784\n",
      "Fold 2 Epoch 129 Batch 0: Train Loss = 0.2214\n",
      "Fold 2 Epoch 129 Batch 5: Train Loss = 0.1710\n",
      "Fold 2 Epoch 129 Batch 10: Train Loss = 0.2121\n",
      "Fold 2 Epoch 129 Batch 15: Train Loss = 0.1788\n",
      "Fold 2 Epoch 129 Batch 20: Train Loss = 0.1734\n",
      "Fold 2, roc = 0.8776, prc = 0.5798\n",
      "Fold 2 Epoch 130 Batch 0: Train Loss = 0.1897\n",
      "Fold 2 Epoch 130 Batch 5: Train Loss = 0.2092\n",
      "Fold 2 Epoch 130 Batch 10: Train Loss = 0.2016\n",
      "Fold 2 Epoch 130 Batch 15: Train Loss = 0.1431\n",
      "Fold 2 Epoch 130 Batch 20: Train Loss = 0.1914\n",
      "Fold 2, epoch 130: Loss = 0.1794 Valid loss = 0.4099 roc = 0.8791\n",
      "confusion matrix:\n",
      "[[1269  157]\n",
      " [  94  153]]\n",
      "accuracy = 0.8499701023101807\n",
      "precision class 0 = 0.931034505367279\n",
      "precision class 1 = 0.4935483932495117\n",
      "recall class 0 = 0.8899018168449402\n",
      "recall class 1 = 0.6194332242012024\n",
      "AUC of ROC = 0.879118851179086\n",
      "AUC of PRC = 0.5906748134991545\n",
      "min(+P, Se) = 0.5344129554655871\n",
      "f1_score = 0.5493716771399559\n",
      "Fold 2, roc = 0.8791, prc = 0.5907\n",
      "Fold 2 Epoch 131 Batch 0: Train Loss = 0.1701\n",
      "Fold 2 Epoch 131 Batch 5: Train Loss = 0.1360\n",
      "Fold 2 Epoch 131 Batch 10: Train Loss = 0.2107\n",
      "Fold 2 Epoch 131 Batch 15: Train Loss = 0.1857\n",
      "Fold 2 Epoch 131 Batch 20: Train Loss = 0.1421\n",
      "Fold 2, roc = 0.8783, prc = 0.5864\n",
      "Fold 2 Epoch 132 Batch 0: Train Loss = 0.1593\n",
      "Fold 2 Epoch 132 Batch 5: Train Loss = 0.1902\n",
      "Fold 2 Epoch 132 Batch 10: Train Loss = 0.1625\n",
      "Fold 2 Epoch 132 Batch 15: Train Loss = 0.2035\n",
      "Fold 2 Epoch 132 Batch 20: Train Loss = 0.1208\n",
      "Fold 2, roc = 0.8747, prc = 0.5853\n",
      "Fold 2 Epoch 133 Batch 0: Train Loss = 0.1700\n",
      "Fold 2 Epoch 133 Batch 5: Train Loss = 0.1984\n",
      "Fold 2 Epoch 133 Batch 10: Train Loss = 0.1816\n",
      "Fold 2 Epoch 133 Batch 15: Train Loss = 0.1900\n",
      "Fold 2 Epoch 133 Batch 20: Train Loss = 0.1204\n",
      "Fold 2, roc = 0.8813, prc = 0.5963\n",
      "Fold 2 Epoch 134 Batch 0: Train Loss = 0.1555\n",
      "Fold 2 Epoch 134 Batch 5: Train Loss = 0.1506\n",
      "Fold 2 Epoch 134 Batch 10: Train Loss = 0.1540\n",
      "Fold 2 Epoch 134 Batch 15: Train Loss = 0.2021\n",
      "Fold 2 Epoch 134 Batch 20: Train Loss = 0.2414\n",
      "Fold 2, roc = 0.8787, prc = 0.5952\n",
      "Fold 2 Epoch 135 Batch 0: Train Loss = 0.1486\n",
      "Fold 2 Epoch 135 Batch 5: Train Loss = 0.2126\n",
      "Fold 2 Epoch 135 Batch 10: Train Loss = 0.1632\n",
      "Fold 2 Epoch 135 Batch 15: Train Loss = 0.1231\n",
      "Fold 2 Epoch 135 Batch 20: Train Loss = 0.1656\n",
      "Fold 2, roc = 0.8806, prc = 0.5975\n",
      "Fold 2 Epoch 136 Batch 0: Train Loss = 0.1705\n",
      "Fold 2 Epoch 136 Batch 5: Train Loss = 0.1503\n",
      "Fold 2 Epoch 136 Batch 10: Train Loss = 0.1338\n",
      "Fold 2 Epoch 136 Batch 15: Train Loss = 0.1500\n",
      "Fold 2 Epoch 136 Batch 20: Train Loss = 0.1967\n",
      "Fold 2, roc = 0.8802, prc = 0.5956\n",
      "Fold 2 Epoch 137 Batch 0: Train Loss = 0.1690\n",
      "Fold 2 Epoch 137 Batch 5: Train Loss = 0.1531\n",
      "Fold 2 Epoch 137 Batch 10: Train Loss = 0.1485\n",
      "Fold 2 Epoch 137 Batch 15: Train Loss = 0.2041\n",
      "Fold 2 Epoch 137 Batch 20: Train Loss = 0.1560\n",
      "Fold 2, roc = 0.8701, prc = 0.5766\n",
      "Fold 2 Epoch 138 Batch 0: Train Loss = 0.1814\n",
      "Fold 2 Epoch 138 Batch 5: Train Loss = 0.1426\n",
      "Fold 2 Epoch 138 Batch 10: Train Loss = 0.1706\n",
      "Fold 2 Epoch 138 Batch 15: Train Loss = 0.1250\n",
      "Fold 2 Epoch 138 Batch 20: Train Loss = 0.1892\n",
      "Fold 2, roc = 0.8763, prc = 0.5841\n",
      "Fold 2 Epoch 139 Batch 0: Train Loss = 0.1944\n",
      "Fold 2 Epoch 139 Batch 5: Train Loss = 0.1650\n",
      "Fold 2 Epoch 139 Batch 10: Train Loss = 0.1578\n",
      "Fold 2 Epoch 139 Batch 15: Train Loss = 0.1559\n",
      "Fold 2 Epoch 139 Batch 20: Train Loss = 0.2024\n",
      "Fold 2, roc = 0.8744, prc = 0.5810\n",
      "Fold 2 Epoch 140 Batch 0: Train Loss = 0.1903\n",
      "Fold 2 Epoch 140 Batch 5: Train Loss = 0.1784\n",
      "Fold 2 Epoch 140 Batch 10: Train Loss = 0.1347\n",
      "Fold 2 Epoch 140 Batch 15: Train Loss = 0.2023\n",
      "Fold 2 Epoch 140 Batch 20: Train Loss = 0.1502\n",
      "Fold 2, epoch 140: Loss = 0.1838 Valid loss = 0.4840 roc = 0.8694\n",
      "confusion matrix:\n",
      "[[1207  219]\n",
      " [  86  161]]\n",
      "accuracy = 0.817692756652832\n",
      "precision class 0 = 0.9334880113601685\n",
      "precision class 1 = 0.4236842095851898\n",
      "recall class 0 = 0.8464235663414001\n",
      "recall class 1 = 0.6518218517303467\n",
      "AUC of ROC = 0.8693877724843989\n",
      "AUC of PRC = 0.5559618741024802\n",
      "min(+P, Se) = 0.49800796812749004\n",
      "f1_score = 0.5135566006022054\n",
      "Fold 2, roc = 0.8694, prc = 0.5560\n",
      "Fold 2 Epoch 141 Batch 0: Train Loss = 0.1659\n",
      "Fold 2 Epoch 141 Batch 5: Train Loss = 0.2464\n",
      "Fold 2 Epoch 141 Batch 10: Train Loss = 0.2175\n",
      "Fold 2 Epoch 141 Batch 15: Train Loss = 0.1854\n",
      "Fold 2 Epoch 141 Batch 20: Train Loss = 0.1700\n",
      "Fold 2, roc = 0.8700, prc = 0.5636\n",
      "Fold 2 Epoch 142 Batch 0: Train Loss = 0.1223\n",
      "Fold 2 Epoch 142 Batch 5: Train Loss = 0.1276\n",
      "Fold 2 Epoch 142 Batch 10: Train Loss = 0.1861\n",
      "Fold 2 Epoch 142 Batch 15: Train Loss = 0.1381\n",
      "Fold 2 Epoch 142 Batch 20: Train Loss = 0.1710\n",
      "Fold 2, roc = 0.8641, prc = 0.5527\n",
      "Fold 2 Epoch 143 Batch 0: Train Loss = 0.2086\n",
      "Fold 2 Epoch 143 Batch 5: Train Loss = 0.1736\n",
      "Fold 2 Epoch 143 Batch 10: Train Loss = 0.2183\n",
      "Fold 2 Epoch 143 Batch 15: Train Loss = 0.2090\n",
      "Fold 2 Epoch 143 Batch 20: Train Loss = 0.1731\n",
      "Fold 2, roc = 0.8693, prc = 0.5612\n",
      "Fold 2 Epoch 144 Batch 0: Train Loss = 0.2107\n",
      "Fold 2 Epoch 144 Batch 5: Train Loss = 0.1540\n",
      "Fold 2 Epoch 144 Batch 10: Train Loss = 0.1955\n",
      "Fold 2 Epoch 144 Batch 15: Train Loss = 0.1866\n",
      "Fold 2 Epoch 144 Batch 20: Train Loss = 0.1665\n",
      "Fold 2, roc = 0.8705, prc = 0.5681\n",
      "Fold 2 Epoch 145 Batch 0: Train Loss = 0.1428\n",
      "Fold 2 Epoch 145 Batch 5: Train Loss = 0.1579\n",
      "Fold 2 Epoch 145 Batch 10: Train Loss = 0.1717\n",
      "Fold 2 Epoch 145 Batch 15: Train Loss = 0.1390\n",
      "Fold 2 Epoch 145 Batch 20: Train Loss = 0.1676\n",
      "Fold 2, roc = 0.8655, prc = 0.5709\n",
      "Fold 2 Epoch 146 Batch 0: Train Loss = 0.1534\n",
      "Fold 2 Epoch 146 Batch 5: Train Loss = 0.1712\n",
      "Fold 2 Epoch 146 Batch 10: Train Loss = 0.1897\n",
      "Fold 2 Epoch 146 Batch 15: Train Loss = 0.2076\n",
      "Fold 2 Epoch 146 Batch 20: Train Loss = 0.1928\n",
      "Fold 2, roc = 0.8740, prc = 0.5750\n",
      "Fold 2 Epoch 147 Batch 0: Train Loss = 0.2089\n",
      "Fold 2 Epoch 147 Batch 5: Train Loss = 0.2105\n",
      "Fold 2 Epoch 147 Batch 10: Train Loss = 0.1616\n",
      "Fold 2 Epoch 147 Batch 15: Train Loss = 0.2095\n",
      "Fold 2 Epoch 147 Batch 20: Train Loss = 0.1325\n",
      "Fold 2, roc = 0.8712, prc = 0.5705\n",
      "Fold 2 Epoch 148 Batch 0: Train Loss = 0.1757\n",
      "Fold 2 Epoch 148 Batch 5: Train Loss = 0.1578\n",
      "Fold 2 Epoch 148 Batch 10: Train Loss = 0.1846\n",
      "Fold 2 Epoch 148 Batch 15: Train Loss = 0.2032\n",
      "Fold 2 Epoch 148 Batch 20: Train Loss = 0.1613\n",
      "Fold 2, roc = 0.8665, prc = 0.5643\n",
      "Fold 2 Epoch 149 Batch 0: Train Loss = 0.1733\n",
      "Fold 2 Epoch 149 Batch 5: Train Loss = 0.1681\n",
      "Fold 2 Epoch 149 Batch 10: Train Loss = 0.1894\n",
      "Fold 2 Epoch 149 Batch 15: Train Loss = 0.2030\n",
      "Fold 2 Epoch 149 Batch 20: Train Loss = 0.2135\n",
      "Fold 2, roc = 0.8614, prc = 0.5582\n",
      "Training data size: 6283, Validation data size: 1580\n",
      "Fold 3 Epoch 0 Batch 0: Train Loss = 0.7454\n",
      "Fold 3 Epoch 0 Batch 5: Train Loss = 0.6143\n",
      "Fold 3 Epoch 0 Batch 10: Train Loss = 0.5889\n",
      "Fold 3 Epoch 0 Batch 15: Train Loss = 0.5415\n",
      "Fold 3 Epoch 0 Batch 20: Train Loss = 0.5165\n",
      "Fold 3, epoch 0: Loss = 0.5860 Valid loss = 0.5456 roc = 0.8765\n",
      "confusion matrix:\n",
      "[[1259    0]\n",
      " [ 242   35]]\n",
      "accuracy = 0.8424479365348816\n",
      "precision class 0 = 0.8387741446495056\n",
      "precision class 1 = 1.0\n",
      "recall class 0 = 1.0\n",
      "recall class 1 = 0.12635378539562225\n",
      "AUC of ROC = 0.8764735062782621\n",
      "AUC of PRC = 0.697600358514737\n",
      "min(+P, Se) = 0.6021505376344086\n",
      "f1_score = 0.2243589750374132\n",
      "Fold 3, roc = 0.8765, prc = 0.6976\n",
      "Fold 3 Epoch 1 Batch 0: Train Loss = 0.4633\n",
      "Fold 3 Epoch 1 Batch 5: Train Loss = 0.4890\n",
      "Fold 3 Epoch 1 Batch 10: Train Loss = 0.4936\n",
      "Fold 3 Epoch 1 Batch 15: Train Loss = 0.4104\n",
      "Fold 3 Epoch 1 Batch 20: Train Loss = 0.4158\n",
      "Fold 3, roc = 0.8845, prc = 0.7146\n",
      "Fold 3 Epoch 2 Batch 0: Train Loss = 0.3924\n",
      "Fold 3 Epoch 2 Batch 5: Train Loss = 0.5187\n",
      "Fold 3 Epoch 2 Batch 10: Train Loss = 0.3871\n",
      "Fold 3 Epoch 2 Batch 15: Train Loss = 0.4012\n",
      "Fold 3 Epoch 2 Batch 20: Train Loss = 0.4396\n",
      "Fold 3, roc = 0.8944, prc = 0.7194\n",
      "Fold 3 Epoch 3 Batch 0: Train Loss = 0.3479\n",
      "Fold 3 Epoch 3 Batch 5: Train Loss = 0.3378\n",
      "Fold 3 Epoch 3 Batch 10: Train Loss = 0.3639\n",
      "Fold 3 Epoch 3 Batch 15: Train Loss = 0.3241\n",
      "Fold 3 Epoch 3 Batch 20: Train Loss = 0.3303\n",
      "Fold 3, roc = 0.8956, prc = 0.7314\n",
      "Fold 3 Epoch 4 Batch 0: Train Loss = 0.3180\n",
      "Fold 3 Epoch 4 Batch 5: Train Loss = 0.3171\n",
      "Fold 3 Epoch 4 Batch 10: Train Loss = 0.3603\n",
      "Fold 3 Epoch 4 Batch 15: Train Loss = 0.3099\n",
      "Fold 3 Epoch 4 Batch 20: Train Loss = 0.2954\n",
      "Fold 3, roc = 0.8800, prc = 0.7189\n",
      "Fold 3 Epoch 5 Batch 0: Train Loss = 0.3569\n",
      "Fold 3 Epoch 5 Batch 5: Train Loss = 0.4345\n",
      "Fold 3 Epoch 5 Batch 10: Train Loss = 0.2775\n",
      "Fold 3 Epoch 5 Batch 15: Train Loss = 0.3438\n",
      "Fold 3 Epoch 5 Batch 20: Train Loss = 0.2649\n",
      "Fold 3, roc = 0.8974, prc = 0.7291\n",
      "Fold 3 Epoch 6 Batch 0: Train Loss = 0.2820\n",
      "Fold 3 Epoch 6 Batch 5: Train Loss = 0.2641\n",
      "Fold 3 Epoch 6 Batch 10: Train Loss = 0.2597\n",
      "Fold 3 Epoch 6 Batch 15: Train Loss = 0.3029\n",
      "Fold 3 Epoch 6 Batch 20: Train Loss = 0.2942\n",
      "Fold 3, roc = 0.8933, prc = 0.7192\n",
      "Fold 3 Epoch 7 Batch 0: Train Loss = 0.2611\n",
      "Fold 3 Epoch 7 Batch 5: Train Loss = 0.3040\n",
      "Fold 3 Epoch 7 Batch 10: Train Loss = 0.2899\n",
      "Fold 3 Epoch 7 Batch 15: Train Loss = 0.3046\n",
      "Fold 3 Epoch 7 Batch 20: Train Loss = 0.3234\n",
      "Fold 3, roc = 0.8944, prc = 0.7239\n",
      "Fold 3 Epoch 8 Batch 0: Train Loss = 0.3082\n",
      "Fold 3 Epoch 8 Batch 5: Train Loss = 0.3524\n",
      "Fold 3 Epoch 8 Batch 10: Train Loss = 0.2583\n",
      "Fold 3 Epoch 8 Batch 15: Train Loss = 0.2910\n",
      "Fold 3 Epoch 8 Batch 20: Train Loss = 0.2845\n",
      "Fold 3, roc = 0.8937, prc = 0.7240\n",
      "Fold 3 Epoch 9 Batch 0: Train Loss = 0.2465\n",
      "Fold 3 Epoch 9 Batch 5: Train Loss = 0.2644\n",
      "Fold 3 Epoch 9 Batch 10: Train Loss = 0.3547\n",
      "Fold 3 Epoch 9 Batch 15: Train Loss = 0.2781\n",
      "Fold 3 Epoch 9 Batch 20: Train Loss = 0.2679\n",
      "Fold 3, roc = 0.8997, prc = 0.7228\n",
      "Fold 3 Epoch 10 Batch 0: Train Loss = 0.3492\n",
      "Fold 3 Epoch 10 Batch 5: Train Loss = 0.3084\n",
      "Fold 3 Epoch 10 Batch 10: Train Loss = 0.2261\n",
      "Fold 3 Epoch 10 Batch 15: Train Loss = 0.2863\n",
      "Fold 3 Epoch 10 Batch 20: Train Loss = 0.2964\n",
      "Fold 3, epoch 10: Loss = 0.2759 Valid loss = 0.2901 roc = 0.8943\n",
      "confusion matrix:\n",
      "[[1216   43]\n",
      " [ 140  137]]\n",
      "accuracy = 0.880859375\n",
      "precision class 0 = 0.8967551589012146\n",
      "precision class 1 = 0.7611111402511597\n",
      "recall class 0 = 0.9658458828926086\n",
      "recall class 1 = 0.4945848286151886\n",
      "AUC of ROC = 0.8943089897144888\n",
      "AUC of PRC = 0.7166865790081415\n",
      "min(+P, Se) = 0.6425992779783394\n",
      "f1_score = 0.5995623799481553\n",
      "Fold 3, roc = 0.8943, prc = 0.7167\n",
      "Fold 3 Epoch 11 Batch 0: Train Loss = 0.2545\n",
      "Fold 3 Epoch 11 Batch 5: Train Loss = 0.2192\n",
      "Fold 3 Epoch 11 Batch 10: Train Loss = 0.2759\n",
      "Fold 3 Epoch 11 Batch 15: Train Loss = 0.2957\n",
      "Fold 3 Epoch 11 Batch 20: Train Loss = 0.2658\n",
      "------------ Save best model - AUROC: 0.9069 ------------\n",
      "Fold 3, roc = 0.9069, prc = 0.7287\n",
      "Fold 3 Epoch 12 Batch 0: Train Loss = 0.2670\n",
      "Fold 3 Epoch 12 Batch 5: Train Loss = 0.2374\n",
      "Fold 3 Epoch 12 Batch 10: Train Loss = 0.2901\n",
      "Fold 3 Epoch 12 Batch 15: Train Loss = 0.2726\n",
      "Fold 3 Epoch 12 Batch 20: Train Loss = 0.2435\n",
      "Fold 3, roc = 0.9039, prc = 0.7223\n",
      "Fold 3 Epoch 13 Batch 0: Train Loss = 0.2325\n",
      "Fold 3 Epoch 13 Batch 5: Train Loss = 0.2539\n",
      "Fold 3 Epoch 13 Batch 10: Train Loss = 0.2142\n",
      "Fold 3 Epoch 13 Batch 15: Train Loss = 0.2565\n",
      "Fold 3 Epoch 13 Batch 20: Train Loss = 0.2608\n",
      "------------ Save best model - AUROC: 0.9087 ------------\n",
      "Fold 3, roc = 0.9087, prc = 0.7307\n",
      "Fold 3 Epoch 14 Batch 0: Train Loss = 0.2587\n",
      "Fold 3 Epoch 14 Batch 5: Train Loss = 0.2298\n",
      "Fold 3 Epoch 14 Batch 10: Train Loss = 0.2639\n",
      "Fold 3 Epoch 14 Batch 15: Train Loss = 0.2794\n",
      "Fold 3 Epoch 14 Batch 20: Train Loss = 0.2360\n",
      "Fold 3, roc = 0.8991, prc = 0.7189\n",
      "Fold 3 Epoch 15 Batch 0: Train Loss = 0.2690\n",
      "Fold 3 Epoch 15 Batch 5: Train Loss = 0.1711\n",
      "Fold 3 Epoch 15 Batch 10: Train Loss = 0.2072\n",
      "Fold 3 Epoch 15 Batch 15: Train Loss = 0.2844\n",
      "Fold 3 Epoch 15 Batch 20: Train Loss = 0.2397\n",
      "Fold 3, roc = 0.8995, prc = 0.7212\n",
      "Fold 3 Epoch 16 Batch 0: Train Loss = 0.3364\n",
      "Fold 3 Epoch 16 Batch 5: Train Loss = 0.2987\n",
      "Fold 3 Epoch 16 Batch 10: Train Loss = 0.2462\n",
      "Fold 3 Epoch 16 Batch 15: Train Loss = 0.2719\n",
      "Fold 3 Epoch 16 Batch 20: Train Loss = 0.2225\n",
      "Fold 3, roc = 0.9012, prc = 0.7178\n",
      "Fold 3 Epoch 17 Batch 0: Train Loss = 0.2536\n",
      "Fold 3 Epoch 17 Batch 5: Train Loss = 0.3012\n",
      "Fold 3 Epoch 17 Batch 10: Train Loss = 0.2373\n",
      "Fold 3 Epoch 17 Batch 15: Train Loss = 0.2481\n",
      "Fold 3 Epoch 17 Batch 20: Train Loss = 0.2591\n",
      "Fold 3, roc = 0.9050, prc = 0.7183\n",
      "Fold 3 Epoch 18 Batch 0: Train Loss = 0.2112\n",
      "Fold 3 Epoch 18 Batch 5: Train Loss = 0.2204\n",
      "Fold 3 Epoch 18 Batch 10: Train Loss = 0.2935\n",
      "Fold 3 Epoch 18 Batch 15: Train Loss = 0.2119\n",
      "Fold 3 Epoch 18 Batch 20: Train Loss = 0.2647\n",
      "------------ Save best model - AUROC: 0.9091 ------------\n",
      "Fold 3, roc = 0.9091, prc = 0.7312\n",
      "Fold 3 Epoch 19 Batch 0: Train Loss = 0.2311\n",
      "Fold 3 Epoch 19 Batch 5: Train Loss = 0.2385\n",
      "Fold 3 Epoch 19 Batch 10: Train Loss = 0.1935\n",
      "Fold 3 Epoch 19 Batch 15: Train Loss = 0.2697\n",
      "Fold 3 Epoch 19 Batch 20: Train Loss = 0.2469\n",
      "Fold 3, roc = 0.9007, prc = 0.7219\n",
      "Fold 3 Epoch 20 Batch 0: Train Loss = 0.2794\n",
      "Fold 3 Epoch 20 Batch 5: Train Loss = 0.2189\n",
      "Fold 3 Epoch 20 Batch 10: Train Loss = 0.2115\n",
      "Fold 3 Epoch 20 Batch 15: Train Loss = 0.2386\n",
      "Fold 3 Epoch 20 Batch 20: Train Loss = 0.1884\n",
      "Fold 3, epoch 20: Loss = 0.2450 Valid loss = 0.2863 roc = 0.9044\n",
      "confusion matrix:\n",
      "[[1184   75]\n",
      " [ 109  168]]\n",
      "accuracy = 0.8802083134651184\n",
      "precision class 0 = 0.9156998991966248\n",
      "precision class 1 = 0.6913580298423767\n",
      "recall class 0 = 0.9404289126396179\n",
      "recall class 1 = 0.6064981818199158\n",
      "AUC of ROC = 0.9043593706540347\n",
      "AUC of PRC = 0.7254062085342353\n",
      "min(+P, Se) = 0.6606498194945848\n",
      "f1_score = 0.6461538409543106\n",
      "Fold 3, roc = 0.9044, prc = 0.7254\n",
      "Fold 3 Epoch 21 Batch 0: Train Loss = 0.2015\n",
      "Fold 3 Epoch 21 Batch 5: Train Loss = 0.2700\n",
      "Fold 3 Epoch 21 Batch 10: Train Loss = 0.2366\n",
      "Fold 3 Epoch 21 Batch 15: Train Loss = 0.1948\n",
      "Fold 3 Epoch 21 Batch 20: Train Loss = 0.2588\n",
      "Fold 3, roc = 0.9000, prc = 0.7135\n",
      "Fold 3 Epoch 22 Batch 0: Train Loss = 0.2038\n",
      "Fold 3 Epoch 22 Batch 5: Train Loss = 0.2692\n",
      "Fold 3 Epoch 22 Batch 10: Train Loss = 0.2413\n",
      "Fold 3 Epoch 22 Batch 15: Train Loss = 0.2241\n",
      "Fold 3 Epoch 22 Batch 20: Train Loss = 0.2371\n",
      "Fold 3, roc = 0.8983, prc = 0.7053\n",
      "Fold 3 Epoch 23 Batch 0: Train Loss = 0.2641\n",
      "Fold 3 Epoch 23 Batch 5: Train Loss = 0.2032\n",
      "Fold 3 Epoch 23 Batch 10: Train Loss = 0.2554\n",
      "Fold 3 Epoch 23 Batch 15: Train Loss = 0.1898\n",
      "Fold 3 Epoch 23 Batch 20: Train Loss = 0.2139\n",
      "Fold 3, roc = 0.9037, prc = 0.7162\n",
      "Fold 3 Epoch 24 Batch 0: Train Loss = 0.2538\n",
      "Fold 3 Epoch 24 Batch 5: Train Loss = 0.1657\n",
      "Fold 3 Epoch 24 Batch 10: Train Loss = 0.2388\n",
      "Fold 3 Epoch 24 Batch 15: Train Loss = 0.2760\n",
      "Fold 3 Epoch 24 Batch 20: Train Loss = 0.2581\n",
      "Fold 3, roc = 0.9026, prc = 0.7226\n",
      "Fold 3 Epoch 25 Batch 0: Train Loss = 0.2454\n",
      "Fold 3 Epoch 25 Batch 5: Train Loss = 0.2804\n",
      "Fold 3 Epoch 25 Batch 10: Train Loss = 0.2632\n",
      "Fold 3 Epoch 25 Batch 15: Train Loss = 0.2637\n",
      "Fold 3 Epoch 25 Batch 20: Train Loss = 0.2242\n",
      "Fold 3, roc = 0.9013, prc = 0.7168\n",
      "Fold 3 Epoch 26 Batch 0: Train Loss = 0.2158\n",
      "Fold 3 Epoch 26 Batch 5: Train Loss = 0.2208\n",
      "Fold 3 Epoch 26 Batch 10: Train Loss = 0.2719\n",
      "Fold 3 Epoch 26 Batch 15: Train Loss = 0.2271\n",
      "Fold 3 Epoch 26 Batch 20: Train Loss = 0.2422\n",
      "Fold 3, roc = 0.9042, prc = 0.7189\n",
      "Fold 3 Epoch 27 Batch 0: Train Loss = 0.2359\n",
      "Fold 3 Epoch 27 Batch 5: Train Loss = 0.2634\n",
      "Fold 3 Epoch 27 Batch 10: Train Loss = 0.2423\n",
      "Fold 3 Epoch 27 Batch 15: Train Loss = 0.1930\n",
      "Fold 3 Epoch 27 Batch 20: Train Loss = 0.2163\n",
      "Fold 3, roc = 0.9062, prc = 0.7319\n",
      "Fold 3 Epoch 28 Batch 0: Train Loss = 0.2459\n",
      "Fold 3 Epoch 28 Batch 5: Train Loss = 0.2571\n",
      "Fold 3 Epoch 28 Batch 10: Train Loss = 0.2163\n",
      "Fold 3 Epoch 28 Batch 15: Train Loss = 0.2876\n",
      "Fold 3 Epoch 28 Batch 20: Train Loss = 0.3248\n",
      "Fold 3, roc = 0.8985, prc = 0.7145\n",
      "Fold 3 Epoch 29 Batch 0: Train Loss = 0.2096\n",
      "Fold 3 Epoch 29 Batch 5: Train Loss = 0.2304\n",
      "Fold 3 Epoch 29 Batch 10: Train Loss = 0.2184\n",
      "Fold 3 Epoch 29 Batch 15: Train Loss = 0.2268\n",
      "Fold 3 Epoch 29 Batch 20: Train Loss = 0.2679\n",
      "Fold 3, roc = 0.8993, prc = 0.7189\n",
      "Fold 3 Epoch 30 Batch 0: Train Loss = 0.2192\n",
      "Fold 3 Epoch 30 Batch 5: Train Loss = 0.2464\n",
      "Fold 3 Epoch 30 Batch 10: Train Loss = 0.2525\n",
      "Fold 3 Epoch 30 Batch 15: Train Loss = 0.2380\n",
      "Fold 3 Epoch 30 Batch 20: Train Loss = 0.2262\n",
      "Fold 3, epoch 30: Loss = 0.2299 Valid loss = 0.3129 roc = 0.9026\n",
      "confusion matrix:\n",
      "[[1153  106]\n",
      " [  84  193]]\n",
      "accuracy = 0.8763020634651184\n",
      "precision class 0 = 0.9320937991142273\n",
      "precision class 1 = 0.6454849243164062\n",
      "recall class 0 = 0.9158061742782593\n",
      "recall class 1 = 0.6967508792877197\n",
      "AUC of ROC = 0.9026446408960179\n",
      "AUC of PRC = 0.7267396673462725\n",
      "min(+P, Se) = 0.6642599277978339\n",
      "f1_score = 0.6701388643884939\n",
      "Fold 3, roc = 0.9026, prc = 0.7267\n",
      "Fold 3 Epoch 31 Batch 0: Train Loss = 0.1915\n",
      "Fold 3 Epoch 31 Batch 5: Train Loss = 0.2384\n",
      "Fold 3 Epoch 31 Batch 10: Train Loss = 0.2388\n",
      "Fold 3 Epoch 31 Batch 15: Train Loss = 0.1921\n",
      "Fold 3 Epoch 31 Batch 20: Train Loss = 0.2854\n",
      "Fold 3, roc = 0.9085, prc = 0.7357\n",
      "Fold 3 Epoch 32 Batch 0: Train Loss = 0.1990\n",
      "Fold 3 Epoch 32 Batch 5: Train Loss = 0.2193\n",
      "Fold 3 Epoch 32 Batch 10: Train Loss = 0.1706\n",
      "Fold 3 Epoch 32 Batch 15: Train Loss = 0.1648\n",
      "Fold 3 Epoch 32 Batch 20: Train Loss = 0.2166\n",
      "Fold 3, roc = 0.9009, prc = 0.7322\n",
      "Fold 3 Epoch 33 Batch 0: Train Loss = 0.2368\n",
      "Fold 3 Epoch 33 Batch 5: Train Loss = 0.2614\n",
      "Fold 3 Epoch 33 Batch 10: Train Loss = 0.2470\n",
      "Fold 3 Epoch 33 Batch 15: Train Loss = 0.2186\n",
      "Fold 3 Epoch 33 Batch 20: Train Loss = 0.1859\n",
      "Fold 3, roc = 0.9012, prc = 0.7156\n",
      "Fold 3 Epoch 34 Batch 0: Train Loss = 0.1568\n",
      "Fold 3 Epoch 34 Batch 5: Train Loss = 0.1790\n",
      "Fold 3 Epoch 34 Batch 10: Train Loss = 0.1833\n",
      "Fold 3 Epoch 34 Batch 15: Train Loss = 0.2934\n",
      "Fold 3 Epoch 34 Batch 20: Train Loss = 0.1805\n",
      "------------ Save best model - AUROC: 0.9093 ------------\n",
      "Fold 3, roc = 0.9093, prc = 0.7432\n",
      "Fold 3 Epoch 35 Batch 0: Train Loss = 0.2216\n",
      "Fold 3 Epoch 35 Batch 5: Train Loss = 0.1887\n",
      "Fold 3 Epoch 35 Batch 10: Train Loss = 0.2413\n",
      "Fold 3 Epoch 35 Batch 15: Train Loss = 0.2342\n",
      "Fold 3 Epoch 35 Batch 20: Train Loss = 0.2083\n",
      "Fold 3, roc = 0.9015, prc = 0.7160\n",
      "Fold 3 Epoch 36 Batch 0: Train Loss = 0.2789\n",
      "Fold 3 Epoch 36 Batch 5: Train Loss = 0.2901\n",
      "Fold 3 Epoch 36 Batch 10: Train Loss = 0.2201\n",
      "Fold 3 Epoch 36 Batch 15: Train Loss = 0.2795\n",
      "Fold 3 Epoch 36 Batch 20: Train Loss = 0.2563\n",
      "Fold 3, roc = 0.8944, prc = 0.7152\n",
      "Fold 3 Epoch 37 Batch 0: Train Loss = 0.2857\n",
      "Fold 3 Epoch 37 Batch 5: Train Loss = 0.2454\n",
      "Fold 3 Epoch 37 Batch 10: Train Loss = 0.2620\n",
      "Fold 3 Epoch 37 Batch 15: Train Loss = 0.2771\n",
      "Fold 3 Epoch 37 Batch 20: Train Loss = 0.2527\n",
      "------------ Save best model - AUROC: 0.9144 ------------\n",
      "Fold 3, roc = 0.9144, prc = 0.7326\n",
      "Fold 3 Epoch 38 Batch 0: Train Loss = 0.3024\n",
      "Fold 3 Epoch 38 Batch 5: Train Loss = 0.2277\n",
      "Fold 3 Epoch 38 Batch 10: Train Loss = 0.1909\n",
      "Fold 3 Epoch 38 Batch 15: Train Loss = 0.3066\n",
      "Fold 3 Epoch 38 Batch 20: Train Loss = 0.2560\n",
      "Fold 3, roc = 0.8888, prc = 0.6825\n",
      "Fold 3 Epoch 39 Batch 0: Train Loss = 0.2376\n",
      "Fold 3 Epoch 39 Batch 5: Train Loss = 0.3302\n",
      "Fold 3 Epoch 39 Batch 10: Train Loss = 0.2438\n",
      "Fold 3 Epoch 39 Batch 15: Train Loss = 0.3248\n",
      "Fold 3 Epoch 39 Batch 20: Train Loss = 0.2489\n",
      "Fold 3, roc = 0.8884, prc = 0.6576\n",
      "Fold 3 Epoch 40 Batch 0: Train Loss = 0.2301\n",
      "Fold 3 Epoch 40 Batch 5: Train Loss = 0.2543\n",
      "Fold 3 Epoch 40 Batch 10: Train Loss = 0.2957\n",
      "Fold 3 Epoch 40 Batch 15: Train Loss = 0.2349\n",
      "Fold 3 Epoch 40 Batch 20: Train Loss = 0.2353\n",
      "Fold 3, epoch 40: Loss = 0.2539 Valid loss = 0.3094 roc = 0.8994\n",
      "confusion matrix:\n",
      "[[1171   88]\n",
      " [ 111  166]]\n",
      "accuracy = 0.8704426884651184\n",
      "precision class 0 = 0.9134165644645691\n",
      "precision class 1 = 0.6535432934761047\n",
      "recall class 0 = 0.9301032423973083\n",
      "recall class 1 = 0.5992779731750488\n",
      "AUC of ROC = 0.8994445766653381\n",
      "AUC of PRC = 0.6823570672332436\n",
      "min(+P, Se) = 0.6353790613718412\n",
      "f1_score = 0.6252354256036579\n",
      "Fold 3, roc = 0.8994, prc = 0.6824\n",
      "Fold 3 Epoch 41 Batch 0: Train Loss = 0.2468\n",
      "Fold 3 Epoch 41 Batch 5: Train Loss = 0.2560\n",
      "Fold 3 Epoch 41 Batch 10: Train Loss = 0.2205\n",
      "Fold 3 Epoch 41 Batch 15: Train Loss = 0.2942\n",
      "Fold 3 Epoch 41 Batch 20: Train Loss = 0.2837\n",
      "Fold 3, roc = 0.8934, prc = 0.6949\n",
      "Fold 3 Epoch 42 Batch 0: Train Loss = 0.2435\n",
      "Fold 3 Epoch 42 Batch 5: Train Loss = 0.2256\n",
      "Fold 3 Epoch 42 Batch 10: Train Loss = 0.2683\n",
      "Fold 3 Epoch 42 Batch 15: Train Loss = 0.1958\n",
      "Fold 3 Epoch 42 Batch 20: Train Loss = 0.2588\n",
      "Fold 3, roc = 0.9075, prc = 0.7133\n",
      "Fold 3 Epoch 43 Batch 0: Train Loss = 0.2114\n",
      "Fold 3 Epoch 43 Batch 5: Train Loss = 0.2374\n",
      "Fold 3 Epoch 43 Batch 10: Train Loss = 0.1791\n",
      "Fold 3 Epoch 43 Batch 15: Train Loss = 0.2402\n",
      "Fold 3 Epoch 43 Batch 20: Train Loss = 0.2511\n",
      "------------ Save best model - AUROC: 0.9190 ------------\n",
      "Fold 3, roc = 0.9190, prc = 0.7551\n",
      "Fold 3 Epoch 44 Batch 0: Train Loss = 0.2289\n",
      "Fold 3 Epoch 44 Batch 5: Train Loss = 0.2583\n",
      "Fold 3 Epoch 44 Batch 10: Train Loss = 0.2794\n",
      "Fold 3 Epoch 44 Batch 15: Train Loss = 0.2154\n",
      "Fold 3 Epoch 44 Batch 20: Train Loss = 0.2602\n",
      "Fold 3, roc = 0.8925, prc = 0.6129\n",
      "Fold 3 Epoch 45 Batch 0: Train Loss = 0.2256\n",
      "Fold 3 Epoch 45 Batch 5: Train Loss = 0.2313\n",
      "Fold 3 Epoch 45 Batch 10: Train Loss = 0.2873\n",
      "Fold 3 Epoch 45 Batch 15: Train Loss = 0.2557\n",
      "Fold 3 Epoch 45 Batch 20: Train Loss = 0.1644\n",
      "Fold 3, roc = 0.9090, prc = 0.7321\n",
      "Fold 3 Epoch 46 Batch 0: Train Loss = 0.1916\n",
      "Fold 3 Epoch 46 Batch 5: Train Loss = 0.2318\n",
      "Fold 3 Epoch 46 Batch 10: Train Loss = 0.2047\n",
      "Fold 3 Epoch 46 Batch 15: Train Loss = 0.1747\n",
      "Fold 3 Epoch 46 Batch 20: Train Loss = 0.1919\n",
      "Fold 3, roc = 0.9097, prc = 0.7312\n",
      "Fold 3 Epoch 47 Batch 0: Train Loss = 0.2723\n",
      "Fold 3 Epoch 47 Batch 5: Train Loss = 0.1879\n",
      "Fold 3 Epoch 47 Batch 10: Train Loss = 0.1757\n",
      "Fold 3 Epoch 47 Batch 15: Train Loss = 0.2376\n",
      "Fold 3 Epoch 47 Batch 20: Train Loss = 0.2081\n",
      "Fold 3, roc = 0.9082, prc = 0.7274\n",
      "Fold 3 Epoch 48 Batch 0: Train Loss = 0.2312\n",
      "Fold 3 Epoch 48 Batch 5: Train Loss = 0.1993\n",
      "Fold 3 Epoch 48 Batch 10: Train Loss = 0.2065\n",
      "Fold 3 Epoch 48 Batch 15: Train Loss = 0.1852\n",
      "Fold 3 Epoch 48 Batch 20: Train Loss = 0.2068\n",
      "Fold 3, roc = 0.9073, prc = 0.7336\n",
      "Fold 3 Epoch 49 Batch 0: Train Loss = 0.2355\n",
      "Fold 3 Epoch 49 Batch 5: Train Loss = 0.1938\n",
      "Fold 3 Epoch 49 Batch 10: Train Loss = 0.2828\n",
      "Fold 3 Epoch 49 Batch 15: Train Loss = 0.1928\n",
      "Fold 3 Epoch 49 Batch 20: Train Loss = 0.1636\n",
      "Fold 3, roc = 0.9053, prc = 0.7330\n",
      "Fold 3 Epoch 50 Batch 0: Train Loss = 0.1340\n",
      "Fold 3 Epoch 50 Batch 5: Train Loss = 0.1526\n",
      "Fold 3 Epoch 50 Batch 10: Train Loss = 0.2100\n",
      "Fold 3 Epoch 50 Batch 15: Train Loss = 0.1871\n",
      "Fold 3 Epoch 50 Batch 20: Train Loss = 0.2223\n",
      "Fold 3, epoch 50: Loss = 0.2071 Valid loss = 0.3036 roc = 0.9062\n",
      "confusion matrix:\n",
      "[[1172   87]\n",
      " [  91  186]]\n",
      "accuracy = 0.8841145634651184\n",
      "precision class 0 = 0.9279493093490601\n",
      "precision class 1 = 0.6813187003135681\n",
      "recall class 0 = 0.9308975338935852\n",
      "recall class 1 = 0.671480119228363\n",
      "AUC of ROC = 0.9061773282904604\n",
      "AUC of PRC = 0.7332453616356571\n",
      "min(+P, Se) = 0.6834532374100719\n",
      "f1_score = 0.6763636329516884\n",
      "Fold 3, roc = 0.9062, prc = 0.7332\n",
      "Fold 3 Epoch 51 Batch 0: Train Loss = 0.2156\n",
      "Fold 3 Epoch 51 Batch 5: Train Loss = 0.1854\n",
      "Fold 3 Epoch 51 Batch 10: Train Loss = 0.1880\n",
      "Fold 3 Epoch 51 Batch 15: Train Loss = 0.2004\n",
      "Fold 3 Epoch 51 Batch 20: Train Loss = 0.1584\n",
      "Fold 3, roc = 0.9009, prc = 0.7238\n",
      "Fold 3 Epoch 52 Batch 0: Train Loss = 0.2409\n",
      "Fold 3 Epoch 52 Batch 5: Train Loss = 0.1858\n",
      "Fold 3 Epoch 52 Batch 10: Train Loss = 0.2480\n",
      "Fold 3 Epoch 52 Batch 15: Train Loss = 0.1851\n",
      "Fold 3 Epoch 52 Batch 20: Train Loss = 0.1990\n",
      "Fold 3, roc = 0.9078, prc = 0.7342\n",
      "Fold 3 Epoch 53 Batch 0: Train Loss = 0.1297\n",
      "Fold 3 Epoch 53 Batch 5: Train Loss = 0.2103\n",
      "Fold 3 Epoch 53 Batch 10: Train Loss = 0.1651\n",
      "Fold 3 Epoch 53 Batch 15: Train Loss = 0.1791\n",
      "Fold 3 Epoch 53 Batch 20: Train Loss = 0.2482\n",
      "Fold 3, roc = 0.9085, prc = 0.7391\n",
      "Fold 3 Epoch 54 Batch 0: Train Loss = 0.1870\n",
      "Fold 3 Epoch 54 Batch 5: Train Loss = 0.2006\n",
      "Fold 3 Epoch 54 Batch 10: Train Loss = 0.2075\n",
      "Fold 3 Epoch 54 Batch 15: Train Loss = 0.3036\n",
      "Fold 3 Epoch 54 Batch 20: Train Loss = 0.2265\n",
      "Fold 3, roc = 0.9033, prc = 0.7284\n",
      "Fold 3 Epoch 55 Batch 0: Train Loss = 0.1568\n",
      "Fold 3 Epoch 55 Batch 5: Train Loss = 0.2069\n",
      "Fold 3 Epoch 55 Batch 10: Train Loss = 0.1780\n",
      "Fold 3 Epoch 55 Batch 15: Train Loss = 0.1906\n",
      "Fold 3 Epoch 55 Batch 20: Train Loss = 0.2490\n",
      "Fold 3, roc = 0.9040, prc = 0.7256\n",
      "Fold 3 Epoch 56 Batch 0: Train Loss = 0.2235\n",
      "Fold 3 Epoch 56 Batch 5: Train Loss = 0.1655\n",
      "Fold 3 Epoch 56 Batch 10: Train Loss = 0.2127\n",
      "Fold 3 Epoch 56 Batch 15: Train Loss = 0.2098\n",
      "Fold 3 Epoch 56 Batch 20: Train Loss = 0.1868\n",
      "Fold 3, roc = 0.9058, prc = 0.7402\n",
      "Fold 3 Epoch 57 Batch 0: Train Loss = 0.1807\n",
      "Fold 3 Epoch 57 Batch 5: Train Loss = 0.1999\n",
      "Fold 3 Epoch 57 Batch 10: Train Loss = 0.2234\n",
      "Fold 3 Epoch 57 Batch 15: Train Loss = 0.2076\n",
      "Fold 3 Epoch 57 Batch 20: Train Loss = 0.2009\n",
      "Fold 3, roc = 0.9025, prc = 0.7358\n",
      "Fold 3 Epoch 58 Batch 0: Train Loss = 0.1786\n",
      "Fold 3 Epoch 58 Batch 5: Train Loss = 0.1794\n",
      "Fold 3 Epoch 58 Batch 10: Train Loss = 0.1409\n",
      "Fold 3 Epoch 58 Batch 15: Train Loss = 0.2541\n",
      "Fold 3 Epoch 58 Batch 20: Train Loss = 0.1450\n",
      "Fold 3, roc = 0.9084, prc = 0.7412\n",
      "Fold 3 Epoch 59 Batch 0: Train Loss = 0.1764\n",
      "Fold 3 Epoch 59 Batch 5: Train Loss = 0.2232\n",
      "Fold 3 Epoch 59 Batch 10: Train Loss = 0.2006\n",
      "Fold 3 Epoch 59 Batch 15: Train Loss = 0.1997\n",
      "Fold 3 Epoch 59 Batch 20: Train Loss = 0.2269\n",
      "Fold 3, roc = 0.9046, prc = 0.7374\n",
      "Fold 3 Epoch 60 Batch 0: Train Loss = 0.1681\n",
      "Fold 3 Epoch 60 Batch 5: Train Loss = 0.1967\n",
      "Fold 3 Epoch 60 Batch 10: Train Loss = 0.1661\n",
      "Fold 3 Epoch 60 Batch 15: Train Loss = 0.2253\n",
      "Fold 3 Epoch 60 Batch 20: Train Loss = 0.2156\n",
      "Fold 3, epoch 60: Loss = 0.1984 Valid loss = 0.3049 roc = 0.9035\n",
      "confusion matrix:\n",
      "[[1176   83]\n",
      " [  94  183]]\n",
      "accuracy = 0.884765625\n",
      "precision class 0 = 0.925984263420105\n",
      "precision class 1 = 0.6879699230194092\n",
      "recall class 0 = 0.9340746402740479\n",
      "recall class 1 = 0.660649836063385\n",
      "AUC of ROC = 0.9034532592768887\n",
      "AUC of PRC = 0.7438657195181168\n",
      "min(+P, Se) = 0.6726618705035972\n",
      "f1_score = 0.6740331867244481\n",
      "Fold 3, roc = 0.9035, prc = 0.7439\n",
      "Fold 3 Epoch 61 Batch 0: Train Loss = 0.2805\n",
      "Fold 3 Epoch 61 Batch 5: Train Loss = 0.2019\n",
      "Fold 3 Epoch 61 Batch 10: Train Loss = 0.1640\n",
      "Fold 3 Epoch 61 Batch 15: Train Loss = 0.2271\n",
      "Fold 3 Epoch 61 Batch 20: Train Loss = 0.2401\n",
      "Fold 3, roc = 0.9063, prc = 0.7415\n",
      "Fold 3 Epoch 62 Batch 0: Train Loss = 0.1673\n",
      "Fold 3 Epoch 62 Batch 5: Train Loss = 0.2187\n",
      "Fold 3 Epoch 62 Batch 10: Train Loss = 0.2029\n",
      "Fold 3 Epoch 62 Batch 15: Train Loss = 0.2523\n",
      "Fold 3 Epoch 62 Batch 20: Train Loss = 0.1820\n",
      "Fold 3, roc = 0.9050, prc = 0.7227\n",
      "Fold 3 Epoch 63 Batch 0: Train Loss = 0.2775\n",
      "Fold 3 Epoch 63 Batch 5: Train Loss = 0.1898\n",
      "Fold 3 Epoch 63 Batch 10: Train Loss = 0.2793\n",
      "Fold 3 Epoch 63 Batch 15: Train Loss = 0.2404\n",
      "Fold 3 Epoch 63 Batch 20: Train Loss = 0.2307\n",
      "Fold 3, roc = 0.9051, prc = 0.7412\n",
      "Fold 3 Epoch 64 Batch 0: Train Loss = 0.1632\n",
      "Fold 3 Epoch 64 Batch 5: Train Loss = 0.1845\n",
      "Fold 3 Epoch 64 Batch 10: Train Loss = 0.1990\n",
      "Fold 3 Epoch 64 Batch 15: Train Loss = 0.1248\n",
      "Fold 3 Epoch 64 Batch 20: Train Loss = 0.2751\n",
      "Fold 3, roc = 0.9028, prc = 0.7220\n",
      "Fold 3 Epoch 65 Batch 0: Train Loss = 0.1679\n",
      "Fold 3 Epoch 65 Batch 5: Train Loss = 0.2166\n",
      "Fold 3 Epoch 65 Batch 10: Train Loss = 0.1965\n",
      "Fold 3 Epoch 65 Batch 15: Train Loss = 0.1754\n",
      "Fold 3 Epoch 65 Batch 20: Train Loss = 0.2016\n",
      "Fold 3, roc = 0.9054, prc = 0.7390\n",
      "Fold 3 Epoch 66 Batch 0: Train Loss = 0.1553\n",
      "Fold 3 Epoch 66 Batch 5: Train Loss = 0.2116\n",
      "Fold 3 Epoch 66 Batch 10: Train Loss = 0.2146\n",
      "Fold 3 Epoch 66 Batch 15: Train Loss = 0.1675\n",
      "Fold 3 Epoch 66 Batch 20: Train Loss = 0.2119\n",
      "Fold 3, roc = 0.9060, prc = 0.7277\n",
      "Fold 3 Epoch 67 Batch 0: Train Loss = 0.2004\n",
      "Fold 3 Epoch 67 Batch 5: Train Loss = 0.1874\n",
      "Fold 3 Epoch 67 Batch 10: Train Loss = 0.2181\n",
      "Fold 3 Epoch 67 Batch 15: Train Loss = 0.2059\n",
      "Fold 3 Epoch 67 Batch 20: Train Loss = 0.1774\n",
      "Fold 3, roc = 0.9019, prc = 0.7332\n",
      "Fold 3 Epoch 68 Batch 0: Train Loss = 0.2320\n",
      "Fold 3 Epoch 68 Batch 5: Train Loss = 0.1820\n",
      "Fold 3 Epoch 68 Batch 10: Train Loss = 0.2440\n",
      "Fold 3 Epoch 68 Batch 15: Train Loss = 0.2054\n",
      "Fold 3 Epoch 68 Batch 20: Train Loss = 0.2005\n",
      "Fold 3, roc = 0.9040, prc = 0.7374\n",
      "Fold 3 Epoch 69 Batch 0: Train Loss = 0.2620\n",
      "Fold 3 Epoch 69 Batch 5: Train Loss = 0.1842\n",
      "Fold 3 Epoch 69 Batch 10: Train Loss = 0.1316\n",
      "Fold 3 Epoch 69 Batch 15: Train Loss = 0.1828\n",
      "Fold 3 Epoch 69 Batch 20: Train Loss = 0.2148\n",
      "Fold 3, roc = 0.9036, prc = 0.7371\n",
      "Fold 3 Epoch 70 Batch 0: Train Loss = 0.2142\n",
      "Fold 3 Epoch 70 Batch 5: Train Loss = 0.1666\n",
      "Fold 3 Epoch 70 Batch 10: Train Loss = 0.1677\n",
      "Fold 3 Epoch 70 Batch 15: Train Loss = 0.2092\n",
      "Fold 3 Epoch 70 Batch 20: Train Loss = 0.2081\n",
      "Fold 3, epoch 70: Loss = 0.1872 Valid loss = 0.3109 roc = 0.9033\n",
      "confusion matrix:\n",
      "[[1184   75]\n",
      " [  95  182]]\n",
      "accuracy = 0.8893229365348816\n",
      "precision class 0 = 0.9257231950759888\n",
      "precision class 1 = 0.7081711888313293\n",
      "recall class 0 = 0.9404289126396179\n",
      "recall class 1 = 0.6570397019386292\n",
      "AUC of ROC = 0.9032898151360743\n",
      "AUC of PRC = 0.7389681697590311\n",
      "min(+P, Se) = 0.6714801444043321\n",
      "f1_score = 0.6816479270376183\n",
      "Fold 3, roc = 0.9033, prc = 0.7390\n",
      "Fold 3 Epoch 71 Batch 0: Train Loss = 0.2023\n",
      "Fold 3 Epoch 71 Batch 5: Train Loss = 0.1595\n",
      "Fold 3 Epoch 71 Batch 10: Train Loss = 0.1365\n",
      "Fold 3 Epoch 71 Batch 15: Train Loss = 0.2240\n",
      "Fold 3 Epoch 71 Batch 20: Train Loss = 0.1867\n",
      "Fold 3, roc = 0.8995, prc = 0.7261\n",
      "Fold 3 Epoch 72 Batch 0: Train Loss = 0.1731\n",
      "Fold 3 Epoch 72 Batch 5: Train Loss = 0.2163\n",
      "Fold 3 Epoch 72 Batch 10: Train Loss = 0.2334\n",
      "Fold 3 Epoch 72 Batch 15: Train Loss = 0.1451\n",
      "Fold 3 Epoch 72 Batch 20: Train Loss = 0.1906\n",
      "Fold 3, roc = 0.9013, prc = 0.7341\n",
      "Fold 3 Epoch 73 Batch 0: Train Loss = 0.1903\n",
      "Fold 3 Epoch 73 Batch 5: Train Loss = 0.1510\n",
      "Fold 3 Epoch 73 Batch 10: Train Loss = 0.1779\n",
      "Fold 3 Epoch 73 Batch 15: Train Loss = 0.1239\n",
      "Fold 3 Epoch 73 Batch 20: Train Loss = 0.1487\n",
      "Fold 3, roc = 0.9033, prc = 0.7380\n",
      "Fold 3 Epoch 74 Batch 0: Train Loss = 0.1890\n",
      "Fold 3 Epoch 74 Batch 5: Train Loss = 0.2612\n",
      "Fold 3 Epoch 74 Batch 10: Train Loss = 0.1927\n",
      "Fold 3 Epoch 74 Batch 15: Train Loss = 0.2268\n",
      "Fold 3 Epoch 74 Batch 20: Train Loss = 0.2265\n",
      "Fold 3, roc = 0.9038, prc = 0.7456\n",
      "Fold 3 Epoch 75 Batch 0: Train Loss = 0.1360\n",
      "Fold 3 Epoch 75 Batch 5: Train Loss = 0.1785\n",
      "Fold 3 Epoch 75 Batch 10: Train Loss = 0.1871\n",
      "Fold 3 Epoch 75 Batch 15: Train Loss = 0.1539\n",
      "Fold 3 Epoch 75 Batch 20: Train Loss = 0.1661\n",
      "Fold 3, roc = 0.8999, prc = 0.7110\n",
      "Fold 3 Epoch 76 Batch 0: Train Loss = 0.1860\n",
      "Fold 3 Epoch 76 Batch 5: Train Loss = 0.1582\n",
      "Fold 3 Epoch 76 Batch 10: Train Loss = 0.1996\n",
      "Fold 3 Epoch 76 Batch 15: Train Loss = 0.1777\n",
      "Fold 3 Epoch 76 Batch 20: Train Loss = 0.1485\n",
      "Fold 3, roc = 0.9079, prc = 0.7520\n",
      "Fold 3 Epoch 77 Batch 0: Train Loss = 0.2000\n",
      "Fold 3 Epoch 77 Batch 5: Train Loss = 0.1684\n",
      "Fold 3 Epoch 77 Batch 10: Train Loss = 0.2040\n",
      "Fold 3 Epoch 77 Batch 15: Train Loss = 0.2060\n",
      "Fold 3 Epoch 77 Batch 20: Train Loss = 0.1709\n",
      "Fold 3, roc = 0.9025, prc = 0.7191\n",
      "Fold 3 Epoch 78 Batch 0: Train Loss = 0.1865\n",
      "Fold 3 Epoch 78 Batch 5: Train Loss = 0.2086\n",
      "Fold 3 Epoch 78 Batch 10: Train Loss = 0.1741\n",
      "Fold 3 Epoch 78 Batch 15: Train Loss = 0.2016\n",
      "Fold 3 Epoch 78 Batch 20: Train Loss = 0.1746\n",
      "Fold 3, roc = 0.8983, prc = 0.7239\n",
      "Fold 3 Epoch 79 Batch 0: Train Loss = 0.1681\n",
      "Fold 3 Epoch 79 Batch 5: Train Loss = 0.1940\n",
      "Fold 3 Epoch 79 Batch 10: Train Loss = 0.2022\n",
      "Fold 3 Epoch 79 Batch 15: Train Loss = 0.1895\n",
      "Fold 3 Epoch 79 Batch 20: Train Loss = 0.1618\n",
      "Fold 3, roc = 0.9006, prc = 0.7304\n",
      "Fold 3 Epoch 80 Batch 0: Train Loss = 0.1620\n",
      "Fold 3 Epoch 80 Batch 5: Train Loss = 0.1840\n",
      "Fold 3 Epoch 80 Batch 10: Train Loss = 0.1709\n",
      "Fold 3 Epoch 80 Batch 15: Train Loss = 0.1996\n",
      "Fold 3 Epoch 80 Batch 20: Train Loss = 0.1871\n",
      "Fold 3, epoch 80: Loss = 0.1768 Valid loss = 0.3357 roc = 0.8964\n",
      "confusion matrix:\n",
      "[[1159  100]\n",
      " [  94  183]]\n",
      "accuracy = 0.8736979365348816\n",
      "precision class 0 = 0.9249800443649292\n",
      "precision class 1 = 0.6466431021690369\n",
      "recall class 0 = 0.9205718636512756\n",
      "recall class 1 = 0.660649836063385\n",
      "AUC of ROC = 0.8963506077541342\n",
      "AUC of PRC = 0.7140839363872649\n",
      "min(+P, Se) = 0.6546762589928058\n",
      "f1_score = 0.6535714329140525\n",
      "Fold 3, roc = 0.8964, prc = 0.7141\n",
      "Fold 3 Epoch 81 Batch 0: Train Loss = 0.1974\n",
      "Fold 3 Epoch 81 Batch 5: Train Loss = 0.1880\n",
      "Fold 3 Epoch 81 Batch 10: Train Loss = 0.2047\n",
      "Fold 3 Epoch 81 Batch 15: Train Loss = 0.1945\n",
      "Fold 3 Epoch 81 Batch 20: Train Loss = 0.1786\n",
      "Fold 3, roc = 0.8990, prc = 0.7406\n",
      "Fold 3 Epoch 82 Batch 0: Train Loss = 0.1554\n",
      "Fold 3 Epoch 82 Batch 5: Train Loss = 0.2535\n",
      "Fold 3 Epoch 82 Batch 10: Train Loss = 0.2243\n",
      "Fold 3 Epoch 82 Batch 15: Train Loss = 0.1886\n",
      "Fold 3 Epoch 82 Batch 20: Train Loss = 0.1913\n",
      "Fold 3, roc = 0.9011, prc = 0.7351\n",
      "Fold 3 Epoch 83 Batch 0: Train Loss = 0.2355\n",
      "Fold 3 Epoch 83 Batch 5: Train Loss = 0.1636\n",
      "Fold 3 Epoch 83 Batch 10: Train Loss = 0.1893\n",
      "Fold 3 Epoch 83 Batch 15: Train Loss = 0.2328\n",
      "Fold 3 Epoch 83 Batch 20: Train Loss = 0.2163\n",
      "Fold 3, roc = 0.8955, prc = 0.7298\n",
      "Fold 3 Epoch 84 Batch 0: Train Loss = 0.1765\n",
      "Fold 3 Epoch 84 Batch 5: Train Loss = 0.1926\n",
      "Fold 3 Epoch 84 Batch 10: Train Loss = 0.1767\n",
      "Fold 3 Epoch 84 Batch 15: Train Loss = 0.2107\n",
      "Fold 3 Epoch 84 Batch 20: Train Loss = 0.1625\n",
      "Fold 3, roc = 0.9039, prc = 0.7480\n",
      "Fold 3 Epoch 85 Batch 0: Train Loss = 0.2092\n",
      "Fold 3 Epoch 85 Batch 5: Train Loss = 0.1734\n",
      "Fold 3 Epoch 85 Batch 10: Train Loss = 0.1523\n",
      "Fold 3 Epoch 85 Batch 15: Train Loss = 0.2130\n",
      "Fold 3 Epoch 85 Batch 20: Train Loss = 0.1822\n",
      "Fold 3, roc = 0.6804, prc = 0.6518\n",
      "Fold 3 Epoch 86 Batch 0: Train Loss = 0.1831\n",
      "Fold 3 Epoch 86 Batch 5: Train Loss = 0.2089\n",
      "Fold 3 Epoch 86 Batch 10: Train Loss = 0.2092\n",
      "Fold 3 Epoch 86 Batch 15: Train Loss = 0.2029\n",
      "Fold 3 Epoch 86 Batch 20: Train Loss = 0.1633\n",
      "Fold 3, roc = 0.8974, prc = 0.7046\n",
      "Fold 3 Epoch 87 Batch 0: Train Loss = 0.1941\n",
      "Fold 3 Epoch 87 Batch 5: Train Loss = 0.1542\n",
      "Fold 3 Epoch 87 Batch 10: Train Loss = 0.1852\n",
      "Fold 3 Epoch 87 Batch 15: Train Loss = 0.2607\n",
      "Fold 3 Epoch 87 Batch 20: Train Loss = 0.1763\n",
      "Fold 3, roc = 0.8944, prc = 0.7003\n",
      "Fold 3 Epoch 88 Batch 0: Train Loss = 0.2066\n",
      "Fold 3 Epoch 88 Batch 5: Train Loss = 0.1497\n",
      "Fold 3 Epoch 88 Batch 10: Train Loss = 0.2000\n",
      "Fold 3 Epoch 88 Batch 15: Train Loss = 0.1614\n",
      "Fold 3 Epoch 88 Batch 20: Train Loss = 0.1770\n",
      "Fold 3, roc = 0.8914, prc = 0.7105\n",
      "Fold 3 Epoch 89 Batch 0: Train Loss = 0.1615\n",
      "Fold 3 Epoch 89 Batch 5: Train Loss = 0.1832\n",
      "Fold 3 Epoch 89 Batch 10: Train Loss = 0.1930\n",
      "Fold 3 Epoch 89 Batch 15: Train Loss = 0.2015\n",
      "Fold 3 Epoch 89 Batch 20: Train Loss = 0.1422\n",
      "Fold 3, roc = 0.8825, prc = 0.6877\n",
      "Fold 3 Epoch 90 Batch 0: Train Loss = 0.1870\n",
      "Fold 3 Epoch 90 Batch 5: Train Loss = 0.2174\n",
      "Fold 3 Epoch 90 Batch 10: Train Loss = 0.2367\n",
      "Fold 3 Epoch 90 Batch 15: Train Loss = 0.1750\n",
      "Fold 3 Epoch 90 Batch 20: Train Loss = 0.1657\n",
      "Fold 3, epoch 90: Loss = 0.1749 Valid loss = 0.4515 roc = 0.8908\n",
      "confusion matrix:\n",
      "[[1082  177]\n",
      " [  72  205]]\n",
      "accuracy = 0.837890625\n",
      "precision class 0 = 0.9376083016395569\n",
      "precision class 1 = 0.536649227142334\n",
      "recall class 0 = 0.8594122529029846\n",
      "recall class 1 = 0.7400721907615662\n",
      "AUC of ROC = 0.8907906395253812\n",
      "AUC of PRC = 0.6930412281681441\n",
      "min(+P, Se) = 0.628158844765343\n",
      "f1_score = 0.6221547552826694\n",
      "Fold 3, roc = 0.8908, prc = 0.6930\n",
      "Fold 3 Epoch 91 Batch 0: Train Loss = 0.1772\n",
      "Fold 3 Epoch 91 Batch 5: Train Loss = 0.2127\n",
      "Fold 3 Epoch 91 Batch 10: Train Loss = 0.1850\n",
      "Fold 3 Epoch 91 Batch 15: Train Loss = 0.1741\n",
      "Fold 3 Epoch 91 Batch 20: Train Loss = 0.1613\n",
      "Fold 3, roc = 0.8783, prc = 0.6725\n",
      "Fold 3 Epoch 92 Batch 0: Train Loss = 0.1813\n",
      "Fold 3 Epoch 92 Batch 5: Train Loss = 0.1814\n",
      "Fold 3 Epoch 92 Batch 10: Train Loss = 0.1574\n",
      "Fold 3 Epoch 92 Batch 15: Train Loss = 0.1861\n",
      "Fold 3 Epoch 92 Batch 20: Train Loss = 0.2104\n",
      "Fold 3, roc = 0.8708, prc = 0.6767\n",
      "Fold 3 Epoch 93 Batch 0: Train Loss = 0.2210\n",
      "Fold 3 Epoch 93 Batch 5: Train Loss = 0.1927\n",
      "Fold 3 Epoch 93 Batch 10: Train Loss = 0.1700\n",
      "Fold 3 Epoch 93 Batch 15: Train Loss = 0.1800\n",
      "Fold 3 Epoch 93 Batch 20: Train Loss = 0.1672\n",
      "Fold 3, roc = 0.8722, prc = 0.6617\n",
      "Fold 3 Epoch 94 Batch 0: Train Loss = 0.1263\n",
      "Fold 3 Epoch 94 Batch 5: Train Loss = 0.1745\n",
      "Fold 3 Epoch 94 Batch 10: Train Loss = 0.1353\n",
      "Fold 3 Epoch 94 Batch 15: Train Loss = 0.1526\n",
      "Fold 3 Epoch 94 Batch 20: Train Loss = 0.2332\n",
      "Fold 3, roc = 0.8704, prc = 0.6435\n",
      "Fold 3 Epoch 95 Batch 0: Train Loss = 0.1820\n",
      "Fold 3 Epoch 95 Batch 5: Train Loss = 0.1084\n",
      "Fold 3 Epoch 95 Batch 10: Train Loss = 0.1725\n",
      "Fold 3 Epoch 95 Batch 15: Train Loss = 0.2288\n",
      "Fold 3 Epoch 95 Batch 20: Train Loss = 0.1708\n",
      "Fold 3, roc = 0.8807, prc = 0.6584\n",
      "Fold 3 Epoch 96 Batch 0: Train Loss = 0.1307\n",
      "Fold 3 Epoch 96 Batch 5: Train Loss = 0.2216\n",
      "Fold 3 Epoch 96 Batch 10: Train Loss = 0.1085\n",
      "Fold 3 Epoch 96 Batch 15: Train Loss = 0.1863\n",
      "Fold 3 Epoch 96 Batch 20: Train Loss = 0.2073\n",
      "Fold 3, roc = 0.8764, prc = 0.6550\n",
      "Fold 3 Epoch 97 Batch 0: Train Loss = 0.1502\n",
      "Fold 3 Epoch 97 Batch 5: Train Loss = 0.1328\n",
      "Fold 3 Epoch 97 Batch 10: Train Loss = 0.2125\n",
      "Fold 3 Epoch 97 Batch 15: Train Loss = 0.1274\n",
      "Fold 3 Epoch 97 Batch 20: Train Loss = 0.1853\n",
      "Fold 3, roc = 0.8848, prc = 0.6580\n",
      "Fold 3 Epoch 98 Batch 0: Train Loss = 0.1984\n",
      "Fold 3 Epoch 98 Batch 5: Train Loss = 0.1597\n",
      "Fold 3 Epoch 98 Batch 10: Train Loss = 0.1378\n",
      "Fold 3 Epoch 98 Batch 15: Train Loss = 0.2176\n",
      "Fold 3 Epoch 98 Batch 20: Train Loss = 0.1656\n",
      "Fold 3, roc = 0.8813, prc = 0.6781\n",
      "Fold 3 Epoch 99 Batch 0: Train Loss = 0.2072\n",
      "Fold 3 Epoch 99 Batch 5: Train Loss = 0.1964\n",
      "Fold 3 Epoch 99 Batch 10: Train Loss = 0.1352\n",
      "Fold 3 Epoch 99 Batch 15: Train Loss = 0.1361\n",
      "Fold 3 Epoch 99 Batch 20: Train Loss = 0.1774\n",
      "Fold 3, roc = 0.8815, prc = 0.6852\n",
      "Fold 3 Epoch 100 Batch 0: Train Loss = 0.1579\n",
      "Fold 3 Epoch 100 Batch 5: Train Loss = 0.1791\n",
      "Fold 3 Epoch 100 Batch 10: Train Loss = 0.2083\n",
      "Fold 3 Epoch 100 Batch 15: Train Loss = 0.1941\n",
      "Fold 3 Epoch 100 Batch 20: Train Loss = 0.1686\n",
      "Fold 3, epoch 100: Loss = 0.1730 Valid loss = 0.3738 roc = 0.8802\n",
      "confusion matrix:\n",
      "[[1180   79]\n",
      " [ 114  163]]\n",
      "accuracy = 0.8743489384651184\n",
      "precision class 0 = 0.91190105676651\n",
      "precision class 1 = 0.6735537052154541\n",
      "recall class 0 = 0.9372518062591553\n",
      "recall class 1 = 0.588447630405426\n",
      "AUC of ROC = 0.8801667703724521\n",
      "AUC of PRC = 0.6841565254847514\n",
      "min(+P, Se) = 0.6245487364620939\n",
      "f1_score = 0.6281310317466428\n",
      "Fold 3, roc = 0.8802, prc = 0.6842\n",
      "Fold 3 Epoch 101 Batch 0: Train Loss = 0.1741\n",
      "Fold 3 Epoch 101 Batch 5: Train Loss = 0.1616\n",
      "Fold 3 Epoch 101 Batch 10: Train Loss = 0.1600\n",
      "Fold 3 Epoch 101 Batch 15: Train Loss = 0.1599\n",
      "Fold 3 Epoch 101 Batch 20: Train Loss = 0.1537\n",
      "Fold 3, roc = 0.8456, prc = 0.6415\n",
      "Fold 3 Epoch 102 Batch 0: Train Loss = 0.1956\n",
      "Fold 3 Epoch 102 Batch 5: Train Loss = 0.1822\n",
      "Fold 3 Epoch 102 Batch 10: Train Loss = 0.1962\n",
      "Fold 3 Epoch 102 Batch 15: Train Loss = 0.1602\n",
      "Fold 3 Epoch 102 Batch 20: Train Loss = 0.1667\n",
      "Fold 3, roc = 0.8876, prc = 0.6763\n",
      "Fold 3 Epoch 103 Batch 0: Train Loss = 0.1494\n",
      "Fold 3 Epoch 103 Batch 5: Train Loss = 0.1488\n",
      "Fold 3 Epoch 103 Batch 10: Train Loss = 0.1905\n",
      "Fold 3 Epoch 103 Batch 15: Train Loss = 0.1630\n",
      "Fold 3 Epoch 103 Batch 20: Train Loss = 0.1766\n",
      "Fold 3, roc = 0.8898, prc = 0.6797\n",
      "Fold 3 Epoch 104 Batch 0: Train Loss = 0.1162\n",
      "Fold 3 Epoch 104 Batch 5: Train Loss = 0.1312\n",
      "Fold 3 Epoch 104 Batch 10: Train Loss = 0.1948\n",
      "Fold 3 Epoch 104 Batch 15: Train Loss = 0.1901\n",
      "Fold 3 Epoch 104 Batch 20: Train Loss = 0.1628\n",
      "Fold 3, roc = 0.8765, prc = 0.6375\n",
      "Fold 3 Epoch 105 Batch 0: Train Loss = 0.1382\n",
      "Fold 3 Epoch 105 Batch 5: Train Loss = 0.2067\n",
      "Fold 3 Epoch 105 Batch 10: Train Loss = 0.1561\n",
      "Fold 3 Epoch 105 Batch 15: Train Loss = 0.1650\n",
      "Fold 3 Epoch 105 Batch 20: Train Loss = 0.1405\n",
      "Fold 3, roc = 0.8740, prc = 0.6135\n",
      "Fold 3 Epoch 106 Batch 0: Train Loss = 0.1594\n",
      "Fold 3 Epoch 106 Batch 5: Train Loss = 0.2398\n",
      "Fold 3 Epoch 106 Batch 10: Train Loss = 0.1821\n",
      "Fold 3 Epoch 106 Batch 15: Train Loss = 0.1220\n",
      "Fold 3 Epoch 106 Batch 20: Train Loss = 0.1777\n",
      "Fold 3, roc = 0.8884, prc = 0.6331\n",
      "Fold 3 Epoch 107 Batch 0: Train Loss = 0.1557\n",
      "Fold 3 Epoch 107 Batch 5: Train Loss = 0.1695\n",
      "Fold 3 Epoch 107 Batch 10: Train Loss = 0.1626\n",
      "Fold 3 Epoch 107 Batch 15: Train Loss = 0.1567\n",
      "Fold 3 Epoch 107 Batch 20: Train Loss = 0.1974\n",
      "Fold 3, roc = 0.8825, prc = 0.6267\n",
      "Fold 3 Epoch 108 Batch 0: Train Loss = 0.2059\n",
      "Fold 3 Epoch 108 Batch 5: Train Loss = 0.2217\n",
      "Fold 3 Epoch 108 Batch 10: Train Loss = 0.2007\n",
      "Fold 3 Epoch 108 Batch 15: Train Loss = 0.1596\n",
      "Fold 3 Epoch 108 Batch 20: Train Loss = 0.1862\n",
      "Fold 3, roc = 0.8680, prc = 0.6648\n",
      "Fold 3 Epoch 109 Batch 0: Train Loss = 0.1363\n",
      "Fold 3 Epoch 109 Batch 5: Train Loss = 0.1547\n",
      "Fold 3 Epoch 109 Batch 10: Train Loss = 0.1548\n",
      "Fold 3 Epoch 109 Batch 15: Train Loss = 0.1175\n",
      "Fold 3 Epoch 109 Batch 20: Train Loss = 0.2080\n",
      "Fold 3, roc = 0.8711, prc = 0.6712\n",
      "Fold 3 Epoch 110 Batch 0: Train Loss = 0.1510\n",
      "Fold 3 Epoch 110 Batch 5: Train Loss = 0.1450\n",
      "Fold 3 Epoch 110 Batch 10: Train Loss = 0.1809\n",
      "Fold 3 Epoch 110 Batch 15: Train Loss = 0.1606\n",
      "Fold 3 Epoch 110 Batch 20: Train Loss = 0.1879\n",
      "Fold 3, epoch 110: Loss = 0.1625 Valid loss = 0.5180 roc = 0.8909\n",
      "confusion matrix:\n",
      "[[1109  150]\n",
      " [  76  201]]\n",
      "accuracy = 0.8528645634651184\n",
      "precision class 0 = 0.9358649849891663\n",
      "precision class 1 = 0.5726495981216431\n",
      "recall class 0 = 0.8808578252792358\n",
      "recall class 1 = 0.7256317734718323\n",
      "AUC of ROC = 0.8908752290368552\n",
      "AUC of PRC = 0.6597237418485818\n",
      "min(+P, Se) = 0.6498194945848376\n",
      "f1_score = 0.6401273768191619\n",
      "Fold 3, roc = 0.8909, prc = 0.6597\n",
      "Fold 3 Epoch 111 Batch 0: Train Loss = 0.1765\n",
      "Fold 3 Epoch 111 Batch 5: Train Loss = 0.1909\n",
      "Fold 3 Epoch 111 Batch 10: Train Loss = 0.1654\n",
      "Fold 3 Epoch 111 Batch 15: Train Loss = 0.1853\n",
      "Fold 3 Epoch 111 Batch 20: Train Loss = 0.1789\n",
      "Fold 3, roc = 0.8740, prc = 0.6626\n",
      "Fold 3 Epoch 112 Batch 0: Train Loss = 0.1930\n",
      "Fold 3 Epoch 112 Batch 5: Train Loss = 0.1305\n",
      "Fold 3 Epoch 112 Batch 10: Train Loss = 0.1532\n",
      "Fold 3 Epoch 112 Batch 15: Train Loss = 0.1454\n",
      "Fold 3 Epoch 112 Batch 20: Train Loss = 0.1802\n",
      "Fold 3, roc = 0.8719, prc = 0.6452\n",
      "Fold 3 Epoch 113 Batch 0: Train Loss = 0.2045\n",
      "Fold 3 Epoch 113 Batch 5: Train Loss = 0.2161\n",
      "Fold 3 Epoch 113 Batch 10: Train Loss = 0.1212\n",
      "Fold 3 Epoch 113 Batch 15: Train Loss = 0.1496\n",
      "Fold 3 Epoch 113 Batch 20: Train Loss = 0.1739\n",
      "Fold 3, roc = 0.8859, prc = 0.5865\n",
      "Fold 3 Epoch 114 Batch 0: Train Loss = 0.1305\n",
      "Fold 3 Epoch 114 Batch 5: Train Loss = 0.1399\n",
      "Fold 3 Epoch 114 Batch 10: Train Loss = 0.1412\n",
      "Fold 3 Epoch 114 Batch 15: Train Loss = 0.1704\n",
      "Fold 3 Epoch 114 Batch 20: Train Loss = 0.1604\n",
      "Fold 3, roc = 0.8759, prc = 0.5765\n",
      "Fold 3 Epoch 115 Batch 0: Train Loss = 0.2186\n",
      "Fold 3 Epoch 115 Batch 5: Train Loss = 0.1854\n",
      "Fold 3 Epoch 115 Batch 10: Train Loss = 0.2220\n",
      "Fold 3 Epoch 115 Batch 15: Train Loss = 0.1637\n",
      "Fold 3 Epoch 115 Batch 20: Train Loss = 0.1687\n",
      "Fold 3, roc = 0.8774, prc = 0.5915\n",
      "Fold 3 Epoch 116 Batch 0: Train Loss = 0.1451\n",
      "Fold 3 Epoch 116 Batch 5: Train Loss = 0.1675\n",
      "Fold 3 Epoch 116 Batch 10: Train Loss = 0.1606\n",
      "Fold 3 Epoch 116 Batch 15: Train Loss = 0.1682\n",
      "Fold 3 Epoch 116 Batch 20: Train Loss = 0.1914\n",
      "Fold 3, roc = 0.8895, prc = 0.6114\n",
      "Fold 3 Epoch 117 Batch 0: Train Loss = 0.1742\n",
      "Fold 3 Epoch 117 Batch 5: Train Loss = 0.1597\n",
      "Fold 3 Epoch 117 Batch 10: Train Loss = 0.2300\n",
      "Fold 3 Epoch 117 Batch 15: Train Loss = 0.1269\n",
      "Fold 3 Epoch 117 Batch 20: Train Loss = 0.1466\n",
      "Fold 3, roc = 0.8861, prc = 0.6097\n",
      "Fold 3 Epoch 118 Batch 0: Train Loss = 0.1683\n",
      "Fold 3 Epoch 118 Batch 5: Train Loss = 0.1206\n",
      "Fold 3 Epoch 118 Batch 10: Train Loss = 0.1649\n",
      "Fold 3 Epoch 118 Batch 15: Train Loss = 0.1448\n",
      "Fold 3 Epoch 118 Batch 20: Train Loss = 0.2353\n",
      "Fold 3, roc = 0.8961, prc = 0.6277\n",
      "Fold 3 Epoch 119 Batch 0: Train Loss = 0.2225\n",
      "Fold 3 Epoch 119 Batch 5: Train Loss = 0.1659\n",
      "Fold 3 Epoch 119 Batch 10: Train Loss = 0.2032\n",
      "Fold 3 Epoch 119 Batch 15: Train Loss = 0.2264\n",
      "Fold 3 Epoch 119 Batch 20: Train Loss = 0.1654\n",
      "Fold 3, roc = 0.8828, prc = 0.6466\n",
      "Fold 3 Epoch 120 Batch 0: Train Loss = 0.1241\n",
      "Fold 3 Epoch 120 Batch 5: Train Loss = 0.1528\n",
      "Fold 3 Epoch 120 Batch 10: Train Loss = 0.2188\n",
      "Fold 3 Epoch 120 Batch 15: Train Loss = 0.2498\n",
      "Fold 3 Epoch 120 Batch 20: Train Loss = 0.1454\n",
      "Fold 3, epoch 120: Loss = 0.1617 Valid loss = 0.4088 roc = 0.8806\n",
      "confusion matrix:\n",
      "[[1149  110]\n",
      " [ 107  170]]\n",
      "accuracy = 0.8587239384651184\n",
      "precision class 0 = 0.9148089289665222\n",
      "precision class 1 = 0.6071428656578064\n",
      "recall class 0 = 0.9126290678977966\n",
      "recall class 1 = 0.6137183904647827\n",
      "AUC of ROC = 0.8806198260610248\n",
      "AUC of PRC = 0.6444223948667661\n",
      "min(+P, Se) = 0.6137184115523465\n",
      "f1_score = 0.6104129500657908\n",
      "Fold 3, roc = 0.8806, prc = 0.6444\n",
      "Fold 3 Epoch 121 Batch 0: Train Loss = 0.1667\n",
      "Fold 3 Epoch 121 Batch 5: Train Loss = 0.1279\n",
      "Fold 3 Epoch 121 Batch 10: Train Loss = 0.1774\n",
      "Fold 3 Epoch 121 Batch 15: Train Loss = 0.1786\n",
      "Fold 3 Epoch 121 Batch 20: Train Loss = 0.1396\n",
      "Fold 3, roc = 0.8947, prc = 0.6568\n",
      "Fold 3 Epoch 122 Batch 0: Train Loss = 0.1813\n",
      "Fold 3 Epoch 122 Batch 5: Train Loss = 0.1450\n",
      "Fold 3 Epoch 122 Batch 10: Train Loss = 0.1447\n",
      "Fold 3 Epoch 122 Batch 15: Train Loss = 0.1855\n",
      "Fold 3 Epoch 122 Batch 20: Train Loss = 0.2144\n",
      "Fold 3, roc = 0.8806, prc = 0.6278\n",
      "Fold 3 Epoch 123 Batch 0: Train Loss = 0.1478\n",
      "Fold 3 Epoch 123 Batch 5: Train Loss = 0.1466\n",
      "Fold 3 Epoch 123 Batch 10: Train Loss = 0.2081\n",
      "Fold 3 Epoch 123 Batch 15: Train Loss = 0.1619\n",
      "Fold 3 Epoch 123 Batch 20: Train Loss = 0.1162\n",
      "Fold 3, roc = 0.8960, prc = 0.6424\n",
      "Fold 3 Epoch 124 Batch 0: Train Loss = 0.1462\n",
      "Fold 3 Epoch 124 Batch 5: Train Loss = 0.1565\n",
      "Fold 3 Epoch 124 Batch 10: Train Loss = 0.1710\n",
      "Fold 3 Epoch 124 Batch 15: Train Loss = 0.1589\n",
      "Fold 3 Epoch 124 Batch 20: Train Loss = 0.1622\n",
      "Fold 3, roc = 0.8916, prc = 0.6410\n",
      "Fold 3 Epoch 125 Batch 0: Train Loss = 0.0957\n",
      "Fold 3 Epoch 125 Batch 5: Train Loss = 0.1462\n",
      "Fold 3 Epoch 125 Batch 10: Train Loss = 0.1646\n",
      "Fold 3 Epoch 125 Batch 15: Train Loss = 0.1636\n",
      "Fold 3 Epoch 125 Batch 20: Train Loss = 0.1491\n",
      "Fold 3, roc = 0.8830, prc = 0.6299\n",
      "Fold 3 Epoch 126 Batch 0: Train Loss = 0.1531\n",
      "Fold 3 Epoch 126 Batch 5: Train Loss = 0.1567\n",
      "Fold 3 Epoch 126 Batch 10: Train Loss = 0.1234\n",
      "Fold 3 Epoch 126 Batch 15: Train Loss = 0.0997\n",
      "Fold 3 Epoch 126 Batch 20: Train Loss = 0.2010\n",
      "Fold 3, roc = 0.8820, prc = 0.6495\n",
      "Fold 3 Epoch 127 Batch 0: Train Loss = 0.1718\n",
      "Fold 3 Epoch 127 Batch 5: Train Loss = 0.1717\n",
      "Fold 3 Epoch 127 Batch 10: Train Loss = 0.1466\n",
      "Fold 3 Epoch 127 Batch 15: Train Loss = 0.1476\n",
      "Fold 3 Epoch 127 Batch 20: Train Loss = 0.1708\n",
      "Fold 3, roc = 0.8826, prc = 0.6263\n",
      "Fold 3 Epoch 128 Batch 0: Train Loss = 0.2134\n",
      "Fold 3 Epoch 128 Batch 5: Train Loss = 0.1622\n",
      "Fold 3 Epoch 128 Batch 10: Train Loss = 0.1589\n",
      "Fold 3 Epoch 128 Batch 15: Train Loss = 0.1396\n",
      "Fold 3 Epoch 128 Batch 20: Train Loss = 0.1304\n",
      "Fold 3, roc = 0.8876, prc = 0.6224\n",
      "Fold 3 Epoch 129 Batch 0: Train Loss = 0.1604\n",
      "Fold 3 Epoch 129 Batch 5: Train Loss = 0.1207\n",
      "Fold 3 Epoch 129 Batch 10: Train Loss = 0.1727\n",
      "Fold 3 Epoch 129 Batch 15: Train Loss = 0.1478\n",
      "Fold 3 Epoch 129 Batch 20: Train Loss = 0.1196\n",
      "Fold 3, roc = 0.8877, prc = 0.6119\n",
      "Fold 3 Epoch 130 Batch 0: Train Loss = 0.1498\n",
      "Fold 3 Epoch 130 Batch 5: Train Loss = 0.1645\n",
      "Fold 3 Epoch 130 Batch 10: Train Loss = 0.2084\n",
      "Fold 3 Epoch 130 Batch 15: Train Loss = 0.1291\n",
      "Fold 3 Epoch 130 Batch 20: Train Loss = 0.1637\n",
      "Fold 3, epoch 130: Loss = 0.1588 Valid loss = 0.5032 roc = 0.8679\n",
      "confusion matrix:\n",
      "[[1116  143]\n",
      " [ 100  177]]\n",
      "accuracy = 0.841796875\n",
      "precision class 0 = 0.9177631735801697\n",
      "precision class 1 = 0.5531250238418579\n",
      "recall class 0 = 0.886417806148529\n",
      "recall class 1 = 0.6389891505241394\n",
      "AUC of ROC = 0.8679170621345805\n",
      "AUC of PRC = 0.6205664842264229\n",
      "min(+P, Se) = 0.6101083032490975\n",
      "f1_score = 0.5929648592225718\n",
      "Fold 3, roc = 0.8679, prc = 0.6206\n",
      "Fold 3 Epoch 131 Batch 0: Train Loss = 0.1607\n",
      "Fold 3 Epoch 131 Batch 5: Train Loss = 0.1592\n",
      "Fold 3 Epoch 131 Batch 10: Train Loss = 0.0892\n",
      "Fold 3 Epoch 131 Batch 15: Train Loss = 0.1353\n",
      "Fold 3 Epoch 131 Batch 20: Train Loss = 0.1653\n",
      "Fold 3, roc = 0.8730, prc = 0.6324\n",
      "Fold 3 Epoch 132 Batch 0: Train Loss = 0.1802\n",
      "Fold 3 Epoch 132 Batch 5: Train Loss = 0.1619\n",
      "Fold 3 Epoch 132 Batch 10: Train Loss = 0.1696\n",
      "Fold 3 Epoch 132 Batch 15: Train Loss = 0.1463\n",
      "Fold 3 Epoch 132 Batch 20: Train Loss = 0.1242\n",
      "Fold 3, roc = 0.8706, prc = 0.6239\n",
      "Fold 3 Epoch 133 Batch 0: Train Loss = 0.1708\n",
      "Fold 3 Epoch 133 Batch 5: Train Loss = 0.1593\n",
      "Fold 3 Epoch 133 Batch 10: Train Loss = 0.1637\n",
      "Fold 3 Epoch 133 Batch 15: Train Loss = 0.1729\n",
      "Fold 3 Epoch 133 Batch 20: Train Loss = 0.1637\n",
      "Fold 3, roc = 0.8739, prc = 0.6541\n",
      "Fold 3 Epoch 134 Batch 0: Train Loss = 0.1980\n",
      "Fold 3 Epoch 134 Batch 5: Train Loss = 0.1294\n",
      "Fold 3 Epoch 134 Batch 10: Train Loss = 0.1156\n",
      "Fold 3 Epoch 134 Batch 15: Train Loss = 0.1756\n",
      "Fold 3 Epoch 134 Batch 20: Train Loss = 0.1822\n",
      "Fold 3, roc = 0.8633, prc = 0.6195\n",
      "Fold 3 Epoch 135 Batch 0: Train Loss = 0.1259\n",
      "Fold 3 Epoch 135 Batch 5: Train Loss = 0.1497\n",
      "Fold 3 Epoch 135 Batch 10: Train Loss = 0.1747\n",
      "Fold 3 Epoch 135 Batch 15: Train Loss = 0.1832\n",
      "Fold 3 Epoch 135 Batch 20: Train Loss = 0.1981\n",
      "Fold 3, roc = 0.8758, prc = 0.6308\n",
      "Fold 3 Epoch 136 Batch 0: Train Loss = 0.1205\n",
      "Fold 3 Epoch 136 Batch 5: Train Loss = 0.1611\n",
      "Fold 3 Epoch 136 Batch 10: Train Loss = 0.2252\n",
      "Fold 3 Epoch 136 Batch 15: Train Loss = 0.1714\n",
      "Fold 3 Epoch 136 Batch 20: Train Loss = 0.1482\n",
      "Fold 3, roc = 0.8551, prc = 0.5676\n",
      "Fold 3 Epoch 137 Batch 0: Train Loss = 0.1585\n",
      "Fold 3 Epoch 137 Batch 5: Train Loss = 0.1440\n",
      "Fold 3 Epoch 137 Batch 10: Train Loss = 0.1985\n",
      "Fold 3 Epoch 137 Batch 15: Train Loss = 0.1707\n",
      "Fold 3 Epoch 137 Batch 20: Train Loss = 0.1466\n",
      "Fold 3, roc = 0.8654, prc = 0.6497\n",
      "Fold 3 Epoch 138 Batch 0: Train Loss = 0.1847\n",
      "Fold 3 Epoch 138 Batch 5: Train Loss = 0.1646\n",
      "Fold 3 Epoch 138 Batch 10: Train Loss = 0.1611\n",
      "Fold 3 Epoch 138 Batch 15: Train Loss = 0.1468\n",
      "Fold 3 Epoch 138 Batch 20: Train Loss = 0.1313\n",
      "Fold 3, roc = 0.8402, prc = 0.6182\n",
      "Fold 3 Epoch 139 Batch 0: Train Loss = 0.2107\n",
      "Fold 3 Epoch 139 Batch 5: Train Loss = 0.1540\n",
      "Fold 3 Epoch 139 Batch 10: Train Loss = 0.1496\n",
      "Fold 3 Epoch 139 Batch 15: Train Loss = 0.1584\n",
      "Fold 3 Epoch 139 Batch 20: Train Loss = 0.1534\n",
      "Fold 3, roc = 0.8500, prc = 0.6176\n",
      "Fold 3 Epoch 140 Batch 0: Train Loss = 0.1400\n",
      "Fold 3 Epoch 140 Batch 5: Train Loss = 0.1508\n",
      "Fold 3 Epoch 140 Batch 10: Train Loss = 0.1857\n",
      "Fold 3 Epoch 140 Batch 15: Train Loss = 0.1197\n",
      "Fold 3 Epoch 140 Batch 20: Train Loss = 0.1049\n",
      "Fold 3, epoch 140: Loss = 0.1514 Valid loss = 0.4531 roc = 0.8518\n",
      "confusion matrix:\n",
      "[[1140  119]\n",
      " [ 114  163]]\n",
      "accuracy = 0.8483073115348816\n",
      "precision class 0 = 0.9090909361839294\n",
      "precision class 1 = 0.5780141949653625\n",
      "recall class 0 = 0.9054805636405945\n",
      "recall class 1 = 0.588447630405426\n",
      "AUC of ROC = 0.8518364526313073\n",
      "AUC of PRC = 0.6416854995686384\n",
      "min(+P, Se) = 0.5827338129496403\n",
      "f1_score = 0.5831842516748432\n",
      "Fold 3, roc = 0.8518, prc = 0.6417\n",
      "Fold 3 Epoch 141 Batch 0: Train Loss = 0.1509\n",
      "Fold 3 Epoch 141 Batch 5: Train Loss = 0.1443\n",
      "Fold 3 Epoch 141 Batch 10: Train Loss = 0.1720\n",
      "Fold 3 Epoch 141 Batch 15: Train Loss = 0.1005\n",
      "Fold 3 Epoch 141 Batch 20: Train Loss = 0.1099\n",
      "Fold 3, roc = 0.8753, prc = 0.6566\n",
      "Fold 3 Epoch 142 Batch 0: Train Loss = 0.1592\n",
      "Fold 3 Epoch 142 Batch 5: Train Loss = 0.1520\n",
      "Fold 3 Epoch 142 Batch 10: Train Loss = 0.1587\n",
      "Fold 3 Epoch 142 Batch 15: Train Loss = 0.1434\n",
      "Fold 3 Epoch 142 Batch 20: Train Loss = 0.1173\n",
      "Fold 3, roc = 0.8648, prc = 0.6480\n",
      "Fold 3 Epoch 143 Batch 0: Train Loss = 0.1424\n",
      "Fold 3 Epoch 143 Batch 5: Train Loss = 0.1135\n",
      "Fold 3 Epoch 143 Batch 10: Train Loss = 0.1245\n",
      "Fold 3 Epoch 143 Batch 15: Train Loss = 0.1380\n",
      "Fold 3 Epoch 143 Batch 20: Train Loss = 0.1600\n",
      "Fold 3, roc = 0.8368, prc = 0.6032\n",
      "Fold 3 Epoch 144 Batch 0: Train Loss = 0.1370\n",
      "Fold 3 Epoch 144 Batch 5: Train Loss = 0.1409\n",
      "Fold 3 Epoch 144 Batch 10: Train Loss = 0.1241\n",
      "Fold 3 Epoch 144 Batch 15: Train Loss = 0.1798\n",
      "Fold 3 Epoch 144 Batch 20: Train Loss = 0.1625\n",
      "Fold 3, roc = 0.8414, prc = 0.6076\n",
      "Fold 3 Epoch 145 Batch 0: Train Loss = 0.1663\n",
      "Fold 3 Epoch 145 Batch 5: Train Loss = 0.1518\n",
      "Fold 3 Epoch 145 Batch 10: Train Loss = 0.1492\n",
      "Fold 3 Epoch 145 Batch 15: Train Loss = 0.0868\n",
      "Fold 3 Epoch 145 Batch 20: Train Loss = 0.1515\n",
      "Fold 3, roc = 0.8507, prc = 0.6084\n",
      "Fold 3 Epoch 146 Batch 0: Train Loss = 0.1216\n",
      "Fold 3 Epoch 146 Batch 5: Train Loss = 0.1594\n",
      "Fold 3 Epoch 146 Batch 10: Train Loss = 0.1538\n",
      "Fold 3 Epoch 146 Batch 15: Train Loss = 0.1462\n",
      "Fold 3 Epoch 146 Batch 20: Train Loss = 0.0875\n",
      "Fold 3, roc = 0.8435, prc = 0.5918\n",
      "Fold 3 Epoch 147 Batch 0: Train Loss = 0.1305\n",
      "Fold 3 Epoch 147 Batch 5: Train Loss = 0.1937\n",
      "Fold 3 Epoch 147 Batch 10: Train Loss = 0.1800\n",
      "Fold 3 Epoch 147 Batch 15: Train Loss = 0.1385\n",
      "Fold 3 Epoch 147 Batch 20: Train Loss = 0.1089\n",
      "Fold 3, roc = 0.8269, prc = 0.5809\n",
      "Fold 3 Epoch 148 Batch 0: Train Loss = 0.1636\n",
      "Fold 3 Epoch 148 Batch 5: Train Loss = 0.1946\n",
      "Fold 3 Epoch 148 Batch 10: Train Loss = 0.0990\n",
      "Fold 3 Epoch 148 Batch 15: Train Loss = 0.1317\n",
      "Fold 3 Epoch 148 Batch 20: Train Loss = 0.1512\n",
      "Fold 3, roc = 0.8539, prc = 0.5803\n",
      "Fold 3 Epoch 149 Batch 0: Train Loss = 0.1078\n",
      "Fold 3 Epoch 149 Batch 5: Train Loss = 0.1521\n",
      "Fold 3 Epoch 149 Batch 10: Train Loss = 0.1298\n",
      "Fold 3 Epoch 149 Batch 15: Train Loss = 0.1495\n",
      "Fold 3 Epoch 149 Batch 20: Train Loss = 0.1558\n",
      "Fold 3, roc = 0.8680, prc = 0.6096\n",
      "Training data size: 6352, Validation data size: 1511\n",
      "Fold 4 Epoch 0 Batch 0: Train Loss = 0.7191\n",
      "Fold 4 Epoch 0 Batch 5: Train Loss = 0.6832\n",
      "Fold 4 Epoch 0 Batch 10: Train Loss = 0.6013\n",
      "Fold 4 Epoch 0 Batch 15: Train Loss = 0.5674\n",
      "Fold 4 Epoch 0 Batch 20: Train Loss = 0.5566\n",
      "Fold 4, epoch 0: Loss = 0.6214 Valid loss = 0.6007 roc = 0.7735\n",
      "confusion matrix:\n",
      "[[1150  122]\n",
      " [ 150   89]]\n",
      "accuracy = 0.8199867606163025\n",
      "precision class 0 = 0.8846153616905212\n",
      "precision class 1 = 0.4218009412288666\n",
      "recall class 0 = 0.9040880799293518\n",
      "recall class 1 = 0.3723849356174469\n",
      "AUC of ROC = 0.7734730664982501\n",
      "AUC of PRC = 0.4252531257015925\n",
      "min(+P, Se) = 0.44214876033057854\n",
      "f1_score = 0.3955555517220203\n",
      "Fold 4, roc = 0.7735, prc = 0.4253\n",
      "Fold 4 Epoch 1 Batch 0: Train Loss = 0.5215\n",
      "Fold 4 Epoch 1 Batch 5: Train Loss = 0.4858\n",
      "Fold 4 Epoch 1 Batch 10: Train Loss = 0.4212\n",
      "Fold 4 Epoch 1 Batch 15: Train Loss = 0.4390\n",
      "Fold 4 Epoch 1 Batch 20: Train Loss = 0.5009\n",
      "Fold 4, roc = 0.7803, prc = 0.4371\n",
      "Fold 4 Epoch 2 Batch 0: Train Loss = 0.3754\n",
      "Fold 4 Epoch 2 Batch 5: Train Loss = 0.3524\n",
      "Fold 4 Epoch 2 Batch 10: Train Loss = 0.3855\n",
      "Fold 4 Epoch 2 Batch 15: Train Loss = 0.4267\n",
      "Fold 4 Epoch 2 Batch 20: Train Loss = 0.3245\n",
      "Fold 4, roc = 0.7774, prc = 0.4470\n",
      "Fold 4 Epoch 3 Batch 0: Train Loss = 0.3901\n",
      "Fold 4 Epoch 3 Batch 5: Train Loss = 0.3294\n",
      "Fold 4 Epoch 3 Batch 10: Train Loss = 0.4554\n",
      "Fold 4 Epoch 3 Batch 15: Train Loss = 0.2924\n",
      "Fold 4 Epoch 3 Batch 20: Train Loss = 0.3848\n",
      "Fold 4, roc = 0.8203, prc = 0.4842\n",
      "Fold 4 Epoch 4 Batch 0: Train Loss = 0.3277\n",
      "Fold 4 Epoch 4 Batch 5: Train Loss = 0.2962\n",
      "Fold 4 Epoch 4 Batch 10: Train Loss = 0.2955\n",
      "Fold 4 Epoch 4 Batch 15: Train Loss = 0.2936\n",
      "Fold 4 Epoch 4 Batch 20: Train Loss = 0.3268\n",
      "Fold 4, roc = 0.8128, prc = 0.5043\n",
      "Fold 4 Epoch 5 Batch 0: Train Loss = 0.3393\n",
      "Fold 4 Epoch 5 Batch 5: Train Loss = 0.2951\n",
      "Fold 4 Epoch 5 Batch 10: Train Loss = 0.2507\n",
      "Fold 4 Epoch 5 Batch 15: Train Loss = 0.2933\n",
      "Fold 4 Epoch 5 Batch 20: Train Loss = 0.3715\n",
      "Fold 4, roc = 0.8231, prc = 0.5383\n",
      "Fold 4 Epoch 6 Batch 0: Train Loss = 0.2530\n",
      "Fold 4 Epoch 6 Batch 5: Train Loss = 0.3659\n",
      "Fold 4 Epoch 6 Batch 10: Train Loss = 0.3023\n",
      "Fold 4 Epoch 6 Batch 15: Train Loss = 0.3276\n",
      "Fold 4 Epoch 6 Batch 20: Train Loss = 0.3196\n",
      "Fold 4, roc = 0.8372, prc = 0.5521\n",
      "Fold 4 Epoch 7 Batch 0: Train Loss = 0.2943\n",
      "Fold 4 Epoch 7 Batch 5: Train Loss = 0.2883\n",
      "Fold 4 Epoch 7 Batch 10: Train Loss = 0.2661\n",
      "Fold 4 Epoch 7 Batch 15: Train Loss = 0.3576\n",
      "Fold 4 Epoch 7 Batch 20: Train Loss = 0.3012\n",
      "Fold 4, roc = 0.8298, prc = 0.5337\n",
      "Fold 4 Epoch 8 Batch 0: Train Loss = 0.2338\n",
      "Fold 4 Epoch 8 Batch 5: Train Loss = 0.3362\n",
      "Fold 4 Epoch 8 Batch 10: Train Loss = 0.2974\n",
      "Fold 4 Epoch 8 Batch 15: Train Loss = 0.2872\n",
      "Fold 4 Epoch 8 Batch 20: Train Loss = 0.3445\n",
      "Fold 4, roc = 0.7965, prc = 0.5155\n",
      "Fold 4 Epoch 9 Batch 0: Train Loss = 0.2903\n",
      "Fold 4 Epoch 9 Batch 5: Train Loss = 0.3045\n",
      "Fold 4 Epoch 9 Batch 10: Train Loss = 0.4235\n",
      "Fold 4 Epoch 9 Batch 15: Train Loss = 0.3081\n",
      "Fold 4 Epoch 9 Batch 20: Train Loss = 0.3314\n",
      "Fold 4, roc = 0.8044, prc = 0.4918\n",
      "Fold 4 Epoch 10 Batch 0: Train Loss = 0.3888\n",
      "Fold 4 Epoch 10 Batch 5: Train Loss = 0.3359\n",
      "Fold 4 Epoch 10 Batch 10: Train Loss = 0.3683\n",
      "Fold 4 Epoch 10 Batch 15: Train Loss = 0.2623\n",
      "Fold 4 Epoch 10 Batch 20: Train Loss = 0.2758\n",
      "Fold 4, epoch 10: Loss = 0.2995 Valid loss = 0.3621 roc = 0.8321\n",
      "confusion matrix:\n",
      "[[1162  110]\n",
      " [ 126  113]]\n",
      "accuracy = 0.8438120484352112\n",
      "precision class 0 = 0.9021739363670349\n",
      "precision class 1 = 0.5067264437675476\n",
      "recall class 0 = 0.9135220050811768\n",
      "recall class 1 = 0.47280335426330566\n",
      "AUC of ROC = 0.8321359964211469\n",
      "AUC of PRC = 0.5235587534302785\n",
      "min(+P, Se) = 0.5111111111111111\n",
      "f1_score = 0.4891774865631326\n",
      "Fold 4, roc = 0.8321, prc = 0.5236\n",
      "Fold 4 Epoch 11 Batch 0: Train Loss = 0.2624\n",
      "Fold 4 Epoch 11 Batch 5: Train Loss = 0.2764\n",
      "Fold 4 Epoch 11 Batch 10: Train Loss = 0.2599\n",
      "Fold 4 Epoch 11 Batch 15: Train Loss = 0.2365\n",
      "Fold 4 Epoch 11 Batch 20: Train Loss = 0.2679\n",
      "Fold 4, roc = 0.8304, prc = 0.5280\n",
      "Fold 4 Epoch 12 Batch 0: Train Loss = 0.3072\n",
      "Fold 4 Epoch 12 Batch 5: Train Loss = 0.3459\n",
      "Fold 4 Epoch 12 Batch 10: Train Loss = 0.2544\n",
      "Fold 4 Epoch 12 Batch 15: Train Loss = 0.2980\n",
      "Fold 4 Epoch 12 Batch 20: Train Loss = 0.2906\n",
      "Fold 4, roc = 0.8396, prc = 0.5453\n",
      "Fold 4 Epoch 13 Batch 0: Train Loss = 0.2773\n",
      "Fold 4 Epoch 13 Batch 5: Train Loss = 0.3124\n",
      "Fold 4 Epoch 13 Batch 10: Train Loss = 0.2676\n",
      "Fold 4 Epoch 13 Batch 15: Train Loss = 0.2538\n",
      "Fold 4 Epoch 13 Batch 20: Train Loss = 0.2535\n",
      "Fold 4, roc = 0.8352, prc = 0.5456\n",
      "Fold 4 Epoch 14 Batch 0: Train Loss = 0.3143\n",
      "Fold 4 Epoch 14 Batch 5: Train Loss = 0.2889\n",
      "Fold 4 Epoch 14 Batch 10: Train Loss = 0.2618\n",
      "Fold 4 Epoch 14 Batch 15: Train Loss = 0.1985\n",
      "Fold 4 Epoch 14 Batch 20: Train Loss = 0.2331\n",
      "Fold 4, roc = 0.8326, prc = 0.5333\n",
      "Fold 4 Epoch 15 Batch 0: Train Loss = 0.2851\n",
      "Fold 4 Epoch 15 Batch 5: Train Loss = 0.2539\n",
      "Fold 4 Epoch 15 Batch 10: Train Loss = 0.2578\n",
      "Fold 4 Epoch 15 Batch 15: Train Loss = 0.2417\n",
      "Fold 4 Epoch 15 Batch 20: Train Loss = 0.2063\n",
      "Fold 4, roc = 0.8266, prc = 0.5044\n",
      "Fold 4 Epoch 16 Batch 0: Train Loss = 0.2603\n",
      "Fold 4 Epoch 16 Batch 5: Train Loss = 0.2319\n",
      "Fold 4 Epoch 16 Batch 10: Train Loss = 0.2657\n",
      "Fold 4 Epoch 16 Batch 15: Train Loss = 0.2657\n",
      "Fold 4 Epoch 16 Batch 20: Train Loss = 0.2537\n",
      "Fold 4, roc = 0.8118, prc = 0.5189\n",
      "Fold 4 Epoch 17 Batch 0: Train Loss = 0.2652\n",
      "Fold 4 Epoch 17 Batch 5: Train Loss = 0.2642\n",
      "Fold 4 Epoch 17 Batch 10: Train Loss = 0.1711\n",
      "Fold 4 Epoch 17 Batch 15: Train Loss = 0.2937\n",
      "Fold 4 Epoch 17 Batch 20: Train Loss = 0.2620\n",
      "Fold 4, roc = 0.8250, prc = 0.5060\n",
      "Fold 4 Epoch 18 Batch 0: Train Loss = 0.2150\n",
      "Fold 4 Epoch 18 Batch 5: Train Loss = 0.2178\n",
      "Fold 4 Epoch 18 Batch 10: Train Loss = 0.2919\n",
      "Fold 4 Epoch 18 Batch 15: Train Loss = 0.2643\n",
      "Fold 4 Epoch 18 Batch 20: Train Loss = 0.2597\n",
      "Fold 4, roc = 0.8114, prc = 0.4821\n",
      "Fold 4 Epoch 19 Batch 0: Train Loss = 0.2637\n",
      "Fold 4 Epoch 19 Batch 5: Train Loss = 0.2718\n",
      "Fold 4 Epoch 19 Batch 10: Train Loss = 0.2346\n",
      "Fold 4 Epoch 19 Batch 15: Train Loss = 0.2419\n",
      "Fold 4 Epoch 19 Batch 20: Train Loss = 0.2020\n",
      "Fold 4, roc = 0.8104, prc = 0.4104\n",
      "Fold 4 Epoch 20 Batch 0: Train Loss = 0.1808\n",
      "Fold 4 Epoch 20 Batch 5: Train Loss = 0.2313\n",
      "Fold 4 Epoch 20 Batch 10: Train Loss = 0.2765\n",
      "Fold 4 Epoch 20 Batch 15: Train Loss = 0.2303\n",
      "Fold 4 Epoch 20 Batch 20: Train Loss = 0.2419\n",
      "Fold 4, epoch 20: Loss = 0.2542 Valid loss = 0.4410 roc = 0.8280\n",
      "confusion matrix:\n",
      "[[1154  118]\n",
      " [ 119  120]]\n",
      "accuracy = 0.84315025806427\n",
      "precision class 0 = 0.9065200090408325\n",
      "precision class 1 = 0.5042017102241516\n",
      "recall class 0 = 0.9072327017784119\n",
      "recall class 1 = 0.5020920634269714\n",
      "AUC of ROC = 0.8279716323254651\n",
      "AUC of PRC = 0.45002192298506\n",
      "min(+P, Se) = 0.502092050209205\n",
      "f1_score = 0.5031446754387253\n",
      "Fold 4, roc = 0.8280, prc = 0.4500\n",
      "Fold 4 Epoch 21 Batch 0: Train Loss = 0.2621\n",
      "Fold 4 Epoch 21 Batch 5: Train Loss = 0.2048\n",
      "Fold 4 Epoch 21 Batch 10: Train Loss = 0.2094\n",
      "Fold 4 Epoch 21 Batch 15: Train Loss = 0.2173\n",
      "Fold 4 Epoch 21 Batch 20: Train Loss = 0.2172\n",
      "Fold 4, roc = 0.8078, prc = 0.3920\n",
      "Fold 4 Epoch 22 Batch 0: Train Loss = 0.2252\n",
      "Fold 4 Epoch 22 Batch 5: Train Loss = 0.2557\n",
      "Fold 4 Epoch 22 Batch 10: Train Loss = 0.2402\n",
      "Fold 4 Epoch 22 Batch 15: Train Loss = 0.2418\n",
      "Fold 4 Epoch 22 Batch 20: Train Loss = 0.2334\n",
      "Fold 4, roc = 0.8208, prc = 0.4307\n",
      "Fold 4 Epoch 23 Batch 0: Train Loss = 0.2503\n",
      "Fold 4 Epoch 23 Batch 5: Train Loss = 0.2056\n",
      "Fold 4 Epoch 23 Batch 10: Train Loss = 0.2378\n",
      "Fold 4 Epoch 23 Batch 15: Train Loss = 0.2155\n",
      "Fold 4 Epoch 23 Batch 20: Train Loss = 0.2282\n",
      "Fold 4, roc = 0.8059, prc = 0.4080\n",
      "Fold 4 Epoch 24 Batch 0: Train Loss = 0.3138\n",
      "Fold 4 Epoch 24 Batch 5: Train Loss = 0.2516\n",
      "Fold 4 Epoch 24 Batch 10: Train Loss = 0.2093\n",
      "Fold 4 Epoch 24 Batch 15: Train Loss = 0.2278\n",
      "Fold 4 Epoch 24 Batch 20: Train Loss = 0.2662\n",
      "Fold 4, roc = 0.8207, prc = 0.4632\n",
      "Fold 4 Epoch 25 Batch 0: Train Loss = 0.2726\n",
      "Fold 4 Epoch 25 Batch 5: Train Loss = 0.2259\n",
      "Fold 4 Epoch 25 Batch 10: Train Loss = 0.1926\n",
      "Fold 4 Epoch 25 Batch 15: Train Loss = 0.2216\n",
      "Fold 4 Epoch 25 Batch 20: Train Loss = 0.2231\n",
      "Fold 4, roc = 0.8195, prc = 0.4156\n",
      "Fold 4 Epoch 26 Batch 0: Train Loss = 0.3125\n",
      "Fold 4 Epoch 26 Batch 5: Train Loss = 0.2558\n",
      "Fold 4 Epoch 26 Batch 10: Train Loss = 0.2135\n",
      "Fold 4 Epoch 26 Batch 15: Train Loss = 0.2084\n",
      "Fold 4 Epoch 26 Batch 20: Train Loss = 0.2991\n",
      "Fold 4, roc = 0.8242, prc = 0.4376\n",
      "Fold 4 Epoch 27 Batch 0: Train Loss = 0.2514\n",
      "Fold 4 Epoch 27 Batch 5: Train Loss = 0.2155\n",
      "Fold 4 Epoch 27 Batch 10: Train Loss = 0.2394\n",
      "Fold 4 Epoch 27 Batch 15: Train Loss = 0.1969\n",
      "Fold 4 Epoch 27 Batch 20: Train Loss = 0.2079\n",
      "Fold 4, roc = 0.8405, prc = 0.5084\n",
      "Fold 4 Epoch 28 Batch 0: Train Loss = 0.2722\n",
      "Fold 4 Epoch 28 Batch 5: Train Loss = 0.3356\n",
      "Fold 4 Epoch 28 Batch 10: Train Loss = 0.2484\n",
      "Fold 4 Epoch 28 Batch 15: Train Loss = 0.2754\n",
      "Fold 4 Epoch 28 Batch 20: Train Loss = 0.2384\n",
      "Fold 4, roc = 0.8188, prc = 0.4133\n",
      "Fold 4 Epoch 29 Batch 0: Train Loss = 0.2172\n",
      "Fold 4 Epoch 29 Batch 5: Train Loss = 0.2307\n",
      "Fold 4 Epoch 29 Batch 10: Train Loss = 0.2539\n",
      "Fold 4 Epoch 29 Batch 15: Train Loss = 0.2330\n",
      "Fold 4 Epoch 29 Batch 20: Train Loss = 0.1996\n",
      "Fold 4, roc = 0.8217, prc = 0.4167\n",
      "Fold 4 Epoch 30 Batch 0: Train Loss = 0.1427\n",
      "Fold 4 Epoch 30 Batch 5: Train Loss = 0.2275\n",
      "Fold 4 Epoch 30 Batch 10: Train Loss = 0.2141\n",
      "Fold 4 Epoch 30 Batch 15: Train Loss = 0.1683\n",
      "Fold 4 Epoch 30 Batch 20: Train Loss = 0.3071\n",
      "Fold 4, epoch 30: Loss = 0.2241 Valid loss = 1.2076 roc = 0.8175\n",
      "confusion matrix:\n",
      "[[1125  147]\n",
      " [ 125  114]]\n",
      "accuracy = 0.8199867606163025\n",
      "precision class 0 = 0.8999999761581421\n",
      "precision class 1 = 0.4367816150188446\n",
      "recall class 0 = 0.8844339847564697\n",
      "recall class 1 = 0.47698745131492615\n",
      "AUC of ROC = 0.8175393410699718\n",
      "AUC of PRC = 0.3638331875139644\n",
      "min(+P, Se) = 0.45867768595041325\n",
      "f1_score = 0.4560000048260689\n",
      "Fold 4, roc = 0.8175, prc = 0.3638\n",
      "Fold 4 Epoch 31 Batch 0: Train Loss = 0.2218\n",
      "Fold 4 Epoch 31 Batch 5: Train Loss = 0.2592\n",
      "Fold 4 Epoch 31 Batch 10: Train Loss = 0.2179\n",
      "Fold 4 Epoch 31 Batch 15: Train Loss = 0.2121\n",
      "Fold 4 Epoch 31 Batch 20: Train Loss = 0.2068\n",
      "Fold 4, roc = 0.8310, prc = 0.5025\n",
      "Fold 4 Epoch 32 Batch 0: Train Loss = 0.2349\n",
      "Fold 4 Epoch 32 Batch 5: Train Loss = 0.1979\n",
      "Fold 4 Epoch 32 Batch 10: Train Loss = 0.2483\n",
      "Fold 4 Epoch 32 Batch 15: Train Loss = 0.2501\n",
      "Fold 4 Epoch 32 Batch 20: Train Loss = 0.2507\n",
      "Fold 4, roc = 0.8276, prc = 0.4153\n",
      "Fold 4 Epoch 33 Batch 0: Train Loss = 0.2206\n",
      "Fold 4 Epoch 33 Batch 5: Train Loss = 0.1722\n",
      "Fold 4 Epoch 33 Batch 10: Train Loss = 0.2127\n",
      "Fold 4 Epoch 33 Batch 15: Train Loss = 0.2627\n",
      "Fold 4 Epoch 33 Batch 20: Train Loss = 0.2407\n",
      "Fold 4, roc = 0.8101, prc = 0.4233\n",
      "Fold 4 Epoch 34 Batch 0: Train Loss = 0.2018\n",
      "Fold 4 Epoch 34 Batch 5: Train Loss = 0.1675\n",
      "Fold 4 Epoch 34 Batch 10: Train Loss = 0.2010\n",
      "Fold 4 Epoch 34 Batch 15: Train Loss = 0.2863\n",
      "Fold 4 Epoch 34 Batch 20: Train Loss = 0.2575\n",
      "Fold 4, roc = 0.8121, prc = 0.3881\n",
      "Fold 4 Epoch 35 Batch 0: Train Loss = 0.2237\n",
      "Fold 4 Epoch 35 Batch 5: Train Loss = 0.3055\n",
      "Fold 4 Epoch 35 Batch 10: Train Loss = 0.2097\n",
      "Fold 4 Epoch 35 Batch 15: Train Loss = 0.2291\n",
      "Fold 4 Epoch 35 Batch 20: Train Loss = 0.2545\n",
      "Fold 4, roc = 0.8187, prc = 0.3824\n",
      "Fold 4 Epoch 36 Batch 0: Train Loss = 0.2432\n",
      "Fold 4 Epoch 36 Batch 5: Train Loss = 0.2010\n",
      "Fold 4 Epoch 36 Batch 10: Train Loss = 0.1998\n",
      "Fold 4 Epoch 36 Batch 15: Train Loss = 0.1925\n",
      "Fold 4 Epoch 36 Batch 20: Train Loss = 0.2276\n",
      "Fold 4, roc = 0.8185, prc = 0.3777\n",
      "Fold 4 Epoch 37 Batch 0: Train Loss = 0.2681\n",
      "Fold 4 Epoch 37 Batch 5: Train Loss = 0.2268\n",
      "Fold 4 Epoch 37 Batch 10: Train Loss = 0.2062\n",
      "Fold 4 Epoch 37 Batch 15: Train Loss = 0.2248\n",
      "Fold 4 Epoch 37 Batch 20: Train Loss = 0.2508\n",
      "Fold 4, roc = 0.8091, prc = 0.3716\n",
      "Fold 4 Epoch 38 Batch 0: Train Loss = 0.1832\n",
      "Fold 4 Epoch 38 Batch 5: Train Loss = 0.2383\n",
      "Fold 4 Epoch 38 Batch 10: Train Loss = 0.1603\n",
      "Fold 4 Epoch 38 Batch 15: Train Loss = 0.2211\n",
      "Fold 4 Epoch 38 Batch 20: Train Loss = 0.2479\n",
      "Fold 4, roc = 0.8113, prc = 0.4082\n",
      "Fold 4 Epoch 39 Batch 0: Train Loss = 0.2575\n",
      "Fold 4 Epoch 39 Batch 5: Train Loss = 0.2393\n",
      "Fold 4 Epoch 39 Batch 10: Train Loss = 0.3122\n",
      "Fold 4 Epoch 39 Batch 15: Train Loss = 0.1779\n",
      "Fold 4 Epoch 39 Batch 20: Train Loss = 0.2711\n",
      "Fold 4, roc = 0.8305, prc = 0.4293\n",
      "Fold 4 Epoch 40 Batch 0: Train Loss = 0.2487\n",
      "Fold 4 Epoch 40 Batch 5: Train Loss = 0.2408\n",
      "Fold 4 Epoch 40 Batch 10: Train Loss = 0.1618\n",
      "Fold 4 Epoch 40 Batch 15: Train Loss = 0.2835\n",
      "Fold 4 Epoch 40 Batch 20: Train Loss = 0.2615\n",
      "Fold 4, epoch 40: Loss = 0.2225 Valid loss = 0.4213 roc = 0.7958\n",
      "confusion matrix:\n",
      "[[1176   96]\n",
      " [ 154   85]]\n",
      "accuracy = 0.834546685218811\n",
      "precision class 0 = 0.8842105269432068\n",
      "precision class 1 = 0.469613254070282\n",
      "recall class 0 = 0.9245283007621765\n",
      "recall class 1 = 0.35564854741096497\n",
      "AUC of ROC = 0.7958145838267413\n",
      "AUC of PRC = 0.409200680172464\n",
      "min(+P, Se) = 0.46443514644351463\n",
      "f1_score = 0.4047618957374104\n",
      "Fold 4, roc = 0.7958, prc = 0.4092\n",
      "Fold 4 Epoch 41 Batch 0: Train Loss = 0.2921\n",
      "Fold 4 Epoch 41 Batch 5: Train Loss = 0.2134\n",
      "Fold 4 Epoch 41 Batch 10: Train Loss = 0.2121\n",
      "Fold 4 Epoch 41 Batch 15: Train Loss = 0.2505\n",
      "Fold 4 Epoch 41 Batch 20: Train Loss = 0.2105\n",
      "Fold 4, roc = 0.8300, prc = 0.4643\n",
      "Fold 4 Epoch 42 Batch 0: Train Loss = 0.2263\n",
      "Fold 4 Epoch 42 Batch 5: Train Loss = 0.2387\n",
      "Fold 4 Epoch 42 Batch 10: Train Loss = 0.1705\n",
      "Fold 4 Epoch 42 Batch 15: Train Loss = 0.1843\n",
      "Fold 4 Epoch 42 Batch 20: Train Loss = 0.1771\n",
      "Fold 4, roc = 0.8222, prc = 0.4312\n",
      "Fold 4 Epoch 43 Batch 0: Train Loss = 0.2957\n",
      "Fold 4 Epoch 43 Batch 5: Train Loss = 0.2261\n",
      "Fold 4 Epoch 43 Batch 10: Train Loss = 0.1992\n",
      "Fold 4 Epoch 43 Batch 15: Train Loss = 0.2933\n",
      "Fold 4 Epoch 43 Batch 20: Train Loss = 0.2165\n",
      "Fold 4, roc = 0.8294, prc = 0.4685\n",
      "Fold 4 Epoch 44 Batch 0: Train Loss = 0.1645\n",
      "Fold 4 Epoch 44 Batch 5: Train Loss = 0.2003\n",
      "Fold 4 Epoch 44 Batch 10: Train Loss = 0.1675\n",
      "Fold 4 Epoch 44 Batch 15: Train Loss = 0.1892\n",
      "Fold 4 Epoch 44 Batch 20: Train Loss = 0.2266\n",
      "Fold 4, roc = 0.8291, prc = 0.4193\n",
      "Fold 4 Epoch 45 Batch 0: Train Loss = 0.2077\n",
      "Fold 4 Epoch 45 Batch 5: Train Loss = 0.1885\n",
      "Fold 4 Epoch 45 Batch 10: Train Loss = 0.2154\n",
      "Fold 4 Epoch 45 Batch 15: Train Loss = 0.1483\n",
      "Fold 4 Epoch 45 Batch 20: Train Loss = 0.2649\n",
      "Fold 4, roc = 0.8377, prc = 0.5028\n",
      "Fold 4 Epoch 46 Batch 0: Train Loss = 0.1975\n",
      "Fold 4 Epoch 46 Batch 5: Train Loss = 0.1866\n",
      "Fold 4 Epoch 46 Batch 10: Train Loss = 0.2423\n",
      "Fold 4 Epoch 46 Batch 15: Train Loss = 0.2103\n",
      "Fold 4 Epoch 46 Batch 20: Train Loss = 0.1475\n",
      "Fold 4, roc = 0.8429, prc = 0.4721\n",
      "Fold 4 Epoch 47 Batch 0: Train Loss = 0.2268\n",
      "Fold 4 Epoch 47 Batch 5: Train Loss = 0.2115\n",
      "Fold 4 Epoch 47 Batch 10: Train Loss = 0.2313\n",
      "Fold 4 Epoch 47 Batch 15: Train Loss = 0.2038\n",
      "Fold 4 Epoch 47 Batch 20: Train Loss = 0.1869\n",
      "Fold 4, roc = 0.8454, prc = 0.4808\n",
      "Fold 4 Epoch 48 Batch 0: Train Loss = 0.2287\n",
      "Fold 4 Epoch 48 Batch 5: Train Loss = 0.2066\n",
      "Fold 4 Epoch 48 Batch 10: Train Loss = 0.1942\n",
      "Fold 4 Epoch 48 Batch 15: Train Loss = 0.1908\n",
      "Fold 4 Epoch 48 Batch 20: Train Loss = 0.1677\n",
      "Fold 4, roc = 0.8194, prc = 0.4821\n",
      "Fold 4 Epoch 49 Batch 0: Train Loss = 0.2134\n",
      "Fold 4 Epoch 49 Batch 5: Train Loss = 0.1359\n",
      "Fold 4 Epoch 49 Batch 10: Train Loss = 0.1697\n",
      "Fold 4 Epoch 49 Batch 15: Train Loss = 0.1625\n",
      "Fold 4 Epoch 49 Batch 20: Train Loss = 0.1828\n",
      "Fold 4, roc = 0.8353, prc = 0.4728\n",
      "Fold 4 Epoch 50 Batch 0: Train Loss = 0.2787\n",
      "Fold 4 Epoch 50 Batch 5: Train Loss = 0.1749\n",
      "Fold 4 Epoch 50 Batch 10: Train Loss = 0.1568\n",
      "Fold 4 Epoch 50 Batch 15: Train Loss = 0.2415\n",
      "Fold 4 Epoch 50 Batch 20: Train Loss = 0.2894\n",
      "Fold 4, epoch 50: Loss = 0.2106 Valid loss = 0.4024 roc = 0.8248\n",
      "confusion matrix:\n",
      "[[1216   56]\n",
      " [ 160   79]]\n",
      "accuracy = 0.8570483326911926\n",
      "precision class 0 = 0.8837209343910217\n",
      "precision class 1 = 0.585185170173645\n",
      "recall class 0 = 0.955974817276001\n",
      "recall class 1 = 0.3305439352989197\n",
      "AUC of ROC = 0.8248434251730217\n",
      "AUC of PRC = 0.46195954588815036\n",
      "min(+P, Se) = 0.5102040816326531\n",
      "f1_score = 0.42245989096949105\n",
      "Fold 4, roc = 0.8248, prc = 0.4620\n",
      "Fold 4 Epoch 51 Batch 0: Train Loss = 0.2027\n",
      "Fold 4 Epoch 51 Batch 5: Train Loss = 0.2607\n",
      "Fold 4 Epoch 51 Batch 10: Train Loss = 0.2226\n",
      "Fold 4 Epoch 51 Batch 15: Train Loss = 0.1724\n",
      "Fold 4 Epoch 51 Batch 20: Train Loss = 0.2007\n",
      "Fold 4, roc = 0.8051, prc = 0.4629\n",
      "Fold 4 Epoch 52 Batch 0: Train Loss = 0.2206\n",
      "Fold 4 Epoch 52 Batch 5: Train Loss = 0.1612\n",
      "Fold 4 Epoch 52 Batch 10: Train Loss = 0.2118\n",
      "Fold 4 Epoch 52 Batch 15: Train Loss = 0.2469\n",
      "Fold 4 Epoch 52 Batch 20: Train Loss = 0.2485\n",
      "Fold 4, roc = 0.8114, prc = 0.4585\n",
      "Fold 4 Epoch 53 Batch 0: Train Loss = 0.2099\n",
      "Fold 4 Epoch 53 Batch 5: Train Loss = 0.2327\n",
      "Fold 4 Epoch 53 Batch 10: Train Loss = 0.1928\n",
      "Fold 4 Epoch 53 Batch 15: Train Loss = 0.2128\n",
      "Fold 4 Epoch 53 Batch 20: Train Loss = 0.1635\n",
      "Fold 4, roc = 0.8137, prc = 0.4773\n",
      "Fold 4 Epoch 54 Batch 0: Train Loss = 0.1984\n",
      "Fold 4 Epoch 54 Batch 5: Train Loss = 0.1811\n",
      "Fold 4 Epoch 54 Batch 10: Train Loss = 0.2358\n",
      "Fold 4 Epoch 54 Batch 15: Train Loss = 0.2009\n",
      "Fold 4 Epoch 54 Batch 20: Train Loss = 0.1618\n",
      "Fold 4, roc = 0.8144, prc = 0.4642\n",
      "Fold 4 Epoch 55 Batch 0: Train Loss = 0.2537\n",
      "Fold 4 Epoch 55 Batch 5: Train Loss = 0.2348\n",
      "Fold 4 Epoch 55 Batch 10: Train Loss = 0.2879\n",
      "Fold 4 Epoch 55 Batch 15: Train Loss = 0.1623\n",
      "Fold 4 Epoch 55 Batch 20: Train Loss = 0.2259\n",
      "Fold 4, roc = 0.8145, prc = 0.4469\n",
      "Fold 4 Epoch 56 Batch 0: Train Loss = 0.2211\n",
      "Fold 4 Epoch 56 Batch 5: Train Loss = 0.2486\n",
      "Fold 4 Epoch 56 Batch 10: Train Loss = 0.1692\n",
      "Fold 4 Epoch 56 Batch 15: Train Loss = 0.2258\n",
      "Fold 4 Epoch 56 Batch 20: Train Loss = 0.2346\n",
      "Fold 4, roc = 0.8304, prc = 0.4526\n",
      "Fold 4 Epoch 57 Batch 0: Train Loss = 0.1441\n",
      "Fold 4 Epoch 57 Batch 5: Train Loss = 0.2438\n",
      "Fold 4 Epoch 57 Batch 10: Train Loss = 0.2349\n",
      "Fold 4 Epoch 57 Batch 15: Train Loss = 0.2788\n",
      "Fold 4 Epoch 57 Batch 20: Train Loss = 0.1792\n",
      "Fold 4, roc = 0.8035, prc = 0.4324\n",
      "Fold 4 Epoch 58 Batch 0: Train Loss = 0.1937\n",
      "Fold 4 Epoch 58 Batch 5: Train Loss = 0.1673\n",
      "Fold 4 Epoch 58 Batch 10: Train Loss = 0.1745\n",
      "Fold 4 Epoch 58 Batch 15: Train Loss = 0.1367\n",
      "Fold 4 Epoch 58 Batch 20: Train Loss = 0.1705\n",
      "Fold 4, roc = 0.8174, prc = 0.4528\n",
      "Fold 4 Epoch 59 Batch 0: Train Loss = 0.2078\n",
      "Fold 4 Epoch 59 Batch 5: Train Loss = 0.1861\n",
      "Fold 4 Epoch 59 Batch 10: Train Loss = 0.2049\n",
      "Fold 4 Epoch 59 Batch 15: Train Loss = 0.1364\n",
      "Fold 4 Epoch 59 Batch 20: Train Loss = 0.2203\n",
      "Fold 4, roc = 0.8387, prc = 0.4413\n",
      "Fold 4 Epoch 60 Batch 0: Train Loss = 0.2517\n",
      "Fold 4 Epoch 60 Batch 5: Train Loss = 0.1836\n",
      "Fold 4 Epoch 60 Batch 10: Train Loss = 0.2529\n",
      "Fold 4 Epoch 60 Batch 15: Train Loss = 0.2154\n",
      "Fold 4 Epoch 60 Batch 20: Train Loss = 0.2397\n",
      "Fold 4, epoch 60: Loss = 0.2010 Valid loss = 0.4173 roc = 0.8388\n",
      "confusion matrix:\n",
      "[[1176   96]\n",
      " [ 129  110]]\n",
      "accuracy = 0.8510919809341431\n",
      "precision class 0 = 0.9011494517326355\n",
      "precision class 1 = 0.5339806079864502\n",
      "recall class 0 = 0.9245283007621765\n",
      "recall class 1 = 0.4602510333061218\n",
      "AUC of ROC = 0.8388463461487856\n",
      "AUC of PRC = 0.46396608315088556\n",
      "min(+P, Se) = 0.5102880658436214\n",
      "f1_score = 0.4943820260471346\n",
      "Fold 4, roc = 0.8388, prc = 0.4640\n",
      "Fold 4 Epoch 61 Batch 0: Train Loss = 0.1890\n",
      "Fold 4 Epoch 61 Batch 5: Train Loss = 0.1595\n",
      "Fold 4 Epoch 61 Batch 10: Train Loss = 0.1311\n",
      "Fold 4 Epoch 61 Batch 15: Train Loss = 0.2015\n",
      "Fold 4 Epoch 61 Batch 20: Train Loss = 0.1862\n",
      "Fold 4, roc = 0.8217, prc = 0.4369\n",
      "Fold 4 Epoch 62 Batch 0: Train Loss = 0.1915\n",
      "Fold 4 Epoch 62 Batch 5: Train Loss = 0.1593\n",
      "Fold 4 Epoch 62 Batch 10: Train Loss = 0.1974\n",
      "Fold 4 Epoch 62 Batch 15: Train Loss = 0.2284\n",
      "Fold 4 Epoch 62 Batch 20: Train Loss = 0.2119\n",
      "Fold 4, roc = 0.8505, prc = 0.4884\n",
      "Fold 4 Epoch 63 Batch 0: Train Loss = 0.1559\n",
      "Fold 4 Epoch 63 Batch 5: Train Loss = 0.1993\n",
      "Fold 4 Epoch 63 Batch 10: Train Loss = 0.1862\n",
      "Fold 4 Epoch 63 Batch 15: Train Loss = 0.2186\n",
      "Fold 4 Epoch 63 Batch 20: Train Loss = 0.2341\n",
      "Fold 4, roc = 0.8444, prc = 0.4689\n",
      "Fold 4 Epoch 64 Batch 0: Train Loss = 0.1778\n",
      "Fold 4 Epoch 64 Batch 5: Train Loss = 0.1859\n",
      "Fold 4 Epoch 64 Batch 10: Train Loss = 0.1792\n",
      "Fold 4 Epoch 64 Batch 15: Train Loss = 0.1658\n",
      "Fold 4 Epoch 64 Batch 20: Train Loss = 0.1728\n",
      "Fold 4, roc = 0.8358, prc = 0.4760\n",
      "Fold 4 Epoch 65 Batch 0: Train Loss = 0.1853\n",
      "Fold 4 Epoch 65 Batch 5: Train Loss = 0.1632\n",
      "Fold 4 Epoch 65 Batch 10: Train Loss = 0.2470\n",
      "Fold 4 Epoch 65 Batch 15: Train Loss = 0.1754\n",
      "Fold 4 Epoch 65 Batch 20: Train Loss = 0.1948\n",
      "Fold 4, roc = 0.8315, prc = 0.4503\n",
      "Fold 4 Epoch 66 Batch 0: Train Loss = 0.1637\n",
      "Fold 4 Epoch 66 Batch 5: Train Loss = 0.1802\n",
      "Fold 4 Epoch 66 Batch 10: Train Loss = 0.2228\n",
      "Fold 4 Epoch 66 Batch 15: Train Loss = 0.1708\n",
      "Fold 4 Epoch 66 Batch 20: Train Loss = 0.2133\n",
      "Fold 4, roc = 0.8232, prc = 0.4400\n",
      "Fold 4 Epoch 67 Batch 0: Train Loss = 0.1792\n",
      "Fold 4 Epoch 67 Batch 5: Train Loss = 0.1988\n",
      "Fold 4 Epoch 67 Batch 10: Train Loss = 0.2139\n",
      "Fold 4 Epoch 67 Batch 15: Train Loss = 0.1519\n",
      "Fold 4 Epoch 67 Batch 20: Train Loss = 0.2050\n",
      "Fold 4, roc = 0.8030, prc = 0.4264\n",
      "Fold 4 Epoch 68 Batch 0: Train Loss = 0.2447\n",
      "Fold 4 Epoch 68 Batch 5: Train Loss = 0.2024\n",
      "Fold 4 Epoch 68 Batch 10: Train Loss = 0.2438\n",
      "Fold 4 Epoch 68 Batch 15: Train Loss = 0.1733\n",
      "Fold 4 Epoch 68 Batch 20: Train Loss = 0.1842\n",
      "Fold 4, roc = 0.7725, prc = 0.4270\n",
      "Fold 4 Epoch 69 Batch 0: Train Loss = 0.2406\n",
      "Fold 4 Epoch 69 Batch 5: Train Loss = 0.2673\n",
      "Fold 4 Epoch 69 Batch 10: Train Loss = 0.2157\n",
      "Fold 4 Epoch 69 Batch 15: Train Loss = 0.2246\n",
      "Fold 4 Epoch 69 Batch 20: Train Loss = 0.1875\n",
      "Fold 4, roc = 0.8084, prc = 0.4040\n",
      "Fold 4 Epoch 70 Batch 0: Train Loss = 0.1666\n",
      "Fold 4 Epoch 70 Batch 5: Train Loss = 0.2332\n",
      "Fold 4 Epoch 70 Batch 10: Train Loss = 0.1970\n",
      "Fold 4 Epoch 70 Batch 15: Train Loss = 0.1780\n",
      "Fold 4 Epoch 70 Batch 20: Train Loss = 0.2348\n",
      "Fold 4, epoch 70: Loss = 0.1961 Valid loss = 0.4500 roc = 0.8315\n",
      "confusion matrix:\n",
      "[[1156  116]\n",
      " [ 114  125]]\n",
      "accuracy = 0.8477829098701477\n",
      "precision class 0 = 0.9102362394332886\n",
      "precision class 1 = 0.5186722278594971\n",
      "recall class 0 = 0.9088050127029419\n",
      "recall class 1 = 0.5230125784873962\n",
      "AUC of ROC = 0.8315373279650535\n",
      "AUC of PRC = 0.43757294413231407\n",
      "min(+P, Se) = 0.5188284518828452\n",
      "f1_score = 0.5208333309801934\n",
      "Fold 4, roc = 0.8315, prc = 0.4376\n",
      "Fold 4 Epoch 71 Batch 0: Train Loss = 0.1395\n",
      "Fold 4 Epoch 71 Batch 5: Train Loss = 0.1450\n",
      "Fold 4 Epoch 71 Batch 10: Train Loss = 0.2176\n",
      "Fold 4 Epoch 71 Batch 15: Train Loss = 0.2197\n",
      "Fold 4 Epoch 71 Batch 20: Train Loss = 0.2297\n",
      "Fold 4, roc = 0.8250, prc = 0.4172\n",
      "Fold 4 Epoch 72 Batch 0: Train Loss = 0.1791\n",
      "Fold 4 Epoch 72 Batch 5: Train Loss = 0.2016\n",
      "Fold 4 Epoch 72 Batch 10: Train Loss = 0.2223\n",
      "Fold 4 Epoch 72 Batch 15: Train Loss = 0.1754\n",
      "Fold 4 Epoch 72 Batch 20: Train Loss = 0.1801\n",
      "Fold 4, roc = 0.7982, prc = 0.4238\n",
      "Fold 4 Epoch 73 Batch 0: Train Loss = 0.1755\n",
      "Fold 4 Epoch 73 Batch 5: Train Loss = 0.2287\n",
      "Fold 4 Epoch 73 Batch 10: Train Loss = 0.1470\n",
      "Fold 4 Epoch 73 Batch 15: Train Loss = 0.1719\n",
      "Fold 4 Epoch 73 Batch 20: Train Loss = 0.1606\n",
      "Fold 4, roc = 0.7873, prc = 0.4237\n",
      "Fold 4 Epoch 74 Batch 0: Train Loss = 0.2001\n",
      "Fold 4 Epoch 74 Batch 5: Train Loss = 0.2351\n",
      "Fold 4 Epoch 74 Batch 10: Train Loss = 0.2191\n",
      "Fold 4 Epoch 74 Batch 15: Train Loss = 0.2150\n",
      "Fold 4 Epoch 74 Batch 20: Train Loss = 0.1893\n",
      "Fold 4, roc = 0.8286, prc = 0.4295\n",
      "Fold 4 Epoch 75 Batch 0: Train Loss = 0.2003\n",
      "Fold 4 Epoch 75 Batch 5: Train Loss = 0.2150\n",
      "Fold 4 Epoch 75 Batch 10: Train Loss = 0.1773\n",
      "Fold 4 Epoch 75 Batch 15: Train Loss = 0.1940\n",
      "Fold 4 Epoch 75 Batch 20: Train Loss = 0.1795\n",
      "Fold 4, roc = 0.8100, prc = 0.4210\n",
      "Fold 4 Epoch 76 Batch 0: Train Loss = 0.2096\n",
      "Fold 4 Epoch 76 Batch 5: Train Loss = 0.1382\n",
      "Fold 4 Epoch 76 Batch 10: Train Loss = 0.1849\n",
      "Fold 4 Epoch 76 Batch 15: Train Loss = 0.2255\n",
      "Fold 4 Epoch 76 Batch 20: Train Loss = 0.1838\n",
      "Fold 4, roc = 0.8142, prc = 0.4427\n",
      "Fold 4 Epoch 77 Batch 0: Train Loss = 0.1861\n",
      "Fold 4 Epoch 77 Batch 5: Train Loss = 0.1885\n",
      "Fold 4 Epoch 77 Batch 10: Train Loss = 0.1330\n",
      "Fold 4 Epoch 77 Batch 15: Train Loss = 0.1532\n",
      "Fold 4 Epoch 77 Batch 20: Train Loss = 0.2078\n",
      "Fold 4, roc = 0.8214, prc = 0.4014\n",
      "Fold 4 Epoch 78 Batch 0: Train Loss = 0.1752\n",
      "Fold 4 Epoch 78 Batch 5: Train Loss = 0.1945\n",
      "Fold 4 Epoch 78 Batch 10: Train Loss = 0.1845\n",
      "Fold 4 Epoch 78 Batch 15: Train Loss = 0.2245\n",
      "Fold 4 Epoch 78 Batch 20: Train Loss = 0.1700\n",
      "Fold 4, roc = 0.7675, prc = 0.3759\n",
      "Fold 4 Epoch 79 Batch 0: Train Loss = 0.2496\n",
      "Fold 4 Epoch 79 Batch 5: Train Loss = 0.2134\n",
      "Fold 4 Epoch 79 Batch 10: Train Loss = 0.1328\n",
      "Fold 4 Epoch 79 Batch 15: Train Loss = 0.2129\n",
      "Fold 4 Epoch 79 Batch 20: Train Loss = 0.1854\n",
      "Fold 4, roc = 0.7484, prc = 0.3793\n",
      "Fold 4 Epoch 80 Batch 0: Train Loss = 0.2437\n",
      "Fold 4 Epoch 80 Batch 5: Train Loss = 0.1918\n",
      "Fold 4 Epoch 80 Batch 10: Train Loss = 0.2064\n",
      "Fold 4 Epoch 80 Batch 15: Train Loss = 0.1620\n",
      "Fold 4 Epoch 80 Batch 20: Train Loss = 0.2183\n",
      "Fold 4, epoch 80: Loss = 0.1861 Valid loss = 0.5263 roc = 0.7829\n",
      "confusion matrix:\n",
      "[[1174   98]\n",
      " [ 139  100]]\n",
      "accuracy = 0.84315025806427\n",
      "precision class 0 = 0.894135594367981\n",
      "precision class 1 = 0.5050504803657532\n",
      "recall class 0 = 0.9229559898376465\n",
      "recall class 1 = 0.4184100329875946\n",
      "AUC of ROC = 0.7828675561169441\n",
      "AUC of PRC = 0.38897543986188154\n",
      "min(+P, Se) = 0.47540983606557374\n",
      "f1_score = 0.457665903228785\n",
      "Fold 4, roc = 0.7829, prc = 0.3890\n",
      "Fold 4 Epoch 81 Batch 0: Train Loss = 0.1650\n",
      "Fold 4 Epoch 81 Batch 5: Train Loss = 0.1886\n",
      "Fold 4 Epoch 81 Batch 10: Train Loss = 0.1265\n",
      "Fold 4 Epoch 81 Batch 15: Train Loss = 0.1464\n",
      "Fold 4 Epoch 81 Batch 20: Train Loss = 0.1789\n",
      "Fold 4, roc = 0.7975, prc = 0.3930\n",
      "Fold 4 Epoch 82 Batch 0: Train Loss = 0.2424\n",
      "Fold 4 Epoch 82 Batch 5: Train Loss = 0.1417\n",
      "Fold 4 Epoch 82 Batch 10: Train Loss = 0.1455\n",
      "Fold 4 Epoch 82 Batch 15: Train Loss = 0.1992\n",
      "Fold 4 Epoch 82 Batch 20: Train Loss = 0.1435\n",
      "Fold 4, roc = 0.8100, prc = 0.3893\n",
      "Fold 4 Epoch 83 Batch 0: Train Loss = 0.2172\n",
      "Fold 4 Epoch 83 Batch 5: Train Loss = 0.1957\n",
      "Fold 4 Epoch 83 Batch 10: Train Loss = 0.1696\n",
      "Fold 4 Epoch 83 Batch 15: Train Loss = 0.1867\n",
      "Fold 4 Epoch 83 Batch 20: Train Loss = 0.2128\n",
      "Fold 4, roc = 0.7895, prc = 0.4010\n",
      "Fold 4 Epoch 84 Batch 0: Train Loss = 0.1757\n",
      "Fold 4 Epoch 84 Batch 5: Train Loss = 0.1710\n",
      "Fold 4 Epoch 84 Batch 10: Train Loss = 0.1999\n",
      "Fold 4 Epoch 84 Batch 15: Train Loss = 0.1234\n",
      "Fold 4 Epoch 84 Batch 20: Train Loss = 0.1727\n",
      "Fold 4, roc = 0.7733, prc = 0.4104\n",
      "Fold 4 Epoch 85 Batch 0: Train Loss = 0.1708\n",
      "Fold 4 Epoch 85 Batch 5: Train Loss = 0.1373\n",
      "Fold 4 Epoch 85 Batch 10: Train Loss = 0.1293\n",
      "Fold 4 Epoch 85 Batch 15: Train Loss = 0.1747\n",
      "Fold 4 Epoch 85 Batch 20: Train Loss = 0.2037\n",
      "Fold 4, roc = 0.7816, prc = 0.4143\n",
      "Fold 4 Epoch 86 Batch 0: Train Loss = 0.1539\n",
      "Fold 4 Epoch 86 Batch 5: Train Loss = 0.1784\n",
      "Fold 4 Epoch 86 Batch 10: Train Loss = 0.1906\n",
      "Fold 4 Epoch 86 Batch 15: Train Loss = 0.1412\n",
      "Fold 4 Epoch 86 Batch 20: Train Loss = 0.1941\n",
      "Fold 4, roc = 0.8100, prc = 0.4087\n",
      "Fold 4 Epoch 87 Batch 0: Train Loss = 0.1766\n",
      "Fold 4 Epoch 87 Batch 5: Train Loss = 0.1627\n",
      "Fold 4 Epoch 87 Batch 10: Train Loss = 0.1693\n",
      "Fold 4 Epoch 87 Batch 15: Train Loss = 0.1598\n",
      "Fold 4 Epoch 87 Batch 20: Train Loss = 0.2123\n",
      "Fold 4, roc = 0.7855, prc = 0.4040\n",
      "Fold 4 Epoch 88 Batch 0: Train Loss = 0.1096\n",
      "Fold 4 Epoch 88 Batch 5: Train Loss = 0.2055\n",
      "Fold 4 Epoch 88 Batch 10: Train Loss = 0.2036\n",
      "Fold 4 Epoch 88 Batch 15: Train Loss = 0.1855\n",
      "Fold 4 Epoch 88 Batch 20: Train Loss = 0.2157\n",
      "Fold 4, roc = 0.8014, prc = 0.4134\n",
      "Fold 4 Epoch 89 Batch 0: Train Loss = 0.1448\n",
      "Fold 4 Epoch 89 Batch 5: Train Loss = 0.1693\n",
      "Fold 4 Epoch 89 Batch 10: Train Loss = 0.1565\n",
      "Fold 4 Epoch 89 Batch 15: Train Loss = 0.1506\n",
      "Fold 4 Epoch 89 Batch 20: Train Loss = 0.2405\n",
      "Fold 4, roc = 0.7928, prc = 0.4099\n",
      "Fold 4 Epoch 90 Batch 0: Train Loss = 0.2242\n",
      "Fold 4 Epoch 90 Batch 5: Train Loss = 0.2151\n",
      "Fold 4 Epoch 90 Batch 10: Train Loss = 0.1637\n",
      "Fold 4 Epoch 90 Batch 15: Train Loss = 0.1850\n",
      "Fold 4 Epoch 90 Batch 20: Train Loss = 0.1857\n",
      "Fold 4, epoch 90: Loss = 0.1858 Valid loss = 0.5166 roc = 0.7987\n",
      "confusion matrix:\n",
      "[[1223   49]\n",
      " [ 169   70]]\n",
      "accuracy = 0.8557246923446655\n",
      "precision class 0 = 0.8785919547080994\n",
      "precision class 1 = 0.5882353186607361\n",
      "recall class 0 = 0.9614779949188232\n",
      "recall class 1 = 0.29288703203201294\n",
      "AUC of ROC = 0.7986895081708376\n",
      "AUC of PRC = 0.42123223830042306\n",
      "min(+P, Se) = 0.502092050209205\n",
      "f1_score = 0.3910614603828733\n",
      "Fold 4, roc = 0.7987, prc = 0.4212\n",
      "Fold 4 Epoch 91 Batch 0: Train Loss = 0.1725\n",
      "Fold 4 Epoch 91 Batch 5: Train Loss = 0.1744\n",
      "Fold 4 Epoch 91 Batch 10: Train Loss = 0.1859\n",
      "Fold 4 Epoch 91 Batch 15: Train Loss = 0.1412\n",
      "Fold 4 Epoch 91 Batch 20: Train Loss = 0.1937\n",
      "Fold 4, roc = 0.7912, prc = 0.4110\n",
      "Fold 4 Epoch 92 Batch 0: Train Loss = 0.1979\n",
      "Fold 4 Epoch 92 Batch 5: Train Loss = 0.1206\n",
      "Fold 4 Epoch 92 Batch 10: Train Loss = 0.1780\n",
      "Fold 4 Epoch 92 Batch 15: Train Loss = 0.2009\n",
      "Fold 4 Epoch 92 Batch 20: Train Loss = 0.1579\n",
      "Fold 4, roc = 0.7948, prc = 0.4211\n",
      "Fold 4 Epoch 93 Batch 0: Train Loss = 0.1258\n",
      "Fold 4 Epoch 93 Batch 5: Train Loss = 0.1831\n",
      "Fold 4 Epoch 93 Batch 10: Train Loss = 0.1946\n",
      "Fold 4 Epoch 93 Batch 15: Train Loss = 0.1550\n",
      "Fold 4 Epoch 93 Batch 20: Train Loss = 0.1822\n",
      "Fold 4, roc = 0.8037, prc = 0.4015\n",
      "Fold 4 Epoch 94 Batch 0: Train Loss = 0.1822\n",
      "Fold 4 Epoch 94 Batch 5: Train Loss = 0.1372\n",
      "Fold 4 Epoch 94 Batch 10: Train Loss = 0.1795\n",
      "Fold 4 Epoch 94 Batch 15: Train Loss = 0.1430\n",
      "Fold 4 Epoch 94 Batch 20: Train Loss = 0.1699\n",
      "Fold 4, roc = 0.8025, prc = 0.4063\n",
      "Fold 4 Epoch 95 Batch 0: Train Loss = 0.2009\n",
      "Fold 4 Epoch 95 Batch 5: Train Loss = 0.1433\n",
      "Fold 4 Epoch 95 Batch 10: Train Loss = 0.1502\n",
      "Fold 4 Epoch 95 Batch 15: Train Loss = 0.2232\n",
      "Fold 4 Epoch 95 Batch 20: Train Loss = 0.1325\n",
      "Fold 4, roc = 0.7845, prc = 0.4095\n",
      "Fold 4 Epoch 96 Batch 0: Train Loss = 0.1328\n",
      "Fold 4 Epoch 96 Batch 5: Train Loss = 0.1878\n",
      "Fold 4 Epoch 96 Batch 10: Train Loss = 0.2113\n",
      "Fold 4 Epoch 96 Batch 15: Train Loss = 0.1613\n",
      "Fold 4 Epoch 96 Batch 20: Train Loss = 0.2112\n",
      "Fold 4, roc = 0.7792, prc = 0.4148\n",
      "Fold 4 Epoch 97 Batch 0: Train Loss = 0.1628\n",
      "Fold 4 Epoch 97 Batch 5: Train Loss = 0.1504\n",
      "Fold 4 Epoch 97 Batch 10: Train Loss = 0.2421\n",
      "Fold 4 Epoch 97 Batch 15: Train Loss = 0.1760\n",
      "Fold 4 Epoch 97 Batch 20: Train Loss = 0.2036\n",
      "Fold 4, roc = 0.7704, prc = 0.4020\n",
      "Fold 4 Epoch 98 Batch 0: Train Loss = 0.1795\n",
      "Fold 4 Epoch 98 Batch 5: Train Loss = 0.1809\n",
      "Fold 4 Epoch 98 Batch 10: Train Loss = 0.1615\n",
      "Fold 4 Epoch 98 Batch 15: Train Loss = 0.1714\n",
      "Fold 4 Epoch 98 Batch 20: Train Loss = 0.1626\n",
      "Fold 4, roc = 0.7826, prc = 0.3974\n",
      "Fold 4 Epoch 99 Batch 0: Train Loss = 0.1548\n",
      "Fold 4 Epoch 99 Batch 5: Train Loss = 0.2176\n",
      "Fold 4 Epoch 99 Batch 10: Train Loss = 0.1812\n",
      "Fold 4 Epoch 99 Batch 15: Train Loss = 0.1470\n",
      "Fold 4 Epoch 99 Batch 20: Train Loss = 0.1902\n",
      "Fold 4, roc = 0.7791, prc = 0.3962\n",
      "Fold 4 Epoch 100 Batch 0: Train Loss = 0.1595\n",
      "Fold 4 Epoch 100 Batch 5: Train Loss = 0.1522\n",
      "Fold 4 Epoch 100 Batch 10: Train Loss = 0.1305\n",
      "Fold 4 Epoch 100 Batch 15: Train Loss = 0.1985\n",
      "Fold 4 Epoch 100 Batch 20: Train Loss = 0.1534\n",
      "Fold 4, epoch 100: Loss = 0.1718 Valid loss = 0.6282 roc = 0.7592\n",
      "confusion matrix:\n",
      "[[1169  103]\n",
      " [ 134  105]]\n",
      "accuracy = 0.84315025806427\n",
      "precision class 0 = 0.8971604108810425\n",
      "precision class 1 = 0.504807710647583\n",
      "recall class 0 = 0.919025182723999\n",
      "recall class 1 = 0.4393305480480194\n",
      "AUC of ROC = 0.7592300202626246\n",
      "AUC of PRC = 0.37748804078362064\n",
      "min(+P, Se) = 0.4897119341563786\n",
      "f1_score = 0.46979865318353964\n",
      "Fold 4, roc = 0.7592, prc = 0.3775\n",
      "Fold 4 Epoch 101 Batch 0: Train Loss = 0.1798\n",
      "Fold 4 Epoch 101 Batch 5: Train Loss = 0.1761\n",
      "Fold 4 Epoch 101 Batch 10: Train Loss = 0.1405\n",
      "Fold 4 Epoch 101 Batch 15: Train Loss = 0.1643\n",
      "Fold 4 Epoch 101 Batch 20: Train Loss = 0.1227\n",
      "Fold 4, roc = 0.7493, prc = 0.3878\n",
      "Fold 4 Epoch 102 Batch 0: Train Loss = 0.1437\n",
      "Fold 4 Epoch 102 Batch 5: Train Loss = 0.1421\n",
      "Fold 4 Epoch 102 Batch 10: Train Loss = 0.1303\n",
      "Fold 4 Epoch 102 Batch 15: Train Loss = 0.2237\n",
      "Fold 4 Epoch 102 Batch 20: Train Loss = 0.1383\n",
      "Fold 4, roc = 0.7633, prc = 0.3923\n",
      "Fold 4 Epoch 103 Batch 0: Train Loss = 0.2483\n",
      "Fold 4 Epoch 103 Batch 5: Train Loss = 0.1945\n",
      "Fold 4 Epoch 103 Batch 10: Train Loss = 0.1501\n",
      "Fold 4 Epoch 103 Batch 15: Train Loss = 0.1761\n",
      "Fold 4 Epoch 103 Batch 20: Train Loss = 0.1246\n",
      "Fold 4, roc = 0.7901, prc = 0.3931\n",
      "Fold 4 Epoch 104 Batch 0: Train Loss = 0.1836\n",
      "Fold 4 Epoch 104 Batch 5: Train Loss = 0.2083\n",
      "Fold 4 Epoch 104 Batch 10: Train Loss = 0.2213\n",
      "Fold 4 Epoch 104 Batch 15: Train Loss = 0.1695\n",
      "Fold 4 Epoch 104 Batch 20: Train Loss = 0.2415\n",
      "Fold 4, roc = 0.7714, prc = 0.3925\n",
      "Fold 4 Epoch 105 Batch 0: Train Loss = 0.1713\n",
      "Fold 4 Epoch 105 Batch 5: Train Loss = 0.2078\n",
      "Fold 4 Epoch 105 Batch 10: Train Loss = 0.1836\n",
      "Fold 4 Epoch 105 Batch 15: Train Loss = 0.1846\n",
      "Fold 4 Epoch 105 Batch 20: Train Loss = 0.1293\n",
      "Fold 4, roc = 0.7694, prc = 0.3967\n",
      "Fold 4 Epoch 106 Batch 0: Train Loss = 0.1882\n",
      "Fold 4 Epoch 106 Batch 5: Train Loss = 0.1474\n",
      "Fold 4 Epoch 106 Batch 10: Train Loss = 0.1671\n",
      "Fold 4 Epoch 106 Batch 15: Train Loss = 0.1564\n",
      "Fold 4 Epoch 106 Batch 20: Train Loss = 0.1484\n",
      "Fold 4, roc = 0.7625, prc = 0.3776\n",
      "Fold 4 Epoch 107 Batch 0: Train Loss = 0.2073\n",
      "Fold 4 Epoch 107 Batch 5: Train Loss = 0.1543\n",
      "Fold 4 Epoch 107 Batch 10: Train Loss = 0.1892\n",
      "Fold 4 Epoch 107 Batch 15: Train Loss = 0.1679\n",
      "Fold 4 Epoch 107 Batch 20: Train Loss = 0.1662\n",
      "Fold 4, roc = 0.7657, prc = 0.3971\n",
      "Fold 4 Epoch 108 Batch 0: Train Loss = 0.2111\n",
      "Fold 4 Epoch 108 Batch 5: Train Loss = 0.1899\n",
      "Fold 4 Epoch 108 Batch 10: Train Loss = 0.1609\n",
      "Fold 4 Epoch 108 Batch 15: Train Loss = 0.1739\n",
      "Fold 4 Epoch 108 Batch 20: Train Loss = 0.1677\n",
      "Fold 4, roc = 0.7665, prc = 0.3903\n",
      "Fold 4 Epoch 109 Batch 0: Train Loss = 0.1766\n",
      "Fold 4 Epoch 109 Batch 5: Train Loss = 0.1955\n",
      "Fold 4 Epoch 109 Batch 10: Train Loss = 0.0899\n",
      "Fold 4 Epoch 109 Batch 15: Train Loss = 0.1142\n",
      "Fold 4 Epoch 109 Batch 20: Train Loss = 0.2095\n",
      "Fold 4, roc = 0.7692, prc = 0.3851\n",
      "Fold 4 Epoch 110 Batch 0: Train Loss = 0.1861\n",
      "Fold 4 Epoch 110 Batch 5: Train Loss = 0.1178\n",
      "Fold 4 Epoch 110 Batch 10: Train Loss = 0.1105\n",
      "Fold 4 Epoch 110 Batch 15: Train Loss = 0.1729\n",
      "Fold 4 Epoch 110 Batch 20: Train Loss = 0.1435\n",
      "Fold 4, epoch 110: Loss = 0.1600 Valid loss = 0.6751 roc = 0.7434\n",
      "confusion matrix:\n",
      "[[1208   64]\n",
      " [ 147   92]]\n",
      "accuracy = 0.860357403755188\n",
      "precision class 0 = 0.891512930393219\n",
      "precision class 1 = 0.5897436141967773\n",
      "recall class 0 = 0.9496855139732361\n",
      "recall class 1 = 0.38493722677230835\n",
      "AUC of ROC = 0.7434442514670667\n",
      "AUC of PRC = 0.38515238230861426\n",
      "min(+P, Se) = 0.475\n",
      "f1_score = 0.46582278385584047\n",
      "Fold 4, roc = 0.7434, prc = 0.3852\n",
      "Fold 4 Epoch 111 Batch 0: Train Loss = 0.1280\n",
      "Fold 4 Epoch 111 Batch 5: Train Loss = 0.1341\n",
      "Fold 4 Epoch 111 Batch 10: Train Loss = 0.1595\n",
      "Fold 4 Epoch 111 Batch 15: Train Loss = 0.1576\n",
      "Fold 4 Epoch 111 Batch 20: Train Loss = 0.2097\n",
      "Fold 4, roc = 0.7468, prc = 0.3885\n",
      "Fold 4 Epoch 112 Batch 0: Train Loss = 0.1655\n",
      "Fold 4 Epoch 112 Batch 5: Train Loss = 0.1423\n",
      "Fold 4 Epoch 112 Batch 10: Train Loss = 0.1852\n",
      "Fold 4 Epoch 112 Batch 15: Train Loss = 0.1391\n",
      "Fold 4 Epoch 112 Batch 20: Train Loss = 0.2006\n",
      "Fold 4, roc = 0.7527, prc = 0.3279\n",
      "Fold 4 Epoch 113 Batch 0: Train Loss = 0.1489\n",
      "Fold 4 Epoch 113 Batch 5: Train Loss = 0.1502\n",
      "Fold 4 Epoch 113 Batch 10: Train Loss = 0.1679\n",
      "Fold 4 Epoch 113 Batch 15: Train Loss = 0.1005\n",
      "Fold 4 Epoch 113 Batch 20: Train Loss = 0.1340\n",
      "Fold 4, roc = 0.7411, prc = 0.3192\n",
      "Fold 4 Epoch 114 Batch 0: Train Loss = 0.1598\n",
      "Fold 4 Epoch 114 Batch 5: Train Loss = 0.1640\n",
      "Fold 4 Epoch 114 Batch 10: Train Loss = 0.1800\n",
      "Fold 4 Epoch 114 Batch 15: Train Loss = 0.1820\n",
      "Fold 4 Epoch 114 Batch 20: Train Loss = 0.1478\n",
      "Fold 4, roc = 0.7383, prc = 0.3379\n",
      "Fold 4 Epoch 115 Batch 0: Train Loss = 0.1368\n",
      "Fold 4 Epoch 115 Batch 5: Train Loss = 0.1917\n",
      "Fold 4 Epoch 115 Batch 10: Train Loss = 0.1942\n",
      "Fold 4 Epoch 115 Batch 15: Train Loss = 0.1205\n",
      "Fold 4 Epoch 115 Batch 20: Train Loss = 0.1429\n",
      "Fold 4, roc = 0.7366, prc = 0.3498\n",
      "Fold 4 Epoch 116 Batch 0: Train Loss = 0.1679\n",
      "Fold 4 Epoch 116 Batch 5: Train Loss = 0.1908\n",
      "Fold 4 Epoch 116 Batch 10: Train Loss = 0.1289\n",
      "Fold 4 Epoch 116 Batch 15: Train Loss = 0.1615\n",
      "Fold 4 Epoch 116 Batch 20: Train Loss = 0.1582\n",
      "Fold 4, roc = 0.7381, prc = 0.3465\n",
      "Fold 4 Epoch 117 Batch 0: Train Loss = 0.1210\n",
      "Fold 4 Epoch 117 Batch 5: Train Loss = 0.1412\n",
      "Fold 4 Epoch 117 Batch 10: Train Loss = 0.1471\n",
      "Fold 4 Epoch 117 Batch 15: Train Loss = 0.1402\n",
      "Fold 4 Epoch 117 Batch 20: Train Loss = 0.1360\n",
      "Fold 4, roc = 0.7257, prc = 0.3017\n",
      "Fold 4 Epoch 118 Batch 0: Train Loss = 0.2011\n",
      "Fold 4 Epoch 118 Batch 5: Train Loss = 0.1502\n",
      "Fold 4 Epoch 118 Batch 10: Train Loss = 0.1651\n",
      "Fold 4 Epoch 118 Batch 15: Train Loss = 0.1954\n",
      "Fold 4 Epoch 118 Batch 20: Train Loss = 0.1879\n",
      "Fold 4, roc = 0.7302, prc = 0.3501\n",
      "Fold 4 Epoch 119 Batch 0: Train Loss = 0.1819\n",
      "Fold 4 Epoch 119 Batch 5: Train Loss = 0.1726\n",
      "Fold 4 Epoch 119 Batch 10: Train Loss = 0.1259\n",
      "Fold 4 Epoch 119 Batch 15: Train Loss = 0.1484\n",
      "Fold 4 Epoch 119 Batch 20: Train Loss = 0.1647\n",
      "Fold 4, roc = 0.7247, prc = 0.3473\n",
      "Fold 4 Epoch 120 Batch 0: Train Loss = 0.1762\n",
      "Fold 4 Epoch 120 Batch 5: Train Loss = 0.1674\n",
      "Fold 4 Epoch 120 Batch 10: Train Loss = 0.1179\n",
      "Fold 4 Epoch 120 Batch 15: Train Loss = 0.1994\n",
      "Fold 4 Epoch 120 Batch 20: Train Loss = 0.1697\n",
      "Fold 4, epoch 120: Loss = 0.1599 Valid loss = 0.7407 roc = 0.7370\n",
      "confusion matrix:\n",
      "[[1166  106]\n",
      " [ 142   97]]\n",
      "accuracy = 0.8358702659606934\n",
      "precision class 0 = 0.891437292098999\n",
      "precision class 1 = 0.47783252596855164\n",
      "recall class 0 = 0.9166666865348816\n",
      "recall class 1 = 0.40585774183273315\n",
      "AUC of ROC = 0.7369970527091393\n",
      "AUC of PRC = 0.33870639133722474\n",
      "min(+P, Se) = 0.4476987447698745\n",
      "f1_score = 0.43891404844070464\n",
      "Fold 4, roc = 0.7370, prc = 0.3387\n",
      "Fold 4 Epoch 121 Batch 0: Train Loss = 0.2271\n",
      "Fold 4 Epoch 121 Batch 5: Train Loss = 0.1951\n",
      "Fold 4 Epoch 121 Batch 10: Train Loss = 0.1455\n",
      "Fold 4 Epoch 121 Batch 15: Train Loss = 0.1249\n",
      "Fold 4 Epoch 121 Batch 20: Train Loss = 0.1521\n",
      "Fold 4, roc = 0.7308, prc = 0.3725\n",
      "Fold 4 Epoch 122 Batch 0: Train Loss = 0.1684\n",
      "Fold 4 Epoch 122 Batch 5: Train Loss = 0.1150\n",
      "Fold 4 Epoch 122 Batch 10: Train Loss = 0.1411\n",
      "Fold 4 Epoch 122 Batch 15: Train Loss = 0.1216\n",
      "Fold 4 Epoch 122 Batch 20: Train Loss = 0.1812\n",
      "Fold 4, roc = 0.7333, prc = 0.3135\n",
      "Fold 4 Epoch 123 Batch 0: Train Loss = 0.1688\n",
      "Fold 4 Epoch 123 Batch 5: Train Loss = 0.2101\n",
      "Fold 4 Epoch 123 Batch 10: Train Loss = 0.1309\n",
      "Fold 4 Epoch 123 Batch 15: Train Loss = 0.1907\n",
      "Fold 4 Epoch 123 Batch 20: Train Loss = 0.1406\n",
      "Fold 4, roc = 0.7139, prc = 0.3175\n",
      "Fold 4 Epoch 124 Batch 0: Train Loss = 0.1261\n",
      "Fold 4 Epoch 124 Batch 5: Train Loss = 0.1571\n",
      "Fold 4 Epoch 124 Batch 10: Train Loss = 0.1670\n",
      "Fold 4 Epoch 124 Batch 15: Train Loss = 0.1997\n",
      "Fold 4 Epoch 124 Batch 20: Train Loss = 0.1799\n",
      "Fold 4, roc = 0.7383, prc = 0.2946\n",
      "Fold 4 Epoch 125 Batch 0: Train Loss = 0.1548\n",
      "Fold 4 Epoch 125 Batch 5: Train Loss = 0.1425\n",
      "Fold 4 Epoch 125 Batch 10: Train Loss = 0.1427\n",
      "Fold 4 Epoch 125 Batch 15: Train Loss = 0.2011\n",
      "Fold 4 Epoch 125 Batch 20: Train Loss = 0.1588\n",
      "Fold 4, roc = 0.7481, prc = 0.3479\n",
      "Fold 4 Epoch 126 Batch 0: Train Loss = 0.1699\n",
      "Fold 4 Epoch 126 Batch 5: Train Loss = 0.1136\n",
      "Fold 4 Epoch 126 Batch 10: Train Loss = 0.1318\n",
      "Fold 4 Epoch 126 Batch 15: Train Loss = 0.1556\n",
      "Fold 4 Epoch 126 Batch 20: Train Loss = 0.1832\n",
      "Fold 4, roc = 0.7499, prc = 0.3904\n",
      "Fold 4 Epoch 127 Batch 0: Train Loss = 0.1282\n",
      "Fold 4 Epoch 127 Batch 5: Train Loss = 0.1392\n",
      "Fold 4 Epoch 127 Batch 10: Train Loss = 0.2032\n",
      "Fold 4 Epoch 127 Batch 15: Train Loss = 0.1566\n",
      "Fold 4 Epoch 127 Batch 20: Train Loss = 0.1783\n",
      "Fold 4, roc = 0.7642, prc = 0.3998\n",
      "Fold 4 Epoch 128 Batch 0: Train Loss = 0.1475\n",
      "Fold 4 Epoch 128 Batch 5: Train Loss = 0.1582\n",
      "Fold 4 Epoch 128 Batch 10: Train Loss = 0.1661\n",
      "Fold 4 Epoch 128 Batch 15: Train Loss = 0.2083\n",
      "Fold 4 Epoch 128 Batch 20: Train Loss = 0.1352\n",
      "Fold 4, roc = 0.7525, prc = 0.3670\n",
      "Fold 4 Epoch 129 Batch 0: Train Loss = 0.1633\n",
      "Fold 4 Epoch 129 Batch 5: Train Loss = 0.1407\n",
      "Fold 4 Epoch 129 Batch 10: Train Loss = 0.1394\n",
      "Fold 4 Epoch 129 Batch 15: Train Loss = 0.1587\n",
      "Fold 4 Epoch 129 Batch 20: Train Loss = 0.1717\n",
      "Fold 4, roc = 0.7546, prc = 0.3446\n",
      "Fold 4 Epoch 130 Batch 0: Train Loss = 0.1210\n",
      "Fold 4 Epoch 130 Batch 5: Train Loss = 0.1382\n",
      "Fold 4 Epoch 130 Batch 10: Train Loss = 0.1619\n",
      "Fold 4 Epoch 130 Batch 15: Train Loss = 0.1704\n",
      "Fold 4 Epoch 130 Batch 20: Train Loss = 0.1954\n",
      "Fold 4, epoch 130: Loss = 0.1632 Valid loss = 0.6612 roc = 0.7375\n",
      "confusion matrix:\n",
      "[[1188   84]\n",
      " [ 147   92]]\n",
      "accuracy = 0.8471211194992065\n",
      "precision class 0 = 0.8898876309394836\n",
      "precision class 1 = 0.5227272510528564\n",
      "recall class 0 = 0.9339622855186462\n",
      "recall class 1 = 0.38493722677230835\n",
      "AUC of ROC = 0.7375463803584117\n",
      "AUC of PRC = 0.3536951425715232\n",
      "min(+P, Se) = 0.4560669456066946\n",
      "f1_score = 0.44337347840411445\n",
      "Fold 4, roc = 0.7375, prc = 0.3537\n",
      "Fold 4 Epoch 131 Batch 0: Train Loss = 0.1404\n",
      "Fold 4 Epoch 131 Batch 5: Train Loss = 0.1418\n",
      "Fold 4 Epoch 131 Batch 10: Train Loss = 0.1683\n",
      "Fold 4 Epoch 131 Batch 15: Train Loss = 0.1475\n",
      "Fold 4 Epoch 131 Batch 20: Train Loss = 0.1543\n",
      "Fold 4, roc = 0.7514, prc = 0.3355\n",
      "Fold 4 Epoch 132 Batch 0: Train Loss = 0.0899\n",
      "Fold 4 Epoch 132 Batch 5: Train Loss = 0.1517\n",
      "Fold 4 Epoch 132 Batch 10: Train Loss = 0.1548\n",
      "Fold 4 Epoch 132 Batch 15: Train Loss = 0.1189\n",
      "Fold 4 Epoch 132 Batch 20: Train Loss = 0.2212\n",
      "Fold 4, roc = 0.7437, prc = 0.3416\n",
      "Fold 4 Epoch 133 Batch 0: Train Loss = 0.1770\n",
      "Fold 4 Epoch 133 Batch 5: Train Loss = 0.1430\n",
      "Fold 4 Epoch 133 Batch 10: Train Loss = 0.1664\n",
      "Fold 4 Epoch 133 Batch 15: Train Loss = 0.1762\n",
      "Fold 4 Epoch 133 Batch 20: Train Loss = 0.1526\n",
      "Fold 4, roc = 0.7307, prc = 0.3679\n",
      "Fold 4 Epoch 134 Batch 0: Train Loss = 0.1820\n",
      "Fold 4 Epoch 134 Batch 5: Train Loss = 0.1564\n",
      "Fold 4 Epoch 134 Batch 10: Train Loss = 0.1356\n",
      "Fold 4 Epoch 134 Batch 15: Train Loss = 0.1837\n",
      "Fold 4 Epoch 134 Batch 20: Train Loss = 0.1563\n",
      "Fold 4, roc = 0.7532, prc = 0.3726\n",
      "Fold 4 Epoch 135 Batch 0: Train Loss = 0.1067\n",
      "Fold 4 Epoch 135 Batch 5: Train Loss = 0.1007\n",
      "Fold 4 Epoch 135 Batch 10: Train Loss = 0.1685\n",
      "Fold 4 Epoch 135 Batch 15: Train Loss = 0.1358\n",
      "Fold 4 Epoch 135 Batch 20: Train Loss = 0.1732\n",
      "Fold 4, roc = 0.7707, prc = 0.3322\n",
      "Fold 4 Epoch 136 Batch 0: Train Loss = 0.1668\n",
      "Fold 4 Epoch 136 Batch 5: Train Loss = 0.1610\n",
      "Fold 4 Epoch 136 Batch 10: Train Loss = 0.1934\n",
      "Fold 4 Epoch 136 Batch 15: Train Loss = 0.1628\n",
      "Fold 4 Epoch 136 Batch 20: Train Loss = 0.2480\n",
      "Fold 4, roc = 0.7536, prc = 0.3580\n",
      "Fold 4 Epoch 137 Batch 0: Train Loss = 0.1413\n",
      "Fold 4 Epoch 137 Batch 5: Train Loss = 0.1369\n",
      "Fold 4 Epoch 137 Batch 10: Train Loss = 0.1708\n",
      "Fold 4 Epoch 137 Batch 15: Train Loss = 0.1198\n",
      "Fold 4 Epoch 137 Batch 20: Train Loss = 0.1592\n",
      "Fold 4, roc = 0.7380, prc = 0.3128\n",
      "Fold 4 Epoch 138 Batch 0: Train Loss = 0.1390\n",
      "Fold 4 Epoch 138 Batch 5: Train Loss = 0.1383\n",
      "Fold 4 Epoch 138 Batch 10: Train Loss = 0.2061\n",
      "Fold 4 Epoch 138 Batch 15: Train Loss = 0.1719\n",
      "Fold 4 Epoch 138 Batch 20: Train Loss = 0.1916\n",
      "Fold 4, roc = 0.7837, prc = 0.3339\n",
      "Fold 4 Epoch 139 Batch 0: Train Loss = 0.1569\n",
      "Fold 4 Epoch 139 Batch 5: Train Loss = 0.1926\n",
      "Fold 4 Epoch 139 Batch 10: Train Loss = 0.1450\n",
      "Fold 4 Epoch 139 Batch 15: Train Loss = 0.1296\n",
      "Fold 4 Epoch 139 Batch 20: Train Loss = 0.1227\n",
      "Fold 4, roc = 0.7557, prc = 0.3216\n",
      "Fold 4 Epoch 140 Batch 0: Train Loss = 0.1931\n",
      "Fold 4 Epoch 140 Batch 5: Train Loss = 0.1705\n",
      "Fold 4 Epoch 140 Batch 10: Train Loss = 0.1700\n",
      "Fold 4 Epoch 140 Batch 15: Train Loss = 0.1489\n",
      "Fold 4 Epoch 140 Batch 20: Train Loss = 0.1957\n",
      "Fold 4, epoch 140: Loss = 0.1659 Valid loss = 0.8798 roc = 0.7474\n",
      "confusion matrix:\n",
      "[[1147  125]\n",
      " [ 142   97]]\n",
      "accuracy = 0.8232958316802979\n",
      "precision class 0 = 0.8898370862007141\n",
      "precision class 1 = 0.4369369447231293\n",
      "recall class 0 = 0.9017295837402344\n",
      "recall class 1 = 0.40585774183273315\n",
      "AUC of ROC = 0.7474309886581932\n",
      "AUC of PRC = 0.3056984863239429\n",
      "min(+P, Se) = 0.4476987447698745\n",
      "f1_score = 0.42082431417331867\n",
      "Fold 4, roc = 0.7474, prc = 0.3057\n",
      "Fold 4 Epoch 141 Batch 0: Train Loss = 0.1395\n",
      "Fold 4 Epoch 141 Batch 5: Train Loss = 0.1181\n",
      "Fold 4 Epoch 141 Batch 10: Train Loss = 0.1794\n",
      "Fold 4 Epoch 141 Batch 15: Train Loss = 0.1497\n",
      "Fold 4 Epoch 141 Batch 20: Train Loss = 0.1689\n",
      "Fold 4, roc = 0.7387, prc = 0.3009\n",
      "Fold 4 Epoch 142 Batch 0: Train Loss = 0.1345\n",
      "Fold 4 Epoch 142 Batch 5: Train Loss = 0.1795\n",
      "Fold 4 Epoch 142 Batch 10: Train Loss = 0.1902\n",
      "Fold 4 Epoch 142 Batch 15: Train Loss = 0.1506\n",
      "Fold 4 Epoch 142 Batch 20: Train Loss = 0.1531\n",
      "Fold 4, roc = 0.7309, prc = 0.2987\n",
      "Fold 4 Epoch 143 Batch 0: Train Loss = 0.1520\n",
      "Fold 4 Epoch 143 Batch 5: Train Loss = 0.1640\n",
      "Fold 4 Epoch 143 Batch 10: Train Loss = 0.1602\n",
      "Fold 4 Epoch 143 Batch 15: Train Loss = 0.1532\n",
      "Fold 4 Epoch 143 Batch 20: Train Loss = 0.2006\n",
      "Fold 4, roc = 0.7730, prc = 0.3773\n",
      "Fold 4 Epoch 144 Batch 0: Train Loss = 0.1568\n",
      "Fold 4 Epoch 144 Batch 5: Train Loss = 0.1676\n",
      "Fold 4 Epoch 144 Batch 10: Train Loss = 0.1726\n",
      "Fold 4 Epoch 144 Batch 15: Train Loss = 0.1503\n",
      "Fold 4 Epoch 144 Batch 20: Train Loss = 0.1690\n",
      "Fold 4, roc = 0.7647, prc = 0.3594\n",
      "Fold 4 Epoch 145 Batch 0: Train Loss = 0.1349\n",
      "Fold 4 Epoch 145 Batch 5: Train Loss = 0.1532\n",
      "Fold 4 Epoch 145 Batch 10: Train Loss = 0.1537\n",
      "Fold 4 Epoch 145 Batch 15: Train Loss = 0.1062\n",
      "Fold 4 Epoch 145 Batch 20: Train Loss = 0.1081\n",
      "Fold 4, roc = 0.7391, prc = 0.3424\n",
      "Fold 4 Epoch 146 Batch 0: Train Loss = 0.1262\n",
      "Fold 4 Epoch 146 Batch 5: Train Loss = 0.1660\n",
      "Fold 4 Epoch 146 Batch 10: Train Loss = 0.1915\n",
      "Fold 4 Epoch 146 Batch 15: Train Loss = 0.1216\n",
      "Fold 4 Epoch 146 Batch 20: Train Loss = 0.1345\n",
      "Fold 4, roc = 0.7556, prc = 0.3528\n",
      "Fold 4 Epoch 147 Batch 0: Train Loss = 0.1284\n",
      "Fold 4 Epoch 147 Batch 5: Train Loss = 0.1434\n",
      "Fold 4 Epoch 147 Batch 10: Train Loss = 0.1562\n",
      "Fold 4 Epoch 147 Batch 15: Train Loss = 0.1122\n",
      "Fold 4 Epoch 147 Batch 20: Train Loss = 0.2302\n",
      "Fold 4, roc = 0.7501, prc = 0.3028\n",
      "Fold 4 Epoch 148 Batch 0: Train Loss = 0.1818\n",
      "Fold 4 Epoch 148 Batch 5: Train Loss = 0.2137\n",
      "Fold 4 Epoch 148 Batch 10: Train Loss = 0.1582\n",
      "Fold 4 Epoch 148 Batch 15: Train Loss = 0.1622\n",
      "Fold 4 Epoch 148 Batch 20: Train Loss = 0.1134\n",
      "Fold 4, roc = 0.7392, prc = 0.3294\n",
      "Fold 4 Epoch 149 Batch 0: Train Loss = 0.1109\n",
      "Fold 4 Epoch 149 Batch 5: Train Loss = 0.1293\n",
      "Fold 4 Epoch 149 Batch 10: Train Loss = 0.1843\n",
      "Fold 4 Epoch 149 Batch 15: Train Loss = 0.1803\n",
      "Fold 4 Epoch 149 Batch 20: Train Loss = 0.2144\n",
      "Fold 4, roc = 0.7358, prc = 0.3064\n",
      "Training data size: 6361, Validation data size: 1502\n",
      "Fold 5 Epoch 0 Batch 0: Train Loss = 0.9071\n",
      "Fold 5 Epoch 0 Batch 5: Train Loss = 0.6921\n",
      "Fold 5 Epoch 0 Batch 10: Train Loss = 0.6160\n",
      "Fold 5 Epoch 0 Batch 15: Train Loss = 0.6266\n",
      "Fold 5 Epoch 0 Batch 20: Train Loss = 0.5384\n",
      "Fold 5, epoch 0: Loss = 0.6495 Valid loss = 0.5994 roc = 0.8717\n",
      "confusion matrix:\n",
      "[[1195   14]\n",
      " [ 196   97]]\n",
      "accuracy = 0.8601863980293274\n",
      "precision class 0 = 0.8590942025184631\n",
      "precision class 1 = 0.8738738894462585\n",
      "recall class 0 = 0.9884201884269714\n",
      "recall class 1 = 0.3310580253601074\n",
      "AUC of ROC = 0.8717186516371807\n",
      "AUC of PRC = 0.6983255065810062\n",
      "min(+P, Se) = 0.6033898305084746\n",
      "f1_score = 0.48019800353501435\n",
      "Fold 5, roc = 0.8717, prc = 0.6983\n",
      "Fold 5 Epoch 1 Batch 0: Train Loss = 0.5181\n",
      "Fold 5 Epoch 1 Batch 5: Train Loss = 0.5273\n",
      "Fold 5 Epoch 1 Batch 10: Train Loss = 0.4940\n",
      "Fold 5 Epoch 1 Batch 15: Train Loss = 0.5170\n",
      "Fold 5 Epoch 1 Batch 20: Train Loss = 0.5589\n",
      "Fold 5, roc = 0.8881, prc = 0.7129\n",
      "Fold 5 Epoch 2 Batch 0: Train Loss = 0.4730\n",
      "Fold 5 Epoch 2 Batch 5: Train Loss = 0.4511\n",
      "Fold 5 Epoch 2 Batch 10: Train Loss = 0.4439\n",
      "Fold 5 Epoch 2 Batch 15: Train Loss = 0.3838\n",
      "Fold 5 Epoch 2 Batch 20: Train Loss = 0.4520\n",
      "Fold 5, roc = 0.8987, prc = 0.7307\n",
      "Fold 5 Epoch 3 Batch 0: Train Loss = 0.3432\n",
      "Fold 5 Epoch 3 Batch 5: Train Loss = 0.3579\n",
      "Fold 5 Epoch 3 Batch 10: Train Loss = 0.3846\n",
      "Fold 5 Epoch 3 Batch 15: Train Loss = 0.3283\n",
      "Fold 5 Epoch 3 Batch 20: Train Loss = 0.4238\n",
      "Fold 5, roc = 0.9052, prc = 0.7412\n",
      "Fold 5 Epoch 4 Batch 0: Train Loss = 0.3027\n",
      "Fold 5 Epoch 4 Batch 5: Train Loss = 0.3210\n",
      "Fold 5 Epoch 4 Batch 10: Train Loss = 0.3558\n",
      "Fold 5 Epoch 4 Batch 15: Train Loss = 0.3425\n",
      "Fold 5 Epoch 4 Batch 20: Train Loss = 0.3186\n",
      "Fold 5, roc = 0.9069, prc = 0.7459\n",
      "Fold 5 Epoch 5 Batch 0: Train Loss = 0.3202\n",
      "Fold 5 Epoch 5 Batch 5: Train Loss = 0.3167\n",
      "Fold 5 Epoch 5 Batch 10: Train Loss = 0.3153\n",
      "Fold 5 Epoch 5 Batch 15: Train Loss = 0.3419\n",
      "Fold 5 Epoch 5 Batch 20: Train Loss = 0.3387\n",
      "Fold 5, roc = 0.9111, prc = 0.7628\n",
      "Fold 5 Epoch 6 Batch 0: Train Loss = 0.2631\n",
      "Fold 5 Epoch 6 Batch 5: Train Loss = 0.3463\n",
      "Fold 5 Epoch 6 Batch 10: Train Loss = 0.2581\n",
      "Fold 5 Epoch 6 Batch 15: Train Loss = 0.2527\n",
      "Fold 5 Epoch 6 Batch 20: Train Loss = 0.3416\n",
      "Fold 5, roc = 0.9003, prc = 0.7311\n",
      "Fold 5 Epoch 7 Batch 0: Train Loss = 0.3050\n",
      "Fold 5 Epoch 7 Batch 5: Train Loss = 0.3036\n",
      "Fold 5 Epoch 7 Batch 10: Train Loss = 0.2982\n",
      "Fold 5 Epoch 7 Batch 15: Train Loss = 0.2741\n",
      "Fold 5 Epoch 7 Batch 20: Train Loss = 0.2915\n",
      "Fold 5, roc = 0.9060, prc = 0.7546\n",
      "Fold 5 Epoch 8 Batch 0: Train Loss = 0.2628\n",
      "Fold 5 Epoch 8 Batch 5: Train Loss = 0.2886\n",
      "Fold 5 Epoch 8 Batch 10: Train Loss = 0.2745\n",
      "Fold 5 Epoch 8 Batch 15: Train Loss = 0.2494\n",
      "Fold 5 Epoch 8 Batch 20: Train Loss = 0.2716\n",
      "Fold 5, roc = 0.9028, prc = 0.7627\n",
      "Fold 5 Epoch 9 Batch 0: Train Loss = 0.2634\n",
      "Fold 5 Epoch 9 Batch 5: Train Loss = 0.2314\n",
      "Fold 5 Epoch 9 Batch 10: Train Loss = 0.3392\n",
      "Fold 5 Epoch 9 Batch 15: Train Loss = 0.2737\n",
      "Fold 5 Epoch 9 Batch 20: Train Loss = 0.2749\n",
      "------------ Save best model - AUROC: 0.9229 ------------\n",
      "Fold 5, roc = 0.9229, prc = 0.7832\n",
      "Fold 5 Epoch 10 Batch 0: Train Loss = 0.3053\n",
      "Fold 5 Epoch 10 Batch 5: Train Loss = 0.2904\n",
      "Fold 5 Epoch 10 Batch 10: Train Loss = 0.2298\n",
      "Fold 5 Epoch 10 Batch 15: Train Loss = 0.2567\n",
      "Fold 5 Epoch 10 Batch 20: Train Loss = 0.2180\n",
      "Fold 5, epoch 10: Loss = 0.2715 Valid loss = 0.2699 roc = 0.9220\n",
      "confusion matrix:\n",
      "[[1188   21]\n",
      " [ 144  149]]\n",
      "accuracy = 0.8901464939117432\n",
      "precision class 0 = 0.8918918967247009\n",
      "precision class 1 = 0.8764705657958984\n",
      "recall class 0 = 0.9826302528381348\n",
      "recall class 1 = 0.5085324048995972\n",
      "AUC of ROC = 0.9220027834472402\n",
      "AUC of PRC = 0.7851249021054899\n",
      "min(+P, Se) = 0.6928327645051194\n",
      "f1_score = 0.6436284890047254\n",
      "Fold 5, roc = 0.9220, prc = 0.7851\n",
      "Fold 5 Epoch 11 Batch 0: Train Loss = 0.2403\n",
      "Fold 5 Epoch 11 Batch 5: Train Loss = 0.2279\n",
      "Fold 5 Epoch 11 Batch 10: Train Loss = 0.2646\n",
      "Fold 5 Epoch 11 Batch 15: Train Loss = 0.2716\n",
      "Fold 5 Epoch 11 Batch 20: Train Loss = 0.2989\n",
      "Fold 5, roc = 0.9163, prc = 0.7766\n",
      "Fold 5 Epoch 12 Batch 0: Train Loss = 0.3067\n",
      "Fold 5 Epoch 12 Batch 5: Train Loss = 0.2338\n",
      "Fold 5 Epoch 12 Batch 10: Train Loss = 0.2649\n",
      "Fold 5 Epoch 12 Batch 15: Train Loss = 0.2363\n",
      "Fold 5 Epoch 12 Batch 20: Train Loss = 0.2852\n",
      "Fold 5, roc = 0.9073, prc = 0.7479\n",
      "Fold 5 Epoch 13 Batch 0: Train Loss = 0.2230\n",
      "Fold 5 Epoch 13 Batch 5: Train Loss = 0.2830\n",
      "Fold 5 Epoch 13 Batch 10: Train Loss = 0.3010\n",
      "Fold 5 Epoch 13 Batch 15: Train Loss = 0.2971\n",
      "Fold 5 Epoch 13 Batch 20: Train Loss = 0.2639\n",
      "Fold 5, roc = 0.9145, prc = 0.7665\n",
      "Fold 5 Epoch 14 Batch 0: Train Loss = 0.2553\n",
      "Fold 5 Epoch 14 Batch 5: Train Loss = 0.2777\n",
      "Fold 5 Epoch 14 Batch 10: Train Loss = 0.2871\n",
      "Fold 5 Epoch 14 Batch 15: Train Loss = 0.2281\n",
      "Fold 5 Epoch 14 Batch 20: Train Loss = 0.2810\n",
      "Fold 5, roc = 0.9203, prc = 0.7907\n",
      "Fold 5 Epoch 15 Batch 0: Train Loss = 0.2733\n",
      "Fold 5 Epoch 15 Batch 5: Train Loss = 0.3040\n",
      "Fold 5 Epoch 15 Batch 10: Train Loss = 0.2267\n",
      "Fold 5 Epoch 15 Batch 15: Train Loss = 0.3011\n",
      "Fold 5 Epoch 15 Batch 20: Train Loss = 0.2836\n",
      "Fold 5, roc = 0.9212, prc = 0.7893\n",
      "Fold 5 Epoch 16 Batch 0: Train Loss = 0.2076\n",
      "Fold 5 Epoch 16 Batch 5: Train Loss = 0.2346\n",
      "Fold 5 Epoch 16 Batch 10: Train Loss = 0.3076\n",
      "Fold 5 Epoch 16 Batch 15: Train Loss = 0.2655\n",
      "Fold 5 Epoch 16 Batch 20: Train Loss = 0.2741\n",
      "Fold 5, roc = 0.9199, prc = 0.7868\n",
      "Fold 5 Epoch 17 Batch 0: Train Loss = 0.2057\n",
      "Fold 5 Epoch 17 Batch 5: Train Loss = 0.2549\n",
      "Fold 5 Epoch 17 Batch 10: Train Loss = 0.2090\n",
      "Fold 5 Epoch 17 Batch 15: Train Loss = 0.1983\n",
      "Fold 5 Epoch 17 Batch 20: Train Loss = 0.2926\n",
      "Fold 5, roc = 0.9017, prc = 0.7451\n",
      "Fold 5 Epoch 18 Batch 0: Train Loss = 0.2715\n",
      "Fold 5 Epoch 18 Batch 5: Train Loss = 0.2432\n",
      "Fold 5 Epoch 18 Batch 10: Train Loss = 0.2104\n",
      "Fold 5 Epoch 18 Batch 15: Train Loss = 0.1956\n",
      "Fold 5 Epoch 18 Batch 20: Train Loss = 0.2316\n",
      "Fold 5, roc = 0.9179, prc = 0.7723\n",
      "Fold 5 Epoch 19 Batch 0: Train Loss = 0.1736\n",
      "Fold 5 Epoch 19 Batch 5: Train Loss = 0.3541\n",
      "Fold 5 Epoch 19 Batch 10: Train Loss = 0.2678\n",
      "Fold 5 Epoch 19 Batch 15: Train Loss = 0.1872\n",
      "Fold 5 Epoch 19 Batch 20: Train Loss = 0.2631\n",
      "Fold 5, roc = 0.9211, prc = 0.7842\n",
      "Fold 5 Epoch 20 Batch 0: Train Loss = 0.2709\n",
      "Fold 5 Epoch 20 Batch 5: Train Loss = 0.2380\n",
      "Fold 5 Epoch 20 Batch 10: Train Loss = 0.2564\n",
      "Fold 5 Epoch 20 Batch 15: Train Loss = 0.2115\n",
      "Fold 5 Epoch 20 Batch 20: Train Loss = 0.2231\n",
      "Fold 5, epoch 20: Loss = 0.2401 Valid loss = 0.2864 roc = 0.9133\n",
      "confusion matrix:\n",
      "[[1177   32]\n",
      " [ 150  143]]\n",
      "accuracy = 0.878828227519989\n",
      "precision class 0 = 0.8869630694389343\n",
      "precision class 1 = 0.8171428442001343\n",
      "recall class 0 = 0.9735318422317505\n",
      "recall class 1 = 0.4880546033382416\n",
      "AUC of ROC = 0.9132783983604197\n",
      "AUC of PRC = 0.7598381215768706\n",
      "min(+P, Se) = 0.6689419795221843\n",
      "f1_score = 0.6111110902686442\n",
      "Fold 5, roc = 0.9133, prc = 0.7598\n",
      "Fold 5 Epoch 21 Batch 0: Train Loss = 0.2581\n",
      "Fold 5 Epoch 21 Batch 5: Train Loss = 0.2174\n",
      "Fold 5 Epoch 21 Batch 10: Train Loss = 0.2491\n",
      "Fold 5 Epoch 21 Batch 15: Train Loss = 0.2104\n",
      "Fold 5 Epoch 21 Batch 20: Train Loss = 0.2202\n",
      "Fold 5, roc = 0.9107, prc = 0.7416\n",
      "Fold 5 Epoch 22 Batch 0: Train Loss = 0.2284\n",
      "Fold 5 Epoch 22 Batch 5: Train Loss = 0.1920\n",
      "Fold 5 Epoch 22 Batch 10: Train Loss = 0.2613\n",
      "Fold 5 Epoch 22 Batch 15: Train Loss = 0.2533\n",
      "Fold 5 Epoch 22 Batch 20: Train Loss = 0.2437\n",
      "Fold 5, roc = 0.9195, prc = 0.7720\n",
      "Fold 5 Epoch 23 Batch 0: Train Loss = 0.3416\n",
      "Fold 5 Epoch 23 Batch 5: Train Loss = 0.2501\n",
      "Fold 5 Epoch 23 Batch 10: Train Loss = 0.2432\n",
      "Fold 5 Epoch 23 Batch 15: Train Loss = 0.2091\n",
      "Fold 5 Epoch 23 Batch 20: Train Loss = 0.2490\n",
      "Fold 5, roc = 0.9118, prc = 0.7534\n",
      "Fold 5 Epoch 24 Batch 0: Train Loss = 0.1823\n",
      "Fold 5 Epoch 24 Batch 5: Train Loss = 0.2355\n",
      "Fold 5 Epoch 24 Batch 10: Train Loss = 0.2573\n",
      "Fold 5 Epoch 24 Batch 15: Train Loss = 0.2095\n",
      "Fold 5 Epoch 24 Batch 20: Train Loss = 0.2004\n",
      "Fold 5, roc = 0.9196, prc = 0.7800\n",
      "Fold 5 Epoch 25 Batch 0: Train Loss = 0.1806\n",
      "Fold 5 Epoch 25 Batch 5: Train Loss = 0.2116\n",
      "Fold 5 Epoch 25 Batch 10: Train Loss = 0.2240\n",
      "Fold 5 Epoch 25 Batch 15: Train Loss = 0.2522\n",
      "Fold 5 Epoch 25 Batch 20: Train Loss = 0.2467\n",
      "Fold 5, roc = 0.9042, prc = 0.7397\n",
      "Fold 5 Epoch 26 Batch 0: Train Loss = 0.2288\n",
      "Fold 5 Epoch 26 Batch 5: Train Loss = 0.2137\n",
      "Fold 5 Epoch 26 Batch 10: Train Loss = 0.2647\n",
      "Fold 5 Epoch 26 Batch 15: Train Loss = 0.2418\n",
      "Fold 5 Epoch 26 Batch 20: Train Loss = 0.2122\n",
      "Fold 5, roc = 0.9142, prc = 0.7523\n",
      "Fold 5 Epoch 27 Batch 0: Train Loss = 0.2280\n",
      "Fold 5 Epoch 27 Batch 5: Train Loss = 0.2695\n",
      "Fold 5 Epoch 27 Batch 10: Train Loss = 0.2239\n",
      "Fold 5 Epoch 27 Batch 15: Train Loss = 0.2252\n",
      "Fold 5 Epoch 27 Batch 20: Train Loss = 0.2044\n",
      "Fold 5, roc = 0.9035, prc = 0.7334\n",
      "Fold 5 Epoch 28 Batch 0: Train Loss = 0.2458\n",
      "Fold 5 Epoch 28 Batch 5: Train Loss = 0.2087\n",
      "Fold 5 Epoch 28 Batch 10: Train Loss = 0.1779\n",
      "Fold 5 Epoch 28 Batch 15: Train Loss = 0.2302\n",
      "Fold 5 Epoch 28 Batch 20: Train Loss = 0.2003\n",
      "Fold 5, roc = 0.9049, prc = 0.7363\n",
      "Fold 5 Epoch 29 Batch 0: Train Loss = 0.2735\n",
      "Fold 5 Epoch 29 Batch 5: Train Loss = 0.3081\n",
      "Fold 5 Epoch 29 Batch 10: Train Loss = 0.2105\n",
      "Fold 5 Epoch 29 Batch 15: Train Loss = 0.1924\n",
      "Fold 5 Epoch 29 Batch 20: Train Loss = 0.2361\n",
      "Fold 5, roc = 0.8978, prc = 0.7334\n",
      "Fold 5 Epoch 30 Batch 0: Train Loss = 0.2890\n",
      "Fold 5 Epoch 30 Batch 5: Train Loss = 0.2426\n",
      "Fold 5 Epoch 30 Batch 10: Train Loss = 0.2492\n",
      "Fold 5 Epoch 30 Batch 15: Train Loss = 0.2544\n",
      "Fold 5 Epoch 30 Batch 20: Train Loss = 0.2314\n",
      "Fold 5, epoch 30: Loss = 0.2208 Valid loss = 0.3350 roc = 0.8825\n",
      "confusion matrix:\n",
      "[[1124   85]\n",
      " [ 110  183]]\n",
      "accuracy = 0.8701730966567993\n",
      "precision class 0 = 0.9108589887619019\n",
      "precision class 1 = 0.6828358173370361\n",
      "recall class 0 = 0.9296939373016357\n",
      "recall class 1 = 0.6245733499526978\n",
      "AUC of ROC = 0.8824685168404204\n",
      "AUC of PRC = 0.7156776174158667\n",
      "min(+P, Se) = 0.6518771331058021\n",
      "f1_score = 0.6524063997286764\n",
      "Fold 5, roc = 0.8825, prc = 0.7157\n",
      "Fold 5 Epoch 31 Batch 0: Train Loss = 0.1965\n",
      "Fold 5 Epoch 31 Batch 5: Train Loss = 0.2117\n",
      "Fold 5 Epoch 31 Batch 10: Train Loss = 0.1614\n",
      "Fold 5 Epoch 31 Batch 15: Train Loss = 0.1632\n",
      "Fold 5 Epoch 31 Batch 20: Train Loss = 0.2235\n",
      "Fold 5, roc = 0.9090, prc = 0.7433\n",
      "Fold 5 Epoch 32 Batch 0: Train Loss = 0.2088\n",
      "Fold 5 Epoch 32 Batch 5: Train Loss = 0.2432\n",
      "Fold 5 Epoch 32 Batch 10: Train Loss = 0.2315\n",
      "Fold 5 Epoch 32 Batch 15: Train Loss = 0.2058\n",
      "Fold 5 Epoch 32 Batch 20: Train Loss = 0.1624\n",
      "Fold 5, roc = 0.9168, prc = 0.7380\n",
      "Fold 5 Epoch 33 Batch 0: Train Loss = 0.2045\n",
      "Fold 5 Epoch 33 Batch 5: Train Loss = 0.1980\n",
      "Fold 5 Epoch 33 Batch 10: Train Loss = 0.2492\n",
      "Fold 5 Epoch 33 Batch 15: Train Loss = 0.2034\n",
      "Fold 5 Epoch 33 Batch 20: Train Loss = 0.1583\n",
      "Fold 5, roc = 0.9013, prc = 0.7136\n",
      "Fold 5 Epoch 34 Batch 0: Train Loss = 0.2558\n",
      "Fold 5 Epoch 34 Batch 5: Train Loss = 0.2095\n",
      "Fold 5 Epoch 34 Batch 10: Train Loss = 0.1959\n",
      "Fold 5 Epoch 34 Batch 15: Train Loss = 0.2071\n",
      "Fold 5 Epoch 34 Batch 20: Train Loss = 0.1795\n",
      "Fold 5, roc = 0.8479, prc = 0.6554\n",
      "Fold 5 Epoch 35 Batch 0: Train Loss = 0.1738\n",
      "Fold 5 Epoch 35 Batch 5: Train Loss = 0.1987\n",
      "Fold 5 Epoch 35 Batch 10: Train Loss = 0.2791\n",
      "Fold 5 Epoch 35 Batch 15: Train Loss = 0.1761\n",
      "Fold 5 Epoch 35 Batch 20: Train Loss = 0.2006\n",
      "Fold 5, roc = 0.8679, prc = 0.6527\n",
      "Fold 5 Epoch 36 Batch 0: Train Loss = 0.2398\n",
      "Fold 5 Epoch 36 Batch 5: Train Loss = 0.2190\n",
      "Fold 5 Epoch 36 Batch 10: Train Loss = 0.2339\n",
      "Fold 5 Epoch 36 Batch 15: Train Loss = 0.2172\n",
      "Fold 5 Epoch 36 Batch 20: Train Loss = 0.2046\n",
      "Fold 5, roc = 0.8698, prc = 0.6831\n",
      "Fold 5 Epoch 37 Batch 0: Train Loss = 0.2394\n",
      "Fold 5 Epoch 37 Batch 5: Train Loss = 0.2296\n",
      "Fold 5 Epoch 37 Batch 10: Train Loss = 0.2202\n",
      "Fold 5 Epoch 37 Batch 15: Train Loss = 0.2183\n",
      "Fold 5 Epoch 37 Batch 20: Train Loss = 0.2041\n",
      "Fold 5, roc = 0.8683, prc = 0.6813\n",
      "Fold 5 Epoch 38 Batch 0: Train Loss = 0.2270\n",
      "Fold 5 Epoch 38 Batch 5: Train Loss = 0.1771\n",
      "Fold 5 Epoch 38 Batch 10: Train Loss = 0.1820\n",
      "Fold 5 Epoch 38 Batch 15: Train Loss = 0.2721\n",
      "Fold 5 Epoch 38 Batch 20: Train Loss = 0.2212\n",
      "Fold 5, roc = 0.8534, prc = 0.6820\n",
      "Fold 5 Epoch 39 Batch 0: Train Loss = 0.1727\n",
      "Fold 5 Epoch 39 Batch 5: Train Loss = 0.2173\n",
      "Fold 5 Epoch 39 Batch 10: Train Loss = 0.2033\n",
      "Fold 5 Epoch 39 Batch 15: Train Loss = 0.2137\n",
      "Fold 5 Epoch 39 Batch 20: Train Loss = 0.2306\n",
      "Fold 5, roc = 0.8970, prc = 0.7173\n",
      "Fold 5 Epoch 40 Batch 0: Train Loss = 0.2298\n",
      "Fold 5 Epoch 40 Batch 5: Train Loss = 0.2317\n",
      "Fold 5 Epoch 40 Batch 10: Train Loss = 0.2263\n",
      "Fold 5 Epoch 40 Batch 15: Train Loss = 0.1646\n",
      "Fold 5 Epoch 40 Batch 20: Train Loss = 0.1911\n",
      "Fold 5, epoch 40: Loss = 0.2051 Valid loss = 0.3319 roc = 0.8873\n",
      "confusion matrix:\n",
      "[[1139   70]\n",
      " [ 126  167]]\n",
      "accuracy = 0.8695073127746582\n",
      "precision class 0 = 0.9003952741622925\n",
      "precision class 1 = 0.7046413421630859\n",
      "recall class 0 = 0.9421008825302124\n",
      "recall class 1 = 0.5699658989906311\n",
      "AUC of ROC = 0.8872506259933323\n",
      "AUC of PRC = 0.7212261239689715\n",
      "min(+P, Se) = 0.6450511945392492\n",
      "f1_score = 0.6301887230289166\n",
      "Fold 5, roc = 0.8873, prc = 0.7212\n",
      "Fold 5 Epoch 41 Batch 0: Train Loss = 0.2453\n",
      "Fold 5 Epoch 41 Batch 5: Train Loss = 0.1840\n",
      "Fold 5 Epoch 41 Batch 10: Train Loss = 0.2070\n",
      "Fold 5 Epoch 41 Batch 15: Train Loss = 0.1667\n",
      "Fold 5 Epoch 41 Batch 20: Train Loss = 0.1923\n",
      "Fold 5, roc = 0.8718, prc = 0.6875\n",
      "Fold 5 Epoch 42 Batch 0: Train Loss = 0.1733\n",
      "Fold 5 Epoch 42 Batch 5: Train Loss = 0.2298\n",
      "Fold 5 Epoch 42 Batch 10: Train Loss = 0.1946\n",
      "Fold 5 Epoch 42 Batch 15: Train Loss = 0.2281\n",
      "Fold 5 Epoch 42 Batch 20: Train Loss = 0.1830\n",
      "Fold 5, roc = 0.8598, prc = 0.6840\n",
      "Fold 5 Epoch 43 Batch 0: Train Loss = 0.1980\n",
      "Fold 5 Epoch 43 Batch 5: Train Loss = 0.2033\n",
      "Fold 5 Epoch 43 Batch 10: Train Loss = 0.2020\n",
      "Fold 5 Epoch 43 Batch 15: Train Loss = 0.2186\n",
      "Fold 5 Epoch 43 Batch 20: Train Loss = 0.2226\n",
      "Fold 5, roc = 0.9124, prc = 0.7522\n",
      "Fold 5 Epoch 44 Batch 0: Train Loss = 0.2227\n",
      "Fold 5 Epoch 44 Batch 5: Train Loss = 0.2063\n",
      "Fold 5 Epoch 44 Batch 10: Train Loss = 0.1970\n",
      "Fold 5 Epoch 44 Batch 15: Train Loss = 0.3021\n",
      "Fold 5 Epoch 44 Batch 20: Train Loss = 0.2327\n",
      "Fold 5, roc = 0.9045, prc = 0.7250\n",
      "Fold 5 Epoch 45 Batch 0: Train Loss = 0.2062\n",
      "Fold 5 Epoch 45 Batch 5: Train Loss = 0.2151\n",
      "Fold 5 Epoch 45 Batch 10: Train Loss = 0.2257\n",
      "Fold 5 Epoch 45 Batch 15: Train Loss = 0.1823\n",
      "Fold 5 Epoch 45 Batch 20: Train Loss = 0.1734\n",
      "Fold 5, roc = 0.8913, prc = 0.6981\n",
      "Fold 5 Epoch 46 Batch 0: Train Loss = 0.2328\n",
      "Fold 5 Epoch 46 Batch 5: Train Loss = 0.1632\n",
      "Fold 5 Epoch 46 Batch 10: Train Loss = 0.1882\n",
      "Fold 5 Epoch 46 Batch 15: Train Loss = 0.2016\n",
      "Fold 5 Epoch 46 Batch 20: Train Loss = 0.1700\n",
      "Fold 5, roc = 0.8992, prc = 0.7167\n",
      "Fold 5 Epoch 47 Batch 0: Train Loss = 0.1667\n",
      "Fold 5 Epoch 47 Batch 5: Train Loss = 0.1887\n",
      "Fold 5 Epoch 47 Batch 10: Train Loss = 0.1535\n",
      "Fold 5 Epoch 47 Batch 15: Train Loss = 0.1985\n",
      "Fold 5 Epoch 47 Batch 20: Train Loss = 0.1968\n",
      "Fold 5, roc = 0.8932, prc = 0.7027\n",
      "Fold 5 Epoch 48 Batch 0: Train Loss = 0.1441\n",
      "Fold 5 Epoch 48 Batch 5: Train Loss = 0.1774\n",
      "Fold 5 Epoch 48 Batch 10: Train Loss = 0.1799\n",
      "Fold 5 Epoch 48 Batch 15: Train Loss = 0.2070\n",
      "Fold 5 Epoch 48 Batch 20: Train Loss = 0.2060\n",
      "Fold 5, roc = 0.8944, prc = 0.7354\n",
      "Fold 5 Epoch 49 Batch 0: Train Loss = 0.1644\n",
      "Fold 5 Epoch 49 Batch 5: Train Loss = 0.2520\n",
      "Fold 5 Epoch 49 Batch 10: Train Loss = 0.1627\n",
      "Fold 5 Epoch 49 Batch 15: Train Loss = 0.2175\n",
      "Fold 5 Epoch 49 Batch 20: Train Loss = 0.2089\n",
      "Fold 5, roc = 0.8673, prc = 0.7061\n",
      "Fold 5 Epoch 50 Batch 0: Train Loss = 0.1568\n",
      "Fold 5 Epoch 50 Batch 5: Train Loss = 0.1547\n",
      "Fold 5 Epoch 50 Batch 10: Train Loss = 0.2329\n",
      "Fold 5 Epoch 50 Batch 15: Train Loss = 0.2197\n",
      "Fold 5 Epoch 50 Batch 20: Train Loss = 0.2683\n",
      "Fold 5, epoch 50: Loss = 0.1945 Valid loss = 0.4522 roc = 0.8252\n",
      "confusion matrix:\n",
      "[[1150   59]\n",
      " [ 145  148]]\n",
      "accuracy = 0.8641811013221741\n",
      "precision class 0 = 0.8880308866500854\n",
      "precision class 1 = 0.7149758338928223\n",
      "recall class 0 = 0.9511993527412415\n",
      "recall class 1 = 0.5051194429397583\n",
      "AUC of ROC = 0.8252074176328278\n",
      "AUC of PRC = 0.6663728438418914\n",
      "min(+P, Se) = 0.5912162162162162\n",
      "f1_score = 0.5919999885072708\n",
      "Fold 5, roc = 0.8252, prc = 0.6664\n",
      "Fold 5 Epoch 51 Batch 0: Train Loss = 0.1679\n",
      "Fold 5 Epoch 51 Batch 5: Train Loss = 0.2017\n",
      "Fold 5 Epoch 51 Batch 10: Train Loss = 0.2529\n",
      "Fold 5 Epoch 51 Batch 15: Train Loss = 0.2400\n",
      "Fold 5 Epoch 51 Batch 20: Train Loss = 0.2124\n",
      "Fold 5, roc = 0.9208, prc = 0.7797\n",
      "Fold 5 Epoch 52 Batch 0: Train Loss = 0.2234\n",
      "Fold 5 Epoch 52 Batch 5: Train Loss = 0.2071\n",
      "Fold 5 Epoch 52 Batch 10: Train Loss = 0.1869\n",
      "Fold 5 Epoch 52 Batch 15: Train Loss = 0.2243\n",
      "Fold 5 Epoch 52 Batch 20: Train Loss = 0.1615\n",
      "Fold 5, roc = 0.8878, prc = 0.7284\n",
      "Fold 5 Epoch 53 Batch 0: Train Loss = 0.1823\n",
      "Fold 5 Epoch 53 Batch 5: Train Loss = 0.2080\n",
      "Fold 5 Epoch 53 Batch 10: Train Loss = 0.1592\n",
      "Fold 5 Epoch 53 Batch 15: Train Loss = 0.1635\n",
      "Fold 5 Epoch 53 Batch 20: Train Loss = 0.2138\n",
      "Fold 5, roc = 0.8833, prc = 0.7207\n",
      "Fold 5 Epoch 54 Batch 0: Train Loss = 0.2121\n",
      "Fold 5 Epoch 54 Batch 5: Train Loss = 0.1689\n",
      "Fold 5 Epoch 54 Batch 10: Train Loss = 0.1839\n",
      "Fold 5 Epoch 54 Batch 15: Train Loss = 0.1761\n",
      "Fold 5 Epoch 54 Batch 20: Train Loss = 0.2055\n",
      "Fold 5, roc = 0.8994, prc = 0.7462\n",
      "Fold 5 Epoch 55 Batch 0: Train Loss = 0.1762\n",
      "Fold 5 Epoch 55 Batch 5: Train Loss = 0.1772\n",
      "Fold 5 Epoch 55 Batch 10: Train Loss = 0.1351\n",
      "Fold 5 Epoch 55 Batch 15: Train Loss = 0.2248\n",
      "Fold 5 Epoch 55 Batch 20: Train Loss = 0.1881\n",
      "Fold 5, roc = 0.9017, prc = 0.7343\n",
      "Fold 5 Epoch 56 Batch 0: Train Loss = 0.1995\n",
      "Fold 5 Epoch 56 Batch 5: Train Loss = 0.1784\n",
      "Fold 5 Epoch 56 Batch 10: Train Loss = 0.1829\n",
      "Fold 5 Epoch 56 Batch 15: Train Loss = 0.2153\n",
      "Fold 5 Epoch 56 Batch 20: Train Loss = 0.1840\n",
      "Fold 5, roc = 0.8635, prc = 0.6917\n",
      "Fold 5 Epoch 57 Batch 0: Train Loss = 0.1859\n",
      "Fold 5 Epoch 57 Batch 5: Train Loss = 0.2265\n",
      "Fold 5 Epoch 57 Batch 10: Train Loss = 0.2060\n",
      "Fold 5 Epoch 57 Batch 15: Train Loss = 0.1385\n",
      "Fold 5 Epoch 57 Batch 20: Train Loss = 0.1384\n",
      "Fold 5, roc = 0.8887, prc = 0.6975\n",
      "Fold 5 Epoch 58 Batch 0: Train Loss = 0.2098\n",
      "Fold 5 Epoch 58 Batch 5: Train Loss = 0.2042\n",
      "Fold 5 Epoch 58 Batch 10: Train Loss = 0.1784\n",
      "Fold 5 Epoch 58 Batch 15: Train Loss = 0.1438\n",
      "Fold 5 Epoch 58 Batch 20: Train Loss = 0.1518\n",
      "Fold 5, roc = 0.8733, prc = 0.6830\n",
      "Fold 5 Epoch 59 Batch 0: Train Loss = 0.1689\n",
      "Fold 5 Epoch 59 Batch 5: Train Loss = 0.1838\n",
      "Fold 5 Epoch 59 Batch 10: Train Loss = 0.1664\n",
      "Fold 5 Epoch 59 Batch 15: Train Loss = 0.1899\n",
      "Fold 5 Epoch 59 Batch 20: Train Loss = 0.1867\n",
      "Fold 5, roc = 0.8854, prc = 0.7022\n",
      "Fold 5 Epoch 60 Batch 0: Train Loss = 0.1642\n",
      "Fold 5 Epoch 60 Batch 5: Train Loss = 0.1571\n",
      "Fold 5 Epoch 60 Batch 10: Train Loss = 0.2263\n",
      "Fold 5 Epoch 60 Batch 15: Train Loss = 0.1558\n",
      "Fold 5 Epoch 60 Batch 20: Train Loss = 0.2343\n",
      "Fold 5, epoch 60: Loss = 0.1854 Valid loss = 0.3386 roc = 0.8935\n",
      "confusion matrix:\n",
      "[[1159   50]\n",
      " [ 144  149]]\n",
      "accuracy = 0.8708388805389404\n",
      "precision class 0 = 0.889485776424408\n",
      "precision class 1 = 0.7487437129020691\n",
      "recall class 0 = 0.9586434960365295\n",
      "recall class 1 = 0.5085324048995972\n",
      "AUC of ROC = 0.8934978559551938\n",
      "AUC of PRC = 0.725749275077935\n",
      "min(+P, Se) = 0.6382252559726962\n",
      "f1_score = 0.6056910707765591\n",
      "Fold 5, roc = 0.8935, prc = 0.7257\n",
      "Fold 5 Epoch 61 Batch 0: Train Loss = 0.2038\n",
      "Fold 5 Epoch 61 Batch 5: Train Loss = 0.1725\n",
      "Fold 5 Epoch 61 Batch 10: Train Loss = 0.1879\n",
      "Fold 5 Epoch 61 Batch 15: Train Loss = 0.1607\n",
      "Fold 5 Epoch 61 Batch 20: Train Loss = 0.2016\n",
      "Fold 5, roc = 0.8719, prc = 0.6666\n",
      "Fold 5 Epoch 62 Batch 0: Train Loss = 0.1958\n",
      "Fold 5 Epoch 62 Batch 5: Train Loss = 0.1214\n",
      "Fold 5 Epoch 62 Batch 10: Train Loss = 0.1789\n",
      "Fold 5 Epoch 62 Batch 15: Train Loss = 0.1845\n",
      "Fold 5 Epoch 62 Batch 20: Train Loss = 0.2059\n",
      "Fold 5, roc = 0.6018, prc = 0.2952\n",
      "Fold 5 Epoch 63 Batch 0: Train Loss = 0.2005\n",
      "Fold 5 Epoch 63 Batch 5: Train Loss = 0.1764\n",
      "Fold 5 Epoch 63 Batch 10: Train Loss = 0.1644\n",
      "Fold 5 Epoch 63 Batch 15: Train Loss = 0.1433\n",
      "Fold 5 Epoch 63 Batch 20: Train Loss = 0.1958\n",
      "Fold 5, roc = 0.8596, prc = 0.6817\n",
      "Fold 5 Epoch 64 Batch 0: Train Loss = 0.1726\n",
      "Fold 5 Epoch 64 Batch 5: Train Loss = 0.1876\n",
      "Fold 5 Epoch 64 Batch 10: Train Loss = 0.1289\n",
      "Fold 5 Epoch 64 Batch 15: Train Loss = 0.1277\n",
      "Fold 5 Epoch 64 Batch 20: Train Loss = 0.1467\n",
      "Fold 5, roc = 0.8777, prc = 0.6959\n",
      "Fold 5 Epoch 65 Batch 0: Train Loss = 0.1542\n",
      "Fold 5 Epoch 65 Batch 5: Train Loss = 0.2575\n",
      "Fold 5 Epoch 65 Batch 10: Train Loss = 0.1754\n",
      "Fold 5 Epoch 65 Batch 15: Train Loss = 0.1967\n",
      "Fold 5 Epoch 65 Batch 20: Train Loss = 0.1799\n",
      "Fold 5, roc = 0.8875, prc = 0.7128\n",
      "Fold 5 Epoch 66 Batch 0: Train Loss = 0.1529\n",
      "Fold 5 Epoch 66 Batch 5: Train Loss = 0.1720\n",
      "Fold 5 Epoch 66 Batch 10: Train Loss = 0.1717\n",
      "Fold 5 Epoch 66 Batch 15: Train Loss = 0.1619\n",
      "Fold 5 Epoch 66 Batch 20: Train Loss = 0.1850\n",
      "Fold 5, roc = 0.8870, prc = 0.6924\n",
      "Fold 5 Epoch 67 Batch 0: Train Loss = 0.1591\n",
      "Fold 5 Epoch 67 Batch 5: Train Loss = 0.1916\n",
      "Fold 5 Epoch 67 Batch 10: Train Loss = 0.1674\n",
      "Fold 5 Epoch 67 Batch 15: Train Loss = 0.2042\n",
      "Fold 5 Epoch 67 Batch 20: Train Loss = 0.2140\n",
      "Fold 5, roc = 0.8740, prc = 0.6556\n",
      "Fold 5 Epoch 68 Batch 0: Train Loss = 0.2339\n",
      "Fold 5 Epoch 68 Batch 5: Train Loss = 0.2493\n",
      "Fold 5 Epoch 68 Batch 10: Train Loss = 0.1568\n",
      "Fold 5 Epoch 68 Batch 15: Train Loss = 0.1572\n",
      "Fold 5 Epoch 68 Batch 20: Train Loss = 0.2025\n",
      "Fold 5, roc = 0.8675, prc = 0.6922\n",
      "Fold 5 Epoch 69 Batch 0: Train Loss = 0.1642\n",
      "Fold 5 Epoch 69 Batch 5: Train Loss = 0.1540\n",
      "Fold 5 Epoch 69 Batch 10: Train Loss = 0.1560\n",
      "Fold 5 Epoch 69 Batch 15: Train Loss = 0.1787\n",
      "Fold 5 Epoch 69 Batch 20: Train Loss = 0.1395\n",
      "Fold 5, roc = 0.8430, prc = 0.5511\n",
      "Fold 5 Epoch 70 Batch 0: Train Loss = 0.1494\n",
      "Fold 5 Epoch 70 Batch 5: Train Loss = 0.1831\n",
      "Fold 5 Epoch 70 Batch 10: Train Loss = 0.1693\n",
      "Fold 5 Epoch 70 Batch 15: Train Loss = 0.1394\n",
      "Fold 5 Epoch 70 Batch 20: Train Loss = 0.2138\n",
      "Fold 5, epoch 70: Loss = 0.1711 Valid loss = 0.6733 roc = 0.8427\n",
      "confusion matrix:\n",
      "[[1094  115]\n",
      " [ 120  173]]\n",
      "accuracy = 0.8435419201850891\n",
      "precision class 0 = 0.9011532068252563\n",
      "precision class 1 = 0.6006944179534912\n",
      "recall class 0 = 0.9048800468444824\n",
      "recall class 1 = 0.5904436707496643\n",
      "AUC of ROC = 0.8427211160889461\n",
      "AUC of PRC = 0.5630297812411762\n",
      "min(+P, Se) = 0.5938566552901023\n",
      "f1_score = 0.5955249659919297\n",
      "Fold 5, roc = 0.8427, prc = 0.5630\n",
      "Fold 5 Epoch 71 Batch 0: Train Loss = 0.1499\n",
      "Fold 5 Epoch 71 Batch 5: Train Loss = 0.1938\n",
      "Fold 5 Epoch 71 Batch 10: Train Loss = 0.1667\n",
      "Fold 5 Epoch 71 Batch 15: Train Loss = 0.2399\n",
      "Fold 5 Epoch 71 Batch 20: Train Loss = 0.1534\n",
      "Fold 5, roc = 0.8801, prc = 0.6834\n",
      "Fold 5 Epoch 72 Batch 0: Train Loss = 0.1963\n",
      "Fold 5 Epoch 72 Batch 5: Train Loss = 0.1508\n",
      "Fold 5 Epoch 72 Batch 10: Train Loss = 0.2019\n",
      "Fold 5 Epoch 72 Batch 15: Train Loss = 0.2014\n",
      "Fold 5 Epoch 72 Batch 20: Train Loss = 0.2793\n",
      "Fold 5, roc = 0.8474, prc = 0.6508\n",
      "Fold 5 Epoch 73 Batch 0: Train Loss = 0.2132\n",
      "Fold 5 Epoch 73 Batch 5: Train Loss = 0.1986\n",
      "Fold 5 Epoch 73 Batch 10: Train Loss = 0.1729\n",
      "Fold 5 Epoch 73 Batch 15: Train Loss = 0.1648\n",
      "Fold 5 Epoch 73 Batch 20: Train Loss = 0.1904\n",
      "Fold 5, roc = 0.8611, prc = 0.7043\n",
      "Fold 5 Epoch 74 Batch 0: Train Loss = 0.1460\n",
      "Fold 5 Epoch 74 Batch 5: Train Loss = 0.2171\n",
      "Fold 5 Epoch 74 Batch 10: Train Loss = 0.2221\n",
      "Fold 5 Epoch 74 Batch 15: Train Loss = 0.1753\n",
      "Fold 5 Epoch 74 Batch 20: Train Loss = 0.1481\n",
      "Fold 5, roc = 0.8843, prc = 0.7150\n",
      "Fold 5 Epoch 75 Batch 0: Train Loss = 0.1809\n",
      "Fold 5 Epoch 75 Batch 5: Train Loss = 0.1195\n",
      "Fold 5 Epoch 75 Batch 10: Train Loss = 0.1832\n",
      "Fold 5 Epoch 75 Batch 15: Train Loss = 0.1259\n",
      "Fold 5 Epoch 75 Batch 20: Train Loss = 0.1912\n",
      "Fold 5, roc = 0.8266, prc = 0.5673\n",
      "Fold 5 Epoch 76 Batch 0: Train Loss = 0.1859\n",
      "Fold 5 Epoch 76 Batch 5: Train Loss = 0.1979\n",
      "Fold 5 Epoch 76 Batch 10: Train Loss = 0.2034\n",
      "Fold 5 Epoch 76 Batch 15: Train Loss = 0.2133\n",
      "Fold 5 Epoch 76 Batch 20: Train Loss = 0.1342\n",
      "Fold 5, roc = 0.8359, prc = 0.6716\n",
      "Fold 5 Epoch 77 Batch 0: Train Loss = 0.1383\n",
      "Fold 5 Epoch 77 Batch 5: Train Loss = 0.1556\n",
      "Fold 5 Epoch 77 Batch 10: Train Loss = 0.2090\n",
      "Fold 5 Epoch 77 Batch 15: Train Loss = 0.1404\n",
      "Fold 5 Epoch 77 Batch 20: Train Loss = 0.2051\n",
      "Fold 5, roc = 0.8355, prc = 0.6578\n",
      "Fold 5 Epoch 78 Batch 0: Train Loss = 0.2413\n",
      "Fold 5 Epoch 78 Batch 5: Train Loss = 0.1699\n",
      "Fold 5 Epoch 78 Batch 10: Train Loss = 0.1358\n",
      "Fold 5 Epoch 78 Batch 15: Train Loss = 0.1403\n",
      "Fold 5 Epoch 78 Batch 20: Train Loss = 0.1520\n",
      "Fold 5, roc = 0.8469, prc = 0.6728\n",
      "Fold 5 Epoch 79 Batch 0: Train Loss = 0.1522\n",
      "Fold 5 Epoch 79 Batch 5: Train Loss = 0.1641\n",
      "Fold 5 Epoch 79 Batch 10: Train Loss = 0.2366\n",
      "Fold 5 Epoch 79 Batch 15: Train Loss = 0.1882\n",
      "Fold 5 Epoch 79 Batch 20: Train Loss = 0.1477\n",
      "Fold 5, roc = 0.8485, prc = 0.6882\n",
      "Fold 5 Epoch 80 Batch 0: Train Loss = 0.1281\n",
      "Fold 5 Epoch 80 Batch 5: Train Loss = 0.2077\n",
      "Fold 5 Epoch 80 Batch 10: Train Loss = 0.1801\n",
      "Fold 5 Epoch 80 Batch 15: Train Loss = 0.1851\n",
      "Fold 5 Epoch 80 Batch 20: Train Loss = 0.2045\n",
      "Fold 5, epoch 80: Loss = 0.1681 Valid loss = 0.4723 roc = 0.8559\n",
      "confusion matrix:\n",
      "[[1106  103]\n",
      " [ 110  183]]\n",
      "accuracy = 0.8581891059875488\n",
      "precision class 0 = 0.9095394611358643\n",
      "precision class 1 = 0.6398601531982422\n",
      "recall class 0 = 0.9148056507110596\n",
      "recall class 1 = 0.6245733499526978\n",
      "AUC of ROC = 0.855941078995136\n",
      "AUC of PRC = 0.6874384788690464\n",
      "min(+P, Se) = 0.6348122866894198\n",
      "f1_score = 0.6321243440455818\n",
      "Fold 5, roc = 0.8559, prc = 0.6874\n",
      "Fold 5 Epoch 81 Batch 0: Train Loss = 0.1681\n",
      "Fold 5 Epoch 81 Batch 5: Train Loss = 0.1834\n",
      "Fold 5 Epoch 81 Batch 10: Train Loss = 0.1363\n",
      "Fold 5 Epoch 81 Batch 15: Train Loss = 0.1348\n",
      "Fold 5 Epoch 81 Batch 20: Train Loss = 0.2516\n",
      "Fold 5, roc = 0.8480, prc = 0.6907\n",
      "Fold 5 Epoch 82 Batch 0: Train Loss = 0.2083\n",
      "Fold 5 Epoch 82 Batch 5: Train Loss = 0.1589\n",
      "Fold 5 Epoch 82 Batch 10: Train Loss = 0.1606\n",
      "Fold 5 Epoch 82 Batch 15: Train Loss = 0.1690\n",
      "Fold 5 Epoch 82 Batch 20: Train Loss = 0.1168\n",
      "Fold 5, roc = 0.8364, prc = 0.6714\n",
      "Fold 5 Epoch 83 Batch 0: Train Loss = 0.1627\n",
      "Fold 5 Epoch 83 Batch 5: Train Loss = 0.1605\n",
      "Fold 5 Epoch 83 Batch 10: Train Loss = 0.1744\n",
      "Fold 5 Epoch 83 Batch 15: Train Loss = 0.1735\n",
      "Fold 5 Epoch 83 Batch 20: Train Loss = 0.1608\n",
      "Fold 5, roc = 0.8415, prc = 0.6775\n",
      "Fold 5 Epoch 84 Batch 0: Train Loss = 0.1831\n",
      "Fold 5 Epoch 84 Batch 5: Train Loss = 0.2284\n",
      "Fold 5 Epoch 84 Batch 10: Train Loss = 0.1768\n",
      "Fold 5 Epoch 84 Batch 15: Train Loss = 0.1699\n",
      "Fold 5 Epoch 84 Batch 20: Train Loss = 0.2261\n",
      "Fold 5, roc = 0.8470, prc = 0.6891\n",
      "Fold 5 Epoch 85 Batch 0: Train Loss = 0.1455\n",
      "Fold 5 Epoch 85 Batch 5: Train Loss = 0.1598\n",
      "Fold 5 Epoch 85 Batch 10: Train Loss = 0.1535\n",
      "Fold 5 Epoch 85 Batch 15: Train Loss = 0.2382\n",
      "Fold 5 Epoch 85 Batch 20: Train Loss = 0.1638\n",
      "Fold 5, roc = 0.8436, prc = 0.6761\n",
      "Fold 5 Epoch 86 Batch 0: Train Loss = 0.1735\n",
      "Fold 5 Epoch 86 Batch 5: Train Loss = 0.1332\n",
      "Fold 5 Epoch 86 Batch 10: Train Loss = 0.1768\n",
      "Fold 5 Epoch 86 Batch 15: Train Loss = 0.1685\n",
      "Fold 5 Epoch 86 Batch 20: Train Loss = 0.1523\n",
      "Fold 5, roc = 0.8432, prc = 0.6730\n",
      "Fold 5 Epoch 87 Batch 0: Train Loss = 0.1203\n",
      "Fold 5 Epoch 87 Batch 5: Train Loss = 0.1575\n",
      "Fold 5 Epoch 87 Batch 10: Train Loss = 0.1683\n",
      "Fold 5 Epoch 87 Batch 15: Train Loss = 0.1551\n",
      "Fold 5 Epoch 87 Batch 20: Train Loss = 0.1649\n",
      "Fold 5, roc = 0.8309, prc = 0.6537\n",
      "Fold 5 Epoch 88 Batch 0: Train Loss = 0.1378\n",
      "Fold 5 Epoch 88 Batch 5: Train Loss = 0.1377\n",
      "Fold 5 Epoch 88 Batch 10: Train Loss = 0.1487\n",
      "Fold 5 Epoch 88 Batch 15: Train Loss = 0.2171\n",
      "Fold 5 Epoch 88 Batch 20: Train Loss = 0.1571\n",
      "Fold 5, roc = 0.8334, prc = 0.6611\n",
      "Fold 5 Epoch 89 Batch 0: Train Loss = 0.2009\n",
      "Fold 5 Epoch 89 Batch 5: Train Loss = 0.1739\n",
      "Fold 5 Epoch 89 Batch 10: Train Loss = 0.1630\n",
      "Fold 5 Epoch 89 Batch 15: Train Loss = 0.1563\n",
      "Fold 5 Epoch 89 Batch 20: Train Loss = 0.2041\n",
      "Fold 5, roc = 0.8292, prc = 0.6432\n",
      "Fold 5 Epoch 90 Batch 0: Train Loss = 0.1828\n",
      "Fold 5 Epoch 90 Batch 5: Train Loss = 0.1409\n",
      "Fold 5 Epoch 90 Batch 10: Train Loss = 0.1541\n",
      "Fold 5 Epoch 90 Batch 15: Train Loss = 0.1401\n",
      "Fold 5 Epoch 90 Batch 20: Train Loss = 0.1787\n",
      "Fold 5, epoch 90: Loss = 0.1591 Valid loss = 0.5186 roc = 0.8306\n",
      "confusion matrix:\n",
      "[[1132   77]\n",
      " [ 147  146]]\n",
      "accuracy = 0.8508654832839966\n",
      "precision class 0 = 0.8850664496421814\n",
      "precision class 1 = 0.6547085046768188\n",
      "recall class 0 = 0.9363110065460205\n",
      "recall class 1 = 0.49829351902008057\n",
      "AUC of ROC = 0.8306359866417116\n",
      "AUC of PRC = 0.6524384521078981\n",
      "min(+P, Se) = 0.590443686006826\n",
      "f1_score = 0.5658914694386485\n",
      "Fold 5, roc = 0.8306, prc = 0.6524\n",
      "Fold 5 Epoch 91 Batch 0: Train Loss = 0.1566\n",
      "Fold 5 Epoch 91 Batch 5: Train Loss = 0.1710\n",
      "Fold 5 Epoch 91 Batch 10: Train Loss = 0.1339\n",
      "Fold 5 Epoch 91 Batch 15: Train Loss = 0.1589\n",
      "Fold 5 Epoch 91 Batch 20: Train Loss = 0.1514\n",
      "Fold 5, roc = 0.8476, prc = 0.6739\n",
      "Fold 5 Epoch 92 Batch 0: Train Loss = 0.1675\n",
      "Fold 5 Epoch 92 Batch 5: Train Loss = 0.1809\n",
      "Fold 5 Epoch 92 Batch 10: Train Loss = 0.1459\n",
      "Fold 5 Epoch 92 Batch 15: Train Loss = 0.1388\n",
      "Fold 5 Epoch 92 Batch 20: Train Loss = 0.2021\n",
      "Fold 5, roc = 0.8437, prc = 0.6780\n",
      "Fold 5 Epoch 93 Batch 0: Train Loss = 0.1420\n",
      "Fold 5 Epoch 93 Batch 5: Train Loss = 0.1260\n",
      "Fold 5 Epoch 93 Batch 10: Train Loss = 0.1632\n",
      "Fold 5 Epoch 93 Batch 15: Train Loss = 0.1577\n",
      "Fold 5 Epoch 93 Batch 20: Train Loss = 0.1209\n",
      "Fold 5, roc = 0.8486, prc = 0.6905\n",
      "Fold 5 Epoch 94 Batch 0: Train Loss = 0.2070\n",
      "Fold 5 Epoch 94 Batch 5: Train Loss = 0.1691\n",
      "Fold 5 Epoch 94 Batch 10: Train Loss = 0.2221\n",
      "Fold 5 Epoch 94 Batch 15: Train Loss = 0.1620\n",
      "Fold 5 Epoch 94 Batch 20: Train Loss = 0.1377\n",
      "Fold 5, roc = 0.8365, prc = 0.6754\n",
      "Fold 5 Epoch 95 Batch 0: Train Loss = 0.1216\n",
      "Fold 5 Epoch 95 Batch 5: Train Loss = 0.1291\n",
      "Fold 5 Epoch 95 Batch 10: Train Loss = 0.2470\n",
      "Fold 5 Epoch 95 Batch 15: Train Loss = 0.1515\n",
      "Fold 5 Epoch 95 Batch 20: Train Loss = 0.1336\n",
      "Fold 5, roc = 0.8515, prc = 0.6534\n",
      "Fold 5 Epoch 96 Batch 0: Train Loss = 0.1324\n",
      "Fold 5 Epoch 96 Batch 5: Train Loss = 0.2001\n",
      "Fold 5 Epoch 96 Batch 10: Train Loss = 0.1744\n",
      "Fold 5 Epoch 96 Batch 15: Train Loss = 0.1661\n",
      "Fold 5 Epoch 96 Batch 20: Train Loss = 0.1294\n",
      "Fold 5, roc = 0.8548, prc = 0.6535\n",
      "Fold 5 Epoch 97 Batch 0: Train Loss = 0.1561\n",
      "Fold 5 Epoch 97 Batch 5: Train Loss = 0.1578\n",
      "Fold 5 Epoch 97 Batch 10: Train Loss = 0.1977\n",
      "Fold 5 Epoch 97 Batch 15: Train Loss = 0.1682\n",
      "Fold 5 Epoch 97 Batch 20: Train Loss = 0.1427\n",
      "Fold 5, roc = 0.8373, prc = 0.6527\n",
      "Fold 5 Epoch 98 Batch 0: Train Loss = 0.1124\n",
      "Fold 5 Epoch 98 Batch 5: Train Loss = 0.1207\n",
      "Fold 5 Epoch 98 Batch 10: Train Loss = 0.1556\n",
      "Fold 5 Epoch 98 Batch 15: Train Loss = 0.2474\n",
      "Fold 5 Epoch 98 Batch 20: Train Loss = 0.1339\n",
      "Fold 5, roc = 0.8328, prc = 0.6371\n",
      "Fold 5 Epoch 99 Batch 0: Train Loss = 0.1362\n",
      "Fold 5 Epoch 99 Batch 5: Train Loss = 0.1375\n",
      "Fold 5 Epoch 99 Batch 10: Train Loss = 0.1712\n",
      "Fold 5 Epoch 99 Batch 15: Train Loss = 0.1583\n",
      "Fold 5 Epoch 99 Batch 20: Train Loss = 0.2239\n",
      "Fold 5, roc = 0.8421, prc = 0.6304\n",
      "Fold 5 Epoch 100 Batch 0: Train Loss = 0.1668\n",
      "Fold 5 Epoch 100 Batch 5: Train Loss = 0.1387\n",
      "Fold 5 Epoch 100 Batch 10: Train Loss = 0.1611\n",
      "Fold 5 Epoch 100 Batch 15: Train Loss = 0.1245\n",
      "Fold 5 Epoch 100 Batch 20: Train Loss = 0.1548\n",
      "Fold 5, epoch 100: Loss = 0.1553 Valid loss = 0.5305 roc = 0.8289\n",
      "confusion matrix:\n",
      "[[1119   90]\n",
      " [ 137  156]]\n",
      "accuracy = 0.848868191242218\n",
      "precision class 0 = 0.8909235596656799\n",
      "precision class 1 = 0.6341463327407837\n",
      "recall class 0 = 0.92555832862854\n",
      "recall class 1 = 0.532423198223114\n",
      "AUC of ROC = 0.8288546933267841\n",
      "AUC of PRC = 0.6271524474926724\n",
      "min(+P, Se) = 0.5925925925925926\n",
      "f1_score = 0.5788497417576092\n",
      "Fold 5, roc = 0.8289, prc = 0.6272\n",
      "Fold 5 Epoch 101 Batch 0: Train Loss = 0.1541\n",
      "Fold 5 Epoch 101 Batch 5: Train Loss = 0.1331\n",
      "Fold 5 Epoch 101 Batch 10: Train Loss = 0.1418\n",
      "Fold 5 Epoch 101 Batch 15: Train Loss = 0.1214\n",
      "Fold 5 Epoch 101 Batch 20: Train Loss = 0.1545\n",
      "Fold 5, roc = 0.7827, prc = 0.5873\n",
      "Fold 5 Epoch 102 Batch 0: Train Loss = 0.2086\n",
      "Fold 5 Epoch 102 Batch 5: Train Loss = 0.1721\n",
      "Fold 5 Epoch 102 Batch 10: Train Loss = 0.1440\n",
      "Fold 5 Epoch 102 Batch 15: Train Loss = 0.1908\n",
      "Fold 5 Epoch 102 Batch 20: Train Loss = 0.1672\n",
      "Fold 5, roc = 0.8177, prc = 0.6023\n",
      "Fold 5 Epoch 103 Batch 0: Train Loss = 0.1346\n",
      "Fold 5 Epoch 103 Batch 5: Train Loss = 0.1422\n",
      "Fold 5 Epoch 103 Batch 10: Train Loss = 0.1385\n",
      "Fold 5 Epoch 103 Batch 15: Train Loss = 0.1240\n",
      "Fold 5 Epoch 103 Batch 20: Train Loss = 0.2145\n",
      "Fold 5, roc = 0.8195, prc = 0.6224\n",
      "Fold 5 Epoch 104 Batch 0: Train Loss = 0.1515\n",
      "Fold 5 Epoch 104 Batch 5: Train Loss = 0.1566\n",
      "Fold 5 Epoch 104 Batch 10: Train Loss = 0.1647\n",
      "Fold 5 Epoch 104 Batch 15: Train Loss = 0.1987\n",
      "Fold 5 Epoch 104 Batch 20: Train Loss = 0.1369\n",
      "Fold 5, roc = 0.8209, prc = 0.6136\n",
      "Fold 5 Epoch 105 Batch 0: Train Loss = 0.1680\n",
      "Fold 5 Epoch 105 Batch 5: Train Loss = 0.1544\n",
      "Fold 5 Epoch 105 Batch 10: Train Loss = 0.1870\n",
      "Fold 5 Epoch 105 Batch 15: Train Loss = 0.1234\n",
      "Fold 5 Epoch 105 Batch 20: Train Loss = 0.1098\n",
      "Fold 5, roc = 0.8049, prc = 0.5805\n",
      "Fold 5 Epoch 106 Batch 0: Train Loss = 0.1293\n",
      "Fold 5 Epoch 106 Batch 5: Train Loss = 0.1232\n",
      "Fold 5 Epoch 106 Batch 10: Train Loss = 0.1543\n",
      "Fold 5 Epoch 106 Batch 15: Train Loss = 0.1224\n",
      "Fold 5 Epoch 106 Batch 20: Train Loss = 0.1343\n",
      "Fold 5, roc = 0.7995, prc = 0.5998\n",
      "Fold 5 Epoch 107 Batch 0: Train Loss = 0.1326\n",
      "Fold 5 Epoch 107 Batch 5: Train Loss = 0.1360\n",
      "Fold 5 Epoch 107 Batch 10: Train Loss = 0.1415\n",
      "Fold 5 Epoch 107 Batch 15: Train Loss = 0.1389\n",
      "Fold 5 Epoch 107 Batch 20: Train Loss = 0.1921\n",
      "Fold 5, roc = 0.8086, prc = 0.5991\n",
      "Fold 5 Epoch 108 Batch 0: Train Loss = 0.1430\n",
      "Fold 5 Epoch 108 Batch 5: Train Loss = 0.1273\n",
      "Fold 5 Epoch 108 Batch 10: Train Loss = 0.1094\n",
      "Fold 5 Epoch 108 Batch 15: Train Loss = 0.1333\n",
      "Fold 5 Epoch 108 Batch 20: Train Loss = 0.1386\n",
      "Fold 5, roc = 0.8054, prc = 0.6066\n",
      "Fold 5 Epoch 109 Batch 0: Train Loss = 0.0921\n",
      "Fold 5 Epoch 109 Batch 5: Train Loss = 0.1275\n",
      "Fold 5 Epoch 109 Batch 10: Train Loss = 0.1092\n",
      "Fold 5 Epoch 109 Batch 15: Train Loss = 0.1749\n",
      "Fold 5 Epoch 109 Batch 20: Train Loss = 0.1460\n",
      "Fold 5, roc = 0.8457, prc = 0.6317\n",
      "Fold 5 Epoch 110 Batch 0: Train Loss = 0.1621\n",
      "Fold 5 Epoch 110 Batch 5: Train Loss = 0.2068\n",
      "Fold 5 Epoch 110 Batch 10: Train Loss = 0.1620\n",
      "Fold 5 Epoch 110 Batch 15: Train Loss = 0.1288\n",
      "Fold 5 Epoch 110 Batch 20: Train Loss = 0.1703\n",
      "Fold 5, epoch 110: Loss = 0.1569 Valid loss = 0.5795 roc = 0.7970\n",
      "confusion matrix:\n",
      "[[1137   72]\n",
      " [ 164  129]]\n",
      "accuracy = 0.842876136302948\n",
      "precision class 0 = 0.8739431500434875\n",
      "precision class 1 = 0.641791045665741\n",
      "recall class 0 = 0.940446674823761\n",
      "recall class 1 = 0.4402730464935303\n",
      "AUC of ROC = 0.7969861985055203\n",
      "AUC of PRC = 0.6200615103446023\n",
      "min(+P, Se) = 0.5510204081632653\n",
      "f1_score = 0.5222671843012384\n",
      "Fold 5, roc = 0.7970, prc = 0.6201\n",
      "Fold 5 Epoch 111 Batch 0: Train Loss = 0.1670\n",
      "Fold 5 Epoch 111 Batch 5: Train Loss = 0.1221\n",
      "Fold 5 Epoch 111 Batch 10: Train Loss = 0.1438\n",
      "Fold 5 Epoch 111 Batch 15: Train Loss = 0.1840\n",
      "Fold 5 Epoch 111 Batch 20: Train Loss = 0.1722\n",
      "Fold 5, roc = 0.8244, prc = 0.6211\n",
      "Fold 5 Epoch 112 Batch 0: Train Loss = 0.1733\n",
      "Fold 5 Epoch 112 Batch 5: Train Loss = 0.1283\n",
      "Fold 5 Epoch 112 Batch 10: Train Loss = 0.1405\n",
      "Fold 5 Epoch 112 Batch 15: Train Loss = 0.1548\n",
      "Fold 5 Epoch 112 Batch 20: Train Loss = 0.1260\n",
      "Fold 5, roc = 0.8247, prc = 0.6485\n",
      "Fold 5 Epoch 113 Batch 0: Train Loss = 0.1289\n",
      "Fold 5 Epoch 113 Batch 5: Train Loss = 0.1378\n",
      "Fold 5 Epoch 113 Batch 10: Train Loss = 0.1298\n",
      "Fold 5 Epoch 113 Batch 15: Train Loss = 0.1628\n",
      "Fold 5 Epoch 113 Batch 20: Train Loss = 0.1736\n",
      "Fold 5, roc = 0.7991, prc = 0.6258\n",
      "Fold 5 Epoch 114 Batch 0: Train Loss = 0.1769\n",
      "Fold 5 Epoch 114 Batch 5: Train Loss = 0.1663\n",
      "Fold 5 Epoch 114 Batch 10: Train Loss = 0.1514\n",
      "Fold 5 Epoch 114 Batch 15: Train Loss = 0.1438\n",
      "Fold 5 Epoch 114 Batch 20: Train Loss = 0.1873\n",
      "Fold 5, roc = 0.7931, prc = 0.6143\n",
      "Fold 5 Epoch 115 Batch 0: Train Loss = 0.1539\n",
      "Fold 5 Epoch 115 Batch 5: Train Loss = 0.1393\n",
      "Fold 5 Epoch 115 Batch 10: Train Loss = 0.1550\n",
      "Fold 5 Epoch 115 Batch 15: Train Loss = 0.1670\n",
      "Fold 5 Epoch 115 Batch 20: Train Loss = 0.1315\n",
      "Fold 5, roc = 0.8122, prc = 0.6258\n",
      "Fold 5 Epoch 116 Batch 0: Train Loss = 0.1343\n",
      "Fold 5 Epoch 116 Batch 5: Train Loss = 0.1441\n",
      "Fold 5 Epoch 116 Batch 10: Train Loss = 0.1452\n",
      "Fold 5 Epoch 116 Batch 15: Train Loss = 0.1389\n",
      "Fold 5 Epoch 116 Batch 20: Train Loss = 0.1249\n",
      "Fold 5, roc = 0.8170, prc = 0.6310\n",
      "Fold 5 Epoch 117 Batch 0: Train Loss = 0.1327\n",
      "Fold 5 Epoch 117 Batch 5: Train Loss = 0.1751\n",
      "Fold 5 Epoch 117 Batch 10: Train Loss = 0.0963\n",
      "Fold 5 Epoch 117 Batch 15: Train Loss = 0.1572\n",
      "Fold 5 Epoch 117 Batch 20: Train Loss = 0.2148\n",
      "Fold 5, roc = 0.8201, prc = 0.6423\n",
      "Fold 5 Epoch 118 Batch 0: Train Loss = 0.2088\n",
      "Fold 5 Epoch 118 Batch 5: Train Loss = 0.1229\n",
      "Fold 5 Epoch 118 Batch 10: Train Loss = 0.1406\n",
      "Fold 5 Epoch 118 Batch 15: Train Loss = 0.1252\n",
      "Fold 5 Epoch 118 Batch 20: Train Loss = 0.0952\n",
      "Fold 5, roc = 0.8143, prc = 0.6279\n",
      "Fold 5 Epoch 119 Batch 0: Train Loss = 0.1788\n",
      "Fold 5 Epoch 119 Batch 5: Train Loss = 0.1464\n",
      "Fold 5 Epoch 119 Batch 10: Train Loss = 0.1241\n",
      "Fold 5 Epoch 119 Batch 15: Train Loss = 0.1438\n",
      "Fold 5 Epoch 119 Batch 20: Train Loss = 0.1203\n",
      "Fold 5, roc = 0.8184, prc = 0.6228\n",
      "Fold 5 Epoch 120 Batch 0: Train Loss = 0.1200\n",
      "Fold 5 Epoch 120 Batch 5: Train Loss = 0.1298\n",
      "Fold 5 Epoch 120 Batch 10: Train Loss = 0.1507\n",
      "Fold 5 Epoch 120 Batch 15: Train Loss = 0.1583\n",
      "Fold 5 Epoch 120 Batch 20: Train Loss = 0.1112\n",
      "Fold 5, epoch 120: Loss = 0.1483 Valid loss = 0.5830 roc = 0.8063\n",
      "confusion matrix:\n",
      "[[1149   60]\n",
      " [ 165  128]]\n",
      "accuracy = 0.8501997590065002\n",
      "precision class 0 = 0.8744292259216309\n",
      "precision class 1 = 0.6808510422706604\n",
      "recall class 0 = 0.9503722190856934\n",
      "recall class 1 = 0.436860054731369\n",
      "AUC of ROC = 0.8063274022758774\n",
      "AUC of PRC = 0.6274356831413683\n",
      "min(+P, Se) = 0.552901023890785\n",
      "f1_score = 0.5322245297891925\n",
      "Fold 5, roc = 0.8063, prc = 0.6274\n",
      "Fold 5 Epoch 121 Batch 0: Train Loss = 0.1494\n",
      "Fold 5 Epoch 121 Batch 5: Train Loss = 0.1565\n",
      "Fold 5 Epoch 121 Batch 10: Train Loss = 0.1418\n",
      "Fold 5 Epoch 121 Batch 15: Train Loss = 0.1822\n",
      "Fold 5 Epoch 121 Batch 20: Train Loss = 0.1759\n",
      "Fold 5, roc = 0.8244, prc = 0.6262\n",
      "Fold 5 Epoch 122 Batch 0: Train Loss = 0.1907\n",
      "Fold 5 Epoch 122 Batch 5: Train Loss = 0.1192\n",
      "Fold 5 Epoch 122 Batch 10: Train Loss = 0.1210\n",
      "Fold 5 Epoch 122 Batch 15: Train Loss = 0.1477\n",
      "Fold 5 Epoch 122 Batch 20: Train Loss = 0.1682\n",
      "Fold 5, roc = 0.8057, prc = 0.6085\n",
      "Fold 5 Epoch 123 Batch 0: Train Loss = 0.1280\n",
      "Fold 5 Epoch 123 Batch 5: Train Loss = 0.1204\n",
      "Fold 5 Epoch 123 Batch 10: Train Loss = 0.1914\n",
      "Fold 5 Epoch 123 Batch 15: Train Loss = 0.1953\n",
      "Fold 5 Epoch 123 Batch 20: Train Loss = 0.1182\n",
      "Fold 5, roc = 0.8226, prc = 0.6140\n",
      "Fold 5 Epoch 124 Batch 0: Train Loss = 0.1368\n",
      "Fold 5 Epoch 124 Batch 5: Train Loss = 0.1234\n",
      "Fold 5 Epoch 124 Batch 10: Train Loss = 0.1309\n",
      "Fold 5 Epoch 124 Batch 15: Train Loss = 0.1373\n",
      "Fold 5 Epoch 124 Batch 20: Train Loss = 0.1768\n",
      "Fold 5, roc = 0.8198, prc = 0.5944\n",
      "Fold 5 Epoch 125 Batch 0: Train Loss = 0.1313\n",
      "Fold 5 Epoch 125 Batch 5: Train Loss = 0.1875\n",
      "Fold 5 Epoch 125 Batch 10: Train Loss = 0.0989\n",
      "Fold 5 Epoch 125 Batch 15: Train Loss = 0.1215\n",
      "Fold 5 Epoch 125 Batch 20: Train Loss = 0.1892\n",
      "Fold 5, roc = 0.8284, prc = 0.6207\n",
      "Fold 5 Epoch 126 Batch 0: Train Loss = 0.1111\n",
      "Fold 5 Epoch 126 Batch 5: Train Loss = 0.1446\n",
      "Fold 5 Epoch 126 Batch 10: Train Loss = 0.1235\n",
      "Fold 5 Epoch 126 Batch 15: Train Loss = 0.1477\n",
      "Fold 5 Epoch 126 Batch 20: Train Loss = 0.1401\n",
      "Fold 5, roc = 0.8088, prc = 0.6174\n",
      "Fold 5 Epoch 127 Batch 0: Train Loss = 0.1803\n",
      "Fold 5 Epoch 127 Batch 5: Train Loss = 0.2065\n",
      "Fold 5 Epoch 127 Batch 10: Train Loss = 0.1082\n",
      "Fold 5 Epoch 127 Batch 15: Train Loss = 0.1805\n",
      "Fold 5 Epoch 127 Batch 20: Train Loss = 0.1644\n",
      "Fold 5, roc = 0.8148, prc = 0.6145\n",
      "Fold 5 Epoch 128 Batch 0: Train Loss = 0.1272\n",
      "Fold 5 Epoch 128 Batch 5: Train Loss = 0.1329\n",
      "Fold 5 Epoch 128 Batch 10: Train Loss = 0.1336\n",
      "Fold 5 Epoch 128 Batch 15: Train Loss = 0.1477\n",
      "Fold 5 Epoch 128 Batch 20: Train Loss = 0.1302\n",
      "Fold 5, roc = 0.8308, prc = 0.5954\n",
      "Fold 5 Epoch 129 Batch 0: Train Loss = 0.1631\n",
      "Fold 5 Epoch 129 Batch 5: Train Loss = 0.1568\n",
      "Fold 5 Epoch 129 Batch 10: Train Loss = 0.1116\n",
      "Fold 5 Epoch 129 Batch 15: Train Loss = 0.1058\n",
      "Fold 5 Epoch 129 Batch 20: Train Loss = 0.1672\n",
      "Fold 5, roc = 0.8234, prc = 0.6102\n",
      "Fold 5 Epoch 130 Batch 0: Train Loss = 0.1330\n",
      "Fold 5 Epoch 130 Batch 5: Train Loss = 0.1243\n",
      "Fold 5 Epoch 130 Batch 10: Train Loss = 0.1785\n",
      "Fold 5 Epoch 130 Batch 15: Train Loss = 0.1193\n",
      "Fold 5 Epoch 130 Batch 20: Train Loss = 0.2044\n",
      "Fold 5, epoch 130: Loss = 0.1432 Valid loss = 0.5568 roc = 0.8292\n",
      "confusion matrix:\n",
      "[[1118   91]\n",
      " [ 141  152]]\n",
      "accuracy = 0.8455392718315125\n",
      "precision class 0 = 0.888006329536438\n",
      "precision class 1 = 0.6255143880844116\n",
      "recall class 0 = 0.9247311949729919\n",
      "recall class 1 = 0.5187713503837585\n",
      "AUC of ROC = 0.8292400285684443\n",
      "AUC of PRC = 0.6273005823123156\n",
      "min(+P, Se) = 0.5743243243243243\n",
      "f1_score = 0.5671642139457771\n",
      "Fold 5, roc = 0.8292, prc = 0.6273\n",
      "Fold 5 Epoch 131 Batch 0: Train Loss = 0.1728\n",
      "Fold 5 Epoch 131 Batch 5: Train Loss = 0.1528\n",
      "Fold 5 Epoch 131 Batch 10: Train Loss = 0.1832\n",
      "Fold 5 Epoch 131 Batch 15: Train Loss = 0.1975\n",
      "Fold 5 Epoch 131 Batch 20: Train Loss = 0.1805\n",
      "Fold 5, roc = 0.8215, prc = 0.6076\n",
      "Fold 5 Epoch 132 Batch 0: Train Loss = 0.1535\n",
      "Fold 5 Epoch 132 Batch 5: Train Loss = 0.1364\n",
      "Fold 5 Epoch 132 Batch 10: Train Loss = 0.1707\n",
      "Fold 5 Epoch 132 Batch 15: Train Loss = 0.1011\n",
      "Fold 5 Epoch 132 Batch 20: Train Loss = 0.1189\n",
      "Fold 5, roc = 0.8085, prc = 0.5950\n",
      "Fold 5 Epoch 133 Batch 0: Train Loss = 0.1319\n",
      "Fold 5 Epoch 133 Batch 5: Train Loss = 0.1608\n",
      "Fold 5 Epoch 133 Batch 10: Train Loss = 0.1215\n",
      "Fold 5 Epoch 133 Batch 15: Train Loss = 0.1277\n",
      "Fold 5 Epoch 133 Batch 20: Train Loss = 0.1400\n",
      "Fold 5, roc = 0.8337, prc = 0.6146\n",
      "Fold 5 Epoch 134 Batch 0: Train Loss = 0.1467\n",
      "Fold 5 Epoch 134 Batch 5: Train Loss = 0.1465\n",
      "Fold 5 Epoch 134 Batch 10: Train Loss = 0.1299\n",
      "Fold 5 Epoch 134 Batch 15: Train Loss = 0.1439\n",
      "Fold 5 Epoch 134 Batch 20: Train Loss = 0.1750\n",
      "Fold 5, roc = 0.8286, prc = 0.6118\n",
      "Fold 5 Epoch 135 Batch 0: Train Loss = 0.0756\n",
      "Fold 5 Epoch 135 Batch 5: Train Loss = 0.1114\n",
      "Fold 5 Epoch 135 Batch 10: Train Loss = 0.1289\n",
      "Fold 5 Epoch 135 Batch 15: Train Loss = 0.1147\n",
      "Fold 5 Epoch 135 Batch 20: Train Loss = 0.1206\n",
      "Fold 5, roc = 0.8255, prc = 0.6085\n",
      "Fold 5 Epoch 136 Batch 0: Train Loss = 0.1374\n",
      "Fold 5 Epoch 136 Batch 5: Train Loss = 0.1386\n",
      "Fold 5 Epoch 136 Batch 10: Train Loss = 0.1326\n",
      "Fold 5 Epoch 136 Batch 15: Train Loss = 0.1174\n",
      "Fold 5 Epoch 136 Batch 20: Train Loss = 0.1136\n",
      "Fold 5, roc = 0.8039, prc = 0.6068\n",
      "Fold 5 Epoch 137 Batch 0: Train Loss = 0.1148\n",
      "Fold 5 Epoch 137 Batch 5: Train Loss = 0.1505\n",
      "Fold 5 Epoch 137 Batch 10: Train Loss = 0.1388\n",
      "Fold 5 Epoch 137 Batch 15: Train Loss = 0.1150\n",
      "Fold 5 Epoch 137 Batch 20: Train Loss = 0.1439\n",
      "Fold 5, roc = 0.8006, prc = 0.5923\n",
      "Fold 5 Epoch 138 Batch 0: Train Loss = 0.1095\n",
      "Fold 5 Epoch 138 Batch 5: Train Loss = 0.1377\n",
      "Fold 5 Epoch 138 Batch 10: Train Loss = 0.1508\n",
      "Fold 5 Epoch 138 Batch 15: Train Loss = 0.0971\n",
      "Fold 5 Epoch 138 Batch 20: Train Loss = 0.0698\n",
      "Fold 5, roc = 0.8239, prc = 0.5844\n",
      "Fold 5 Epoch 139 Batch 0: Train Loss = 0.1168\n",
      "Fold 5 Epoch 139 Batch 5: Train Loss = 0.1614\n",
      "Fold 5 Epoch 139 Batch 10: Train Loss = 0.1419\n",
      "Fold 5 Epoch 139 Batch 15: Train Loss = 0.1456\n",
      "Fold 5 Epoch 139 Batch 20: Train Loss = 0.1396\n",
      "Fold 5, roc = 0.8153, prc = 0.5697\n",
      "Fold 5 Epoch 140 Batch 0: Train Loss = 0.1552\n",
      "Fold 5 Epoch 140 Batch 5: Train Loss = 0.1582\n",
      "Fold 5 Epoch 140 Batch 10: Train Loss = 0.1285\n",
      "Fold 5 Epoch 140 Batch 15: Train Loss = 0.1173\n",
      "Fold 5 Epoch 140 Batch 20: Train Loss = 0.1556\n",
      "Fold 5, epoch 140: Loss = 0.1353 Valid loss = 0.5925 roc = 0.8244\n",
      "confusion matrix:\n",
      "[[1109  100]\n",
      " [ 145  148]]\n",
      "accuracy = 0.8368841409683228\n",
      "precision class 0 = 0.8843700289726257\n",
      "precision class 1 = 0.5967742204666138\n",
      "recall class 0 = 0.9172869920730591\n",
      "recall class 1 = 0.5051194429397583\n",
      "AUC of ROC = 0.8244000485550633\n",
      "AUC of PRC = 0.5859905008763846\n",
      "min(+P, Se) = 0.552901023890785\n",
      "f1_score = 0.5471349401738673\n",
      "Fold 5, roc = 0.8244, prc = 0.5860\n",
      "Fold 5 Epoch 141 Batch 0: Train Loss = 0.1288\n",
      "Fold 5 Epoch 141 Batch 5: Train Loss = 0.1171\n",
      "Fold 5 Epoch 141 Batch 10: Train Loss = 0.1194\n",
      "Fold 5 Epoch 141 Batch 15: Train Loss = 0.1139\n",
      "Fold 5 Epoch 141 Batch 20: Train Loss = 0.1363\n",
      "Fold 5, roc = 0.7995, prc = 0.5767\n",
      "Fold 5 Epoch 142 Batch 0: Train Loss = 0.1569\n",
      "Fold 5 Epoch 142 Batch 5: Train Loss = 0.1049\n",
      "Fold 5 Epoch 142 Batch 10: Train Loss = 0.1974\n",
      "Fold 5 Epoch 142 Batch 15: Train Loss = 0.1097\n",
      "Fold 5 Epoch 142 Batch 20: Train Loss = 0.1336\n",
      "Fold 5, roc = 0.8008, prc = 0.5550\n",
      "Fold 5 Epoch 143 Batch 0: Train Loss = 0.1494\n",
      "Fold 5 Epoch 143 Batch 5: Train Loss = 0.1292\n",
      "Fold 5 Epoch 143 Batch 10: Train Loss = 0.1332\n",
      "Fold 5 Epoch 143 Batch 15: Train Loss = 0.1263\n",
      "Fold 5 Epoch 143 Batch 20: Train Loss = 0.1126\n",
      "Fold 5, roc = 0.8029, prc = 0.5712\n",
      "Fold 5 Epoch 144 Batch 0: Train Loss = 0.1269\n",
      "Fold 5 Epoch 144 Batch 5: Train Loss = 0.1305\n",
      "Fold 5 Epoch 144 Batch 10: Train Loss = 0.1187\n",
      "Fold 5 Epoch 144 Batch 15: Train Loss = 0.1246\n",
      "Fold 5 Epoch 144 Batch 20: Train Loss = 0.1329\n",
      "Fold 5, roc = 0.8000, prc = 0.5654\n",
      "Fold 5 Epoch 145 Batch 0: Train Loss = 0.1786\n",
      "Fold 5 Epoch 145 Batch 5: Train Loss = 0.1187\n",
      "Fold 5 Epoch 145 Batch 10: Train Loss = 0.1319\n",
      "Fold 5 Epoch 145 Batch 15: Train Loss = 0.1248\n",
      "Fold 5 Epoch 145 Batch 20: Train Loss = 0.1787\n",
      "Fold 5, roc = 0.8040, prc = 0.5656\n",
      "Fold 5 Epoch 146 Batch 0: Train Loss = 0.1339\n",
      "Fold 5 Epoch 146 Batch 5: Train Loss = 0.1362\n",
      "Fold 5 Epoch 146 Batch 10: Train Loss = 0.1146\n",
      "Fold 5 Epoch 146 Batch 15: Train Loss = 0.1152\n",
      "Fold 5 Epoch 146 Batch 20: Train Loss = 0.1281\n",
      "Fold 5, roc = 0.8036, prc = 0.5684\n",
      "Fold 5 Epoch 147 Batch 0: Train Loss = 0.1737\n",
      "Fold 5 Epoch 147 Batch 5: Train Loss = 0.1653\n",
      "Fold 5 Epoch 147 Batch 10: Train Loss = 0.1333\n",
      "Fold 5 Epoch 147 Batch 15: Train Loss = 0.1285\n",
      "Fold 5 Epoch 147 Batch 20: Train Loss = 0.1200\n",
      "Fold 5, roc = 0.7949, prc = 0.5598\n",
      "Fold 5 Epoch 148 Batch 0: Train Loss = 0.1256\n",
      "Fold 5 Epoch 148 Batch 5: Train Loss = 0.1309\n",
      "Fold 5 Epoch 148 Batch 10: Train Loss = 0.1292\n",
      "Fold 5 Epoch 148 Batch 15: Train Loss = 0.0868\n",
      "Fold 5 Epoch 148 Batch 20: Train Loss = 0.1337\n",
      "Fold 5, roc = 0.8087, prc = 0.5666\n",
      "Fold 5 Epoch 149 Batch 0: Train Loss = 0.1135\n",
      "Fold 5 Epoch 149 Batch 5: Train Loss = 0.0951\n",
      "Fold 5 Epoch 149 Batch 10: Train Loss = 0.1571\n",
      "Fold 5 Epoch 149 Batch 15: Train Loss = 0.1754\n",
      "Fold 5 Epoch 149 Batch 20: Train Loss = 0.1338\n",
      "Fold 5, roc = 0.8133, prc = 0.5939\n",
      "auroc 0.8972(0.0261)\n",
      "auprc 0.6946(0.1159)\n",
      "minpse 0.6501(0.0705)\n",
      "f1 0.5357(0.0970)\n"
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    "batch_size = 256\n",
    "\n",
    "fold_count = 0\n",
    "total_train_loss = []\n",
    "total_valid_loss = []\n",
    "global_best = 0\n",
    "\n",
    "global_best = 0\n",
    "auroc = []\n",
    "auprc = []\n",
    "minpse = []\n",
    "history = []\n",
    "acc = []\n",
    "auprc = []\n",
    "minpse = []\n",
    "history = []\n",
    "f1 = []\n",
    "\n",
    "pad_token = np.zeros(33)\n",
    "\n",
    "for train, test in kfold.split(long_x, long_y):\n",
    "    \n",
    "    model = PAIL(device = device, input_dim = input_dim, hidden_dim = hidden_dim, output_dim = output_dim, cluster_num = cluster_num, dropout=dropout, block=block).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    fold_count += 1\n",
    "#     print(train)\n",
    "    \n",
    "    train_x = [long_x[i] for i in train ]\n",
    "    train_y = [long_y[i] for i in train ]\n",
    "    train_x_len = [all_x_len[i] for i in train ]\n",
    "#     print(train_x[0])\n",
    "#     print(train_y[0])\n",
    "    train_x, train_y, train_x_len = get_n2n_data(train_x, train_y, train_x_len)\n",
    "    \n",
    "    test_x = [long_x[i] for i in test ]\n",
    "    test_y = [long_y[i] for i in test ]\n",
    "    test_x_len = [all_x_len[i] for i in test ]\n",
    "    test_x, test_y, test_x_len = get_n2n_data(test_x, test_y, test_x_len)\n",
    "    \n",
    "    print(\"Training data size: %d, Validation data size: %d\" % (len(train_x), len(test_x)))\n",
    "    \n",
    "    ckd_file_name = './model/maple-GCN-noclu-GKernel-3num-new-covid-5-fold-n2n-simiProj-deepk-learnEPS' + str(fold_count)#4114\n",
    "    \n",
    "    fold_train_loss = []\n",
    "    fold_valid_loss = []\n",
    "    best_auroc = 0\n",
    "    best_auprc = 0\n",
    "    best_minpse = 0\n",
    "    best_f1 = 0\n",
    "    \n",
    "    for each_epoch in range(epochs):\n",
    "       \n",
    "        \n",
    "        epoch_loss = []\n",
    "        counter_batch = 0\n",
    "        model.train()  \n",
    "        \n",
    "        for step, (batch_x, batch_y, batch_lens) in enumerate(covid_batch_iter(train_x, train_y, train_x_len, batch_size, shuffle=True)):  \n",
    "            optimizer.zero_grad()\n",
    "            batch_x = torch.tensor(pad_sents(batch_x, pad_token), dtype=torch.float32).to(device)\n",
    "            batch_y = torch.tensor(batch_y, dtype=torch.float32).to(device)\n",
    "            batch_lens = torch.tensor(batch_lens, dtype=torch.float32).to(device).int()\n",
    "\n",
    "            masks = length_to_mask(batch_lens).unsqueeze(-1).float()\n",
    "\n",
    "            opt = model(batch_x, batch_lens)[0]\n",
    "\n",
    "\n",
    "            BCE_Loss = get_loss(opt, batch_y)\n",
    "\n",
    "\n",
    "            model_loss =  BCE_Loss \n",
    "            loss = model_loss\n",
    "\n",
    "            epoch_loss.append(BCE_Loss.cpu().detach().numpy())\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 20)\n",
    "            optimizer.step()\n",
    "            \n",
    "            if step % 5 == 0:\n",
    "                print('Fold %d Epoch %d Batch %d: Train Loss = %.4f'%(fold_count,each_epoch, step, loss.cpu().detach().numpy()))\n",
    "            \n",
    "        epoch_loss = np.mean(epoch_loss)\n",
    "        fold_train_loss.append(epoch_loss)\n",
    "\n",
    "        #Validation\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        y_pred_flatten = []\n",
    "        y_true_flatten = []\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            valid_loss = []\n",
    "            valid_true = []\n",
    "            valid_pred = []\n",
    "            for batch_x, batch_y, batch_lens in covid_batch_iter(test_x, test_y, test_x_len, batch_size):\n",
    "             \n",
    "                batch_x = torch.tensor(pad_sents(batch_x, pad_token), dtype=torch.float32).to(device)\n",
    "                batch_y = torch.tensor(batch_y, dtype=torch.float32).to(device)\n",
    "                batch_lens = torch.tensor(batch_lens, dtype=torch.float32).to(device).int()\n",
    "                masks = length_to_mask(batch_lens).unsqueeze(-1).float()\n",
    "       \n",
    "               \n",
    "                opt= model(batch_x, batch_lens)[0]\n",
    "#                 print(opt)\n",
    "                \n",
    "                BCE_Loss = get_loss(opt, batch_y)\n",
    "#                 REC_Loss = F.mse_loss(recon, batch_x, reduction='mean').to(device)\n",
    "                \n",
    "                valid_loss.append(BCE_Loss.cpu().detach().numpy())\n",
    "\n",
    "    \n",
    "                y_pred += list(opt.cpu().detach().numpy())\n",
    "                y_true += list(batch_y.cpu().numpy())\n",
    "                y_pred_flatten += list(opt.cpu().detach().numpy().flatten())\n",
    "                y_true_flatten += list(batch_y.cpu().numpy().flatten())\n",
    "            \n",
    "\n",
    "            valid_loss = np.mean(valid_loss)\n",
    "            fold_valid_loss.append(valid_loss)\n",
    "            ret = metrics.print_metrics_binary(y_true, y_pred,verbose = 0)\n",
    "            history.append(ret)\n",
    "            #print()\n",
    "\n",
    "            if each_epoch % 10 == 0:\n",
    "                print('Fold %d, epoch %d: Loss = %.4f Valid loss = %.4f roc = %.4f'%(fold_count, each_epoch, fold_train_loss[-1], fold_valid_loss[-1], ret['auroc']))\n",
    "                metrics.print_metrics_binary(y_true, y_pred)\n",
    "                \n",
    "            cur_auroc = ret['auroc']\n",
    "#             cur_prc = ret['auprc']\n",
    "            if cur_auroc > best_auroc:\n",
    "                best_auroc = cur_auroc\n",
    "                best_auprc = ret['auprc']\n",
    "                best_minpse = ret['minpse']\n",
    "                best_f1 = ret['f1_score']\n",
    "                state = {\n",
    "                    'net': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                    'epoch': each_epoch\n",
    "                }\n",
    "                torch.save(state, ckd_file_name+'_'+str(fold_count))\n",
    "                \n",
    "                if cur_auroc > global_best:\n",
    "                    global_best = cur_auroc\n",
    "                    state = {\n",
    "                        'net': model.state_dict(),\n",
    "                        'optimizer': optimizer.state_dict(),\n",
    "                        'epoch': each_epoch\n",
    "                    }\n",
    "                    torch.save(state, ckd_file_name)\n",
    "                    print('------------ Save best model - AUROC: %.4f ------------'%cur_auroc)\n",
    "                    \n",
    "        print('Fold %d, roc = %.4f, prc = %.4f'%(fold_count, ret['auroc'], ret['auprc']))\n",
    "                    \n",
    "    auroc.append(best_auroc)\n",
    "    auprc.append(best_auprc)\n",
    "    minpse.append(best_minpse)\n",
    "    f1.append(best_f1)\n",
    "    total_train_loss.append(fold_train_loss)\n",
    "    total_valid_loss.append(fold_valid_loss)\n",
    "\n",
    "print('auroc %.4f(%.4f)'%(np.mean(auroc), np.std(auroc)))\n",
    "print('auprc %.4f(%.4f)'%(np.mean(auprc), np.std(auprc)))\n",
    "print('minpse %.4f(%.4f)'%(np.mean(minpse), np.std(minpse)))  \n",
    "print('f1 %.4f(%.4f)'%(np.mean(f1), np.std(f1))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T04:25:25.999863Z",
     "start_time": "2020-10-02T04:25:25.987849Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auroc 0.8972(0.0261)\n",
      "auprc 0.6946(0.1159)\n",
      "minpse 0.6501(0.0705)\n",
      "f1 0.5357(0.0970)\n"
     ]
    }
   ],
   "source": [
    "print('auroc %.4f(%.4f)'%(np.mean(auroc), np.std(auroc)))\n",
    "print('auprc %.4f(%.4f)'%(np.mean(auprc), np.std(auprc)))\n",
    "print('minpse %.4f(%.4f)'%(np.mean(minpse), np.std(minpse)))  \n",
    "print('f1 %.4f(%.4f)'%(np.mean(f1), np.std(f1))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
